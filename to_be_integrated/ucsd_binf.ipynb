{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import re\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "#import numpy as np\n",
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DNA = ('A', 'C', 'G', 'T')\n",
    "RNA = ('A', 'C', 'G', 'U')\n",
    "\n",
    "MAP_seq2NUMBER = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "MAP_RNA2NUMBER = {'A':0, 'C':1, 'G':2, 'U':3}\n",
    "\n",
    "MAP_NUMBER2DNA = {0:'A', 1:'C', 2:'G', 3:'T'}\n",
    "MAP_NUMBER2RNA = {0:'A', 1:'C', 2:'G', 3:'U'}\n",
    "\n",
    "MAP_CODON2AMINOACID = {'GUC': 'V', 'ACC': 'T', 'GUA': 'V', 'GUG': 'V', 'GUU': 'V', 'AAC': 'N', 'CCU': 'P', 'UGG': 'W',\n",
    "                       'AGC': 'S', 'AUC': 'I', 'CAU': 'H', 'AAU': 'N', 'AGU': 'S', 'ACU': 'T', 'CAC': 'H', 'ACG': 'T',\n",
    "                       'CCG': 'P', 'CCA': 'P', 'ACA': 'T', 'CCC': 'P', 'GGU': 'G', 'UCU': 'S', 'GCG': 'A', 'UGC': 'C',\n",
    "                       'CAG': 'Q', 'GAU': 'D', 'UAU': 'Y', 'CGG': 'R', 'UCG': 'S', 'AGG': 'R', 'GGG': 'G', 'UCC': 'S',\n",
    "                       'UCA': 'S', 'GAG': 'E', 'GGA': 'G', 'UAC': 'Y', 'GAC': 'D', 'GAA': 'E', 'AUA': 'I', 'GCA': 'A',\n",
    "                       'CUU': 'L', 'GGC': 'G', 'AUG': 'M', 'CUG': 'L', 'CUC': 'L', 'AGA': 'R', 'CUA': 'L', 'GCC': 'A',\n",
    "                       'AAA': 'K', 'AAG': 'K', 'CAA': 'Q', 'UUU': 'F', 'CGU': 'R', 'CGA': 'R', 'GCU': 'A', 'UGU': 'C',\n",
    "                       'AUU': 'I', 'UUG': 'L', 'UUA': 'L', 'CGC': 'R', 'UUC': 'F', 'UAA': 'X', 'UAG': 'X', 'UGA': 'X'}\n",
    "\n",
    "ALPHANUMERIC = [chr(i) for i in range(48, 58)] + [chr(i) for i in range(65, 91)] + [chr(i) for i in range(97, 123)]\n",
    "WHITESPACE = re.compile(r'\\s*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_kmer_freq(sequence, kmer):\n",
    "    \"\"\"\n",
    "    PatternCount\n",
    "    \n",
    "    Count the number of times <kmer> appears in <sequence>.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    # Slide window\n",
    "    for i in range(len(sequence) - len(kmer) + 1):\n",
    "        # Check match\n",
    "        if sequence[i:i + len(kmer)] == kmer:\n",
    "            # Update count\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def convert_nucleotide_to_number(nucleotide, nucleotide_type='DNA'):\n",
    "    \"\"\"\n",
    "    PatternToNumber\n",
    "    \n",
    "    Use lexicographical order to turn <nucleotide> into a number.\n",
    "    Kmer represents a 4-ary number.\n",
    "    \n",
    "    Removing the final symbol from all lexicographically ordered k-mers maintians the resulting list to be still ordered lexicographically.    \n",
    "    \"\"\"\n",
    "    if len(nucleotide) == 0:\n",
    "        return 0\n",
    "    \n",
    "    if nucleotide_type == 'DNA':\n",
    "        return 4 * convert_nucleotide_to_number(nucleotide[:-1]) + MAP_seq2NUMBER[nucleotide[-1]]\n",
    "    elif nucleotide_type == 'RNA':\n",
    "        return 4 * convert_nucleotide_to_number(nucleotide[:-1], nucleotide_type='RNA') + MAP_RNA2NUMBER[nucleotide[-1]]\n",
    "\n",
    "    \n",
    "def convert_number_to_nucleotide(number, k, nucleotide_type='DNA'):\n",
    "    \"\"\"\n",
    "    NumberToPattern\n",
    "    \n",
    "    Use lexicographical order to turn <number> into a nucleotide of length <k>.\n",
    "    \"\"\"\n",
    "    if k == 1:\n",
    "        if nucleotide_type == 'DNA':\n",
    "            return MAP_NUMBER2DNA[number]\n",
    "        elif nucleotide_type == 'RNA':\n",
    "            return MAP_NUMBER2RNA[number]\n",
    "    \n",
    "    prefix_index = int(number / 4)\n",
    "    if nucleotide_type == 'DNA':\n",
    "        return convert_number_to_nucleotide(prefix_index, k-1) + MAP_NUMBER2DNA[number % 4]\n",
    "    elif nucleotide_type == 'RNA':\n",
    "        return convert_number_to_nucleotide(prefix_index, k-1, nucleotide_type='RNA') + MAP_NUMBER2DNA[number % 4]\n",
    "\n",
    "    \n",
    "def make_kmer_freq_array(sequence, k):\n",
    "    \"\"\"\n",
    "    ComputingFrequencies\n",
    "    \n",
    "    Make a frequency array holding all <k>mers (length 4^k),\n",
    "    where the ith element of the array holds the number of times\n",
    "    that the i-th k-mer appears (in the lexicographic order) in <sequence>.\n",
    "    param sequence: string\n",
    "    param k: int\n",
    "    return: numpy array\n",
    "    \"\"\"\n",
    "    # Make an empty array of length 4^k\n",
    "    freq_array = [0 for i in range(4 ** k)]#np.zeros(4**k)\n",
    "    \n",
    "    # Slide over <sequence>\n",
    "    for i in range(len(sequence) - k + 1):\n",
    "        # For each kmer, get its number representation <n> and increment <freq_array>[<n>]\n",
    "        n = convert_nucleotide_to_number(sequence[i:i+k])\n",
    "        freq_array[n] += 1\n",
    "    return freq_array\n",
    "\n",
    "\n",
    "def get_most_freq_kmers(sequence, k, algorithm='freq_array'):\n",
    "    \"\"\"\n",
    "    FrequentWords & FreqArrayFrequentWords & FreqArraySortFrequentWords\n",
    "    \n",
    "    Find the most frequenct <k>mer in <sequence>.\n",
    "    \"\"\"\n",
    "    most_freq_kmers = []\n",
    "    max_freq = 0\n",
    "    length = len(sequence)\n",
    "    \n",
    "    if algorithm == 'freq_array':\n",
    "        # Make frequency array\n",
    "        freq_array = make_kmer_freq_array(sequence, k)\n",
    "        for i, freq in enumerate(freq_array):\n",
    "            if freq > max_freq:\n",
    "                most_freq_kmers = [convert_number_to_nucleotide(i, k)]\n",
    "                max_freq = freq\n",
    "            elif freq == max_freq:\n",
    "                most_freq_kmers.append(convert_number_to_nucleotide(i, k))\n",
    "    \n",
    "    elif algorithm == 'brute_force':\n",
    "        # Slide window\n",
    "        for i in range(len(sequence) - k + 1):\n",
    "            kmer = sequence[i:i + k]\n",
    "            # Get frequency of this kmer\n",
    "            freq = get_kmer_freq(sequence, kmer)\n",
    "            if freq > max_freq:\n",
    "                most_freq_kmers = [kmer]\n",
    "                max_freq = freq\n",
    "            elif freq == max_freq: # Tie\n",
    "                most_freq_kmers.append(kmer)\n",
    "        \n",
    "    elif algorithm == 'sort':\n",
    "        # Lexicographical order of kmers\n",
    "        kmer_lex_idx = [(None, 0) for i in range(length - k + 1)]\n",
    "        kmer_count = {}\n",
    "        for i in range(length - k + 1):\n",
    "            kmer = sequence[i:i + k]\n",
    "            kmer_lex_idx[i] = kmer, convert_nucleotide_to_number(kmer)\n",
    "            kmer_count[kmer] = 1\n",
    "\n",
    "        # Sort kmers by lexicographical order\n",
    "        print('kmer_lex_idx: before sort', kmer_lex_idx)        \n",
    "        kmer_lex_idx = sorted(kmer_lex_idx, key=lambda x: x[1])\n",
    "        print('kmer_lex_idx: after sort', kmer_lex_idx)\n",
    "\n",
    "        for i in range(1, len(kmer_lex_idx)):\n",
    "            prev_t = kmer_lex_idx[i - 1]\n",
    "            t = kmer_lex_idx[i]\n",
    "            if prev_t[1] == t[1]:\n",
    "                kmer_count[t[0]] = kmer_count[prev_t[0]]  + 1\n",
    "\n",
    "        for k, v in kmer_count.items():\n",
    "            if v > max_freq:\n",
    "                most_freq_kmers = [k]\n",
    "                max_freq = v\n",
    "            elif v == max_freq:\n",
    "                most_freq_kmers.append(k)\n",
    "                \n",
    "    return set(most_freq_kmers), max_freq\n",
    "\n",
    "\n",
    "def reverse_complement(dna_sequence):\n",
    "    \"\"\"\n",
    "    ReverseComplement\n",
    "    \n",
    "    Return the reverse complement of <dna_sequence>.\n",
    "    \"\"\"\n",
    "    complements = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C', 'N': 'N', '': ''}\n",
    "    return ''.join([complements[x] for x in dna_sequence[::-1]])\n",
    "\n",
    "\n",
    "def get_hamming_distance_between_kmers(kmer1, kmer2):\n",
    "    \"\"\"\n",
    "    HammingDistance\n",
    "    \n",
    "    Get hamming distance between <kmer1> and <kmer2>.\n",
    "    \"\"\"\n",
    "    assert len(kmer1) == len(kmer2), 'Length of 2 kmers must be the same'\n",
    "    hamming_distance = 0\n",
    "    for i, char1 in enumerate(kmer1):\n",
    "        if char1 != kmer2[i]:\n",
    "            hamming_distance += 1\n",
    "    return hamming_distance\n",
    "\n",
    "\n",
    "def get_kmer_occurence(kmer, sequence, thres=0):\n",
    "    \"\"\"\n",
    "    PatternMatch & ApproximatePatternMatch\n",
    "    \n",
    "    Get all indices where <subseq> apprears in <seq>.\n",
    "    \"\"\"\n",
    "    kmer_length = len(kmer)\n",
    "    assert kmer_length <= len(sequence), 'kmer must be shorter than sequence'\n",
    "    occurences = []\n",
    "    for i in range(len(sequence) - kmer_length + 1):\n",
    "        if thres > 0 and get_hamming_distance_between_kmers(sequence[i:i + kmer_length], kmer) <= thres:\n",
    "            occurences.append(i)\n",
    "        elif sequence[i: i + kmer_length] == kmer:\n",
    "            occurences.append(i)\n",
    "    return occurences\n",
    "\n",
    "\n",
    "def count_approximate_kmer_occurence(kmer, sequence, d):\n",
    "    \"\"\"\n",
    "    ApproximatePatternCount\n",
    "    \n",
    "    Count the occurences of <kmer> in <sequence>, including mers with at most d mismatches with <kmer>.\n",
    "    \"\"\"\n",
    "    return len(get_kmer_occurence(kmer, sequence, thres=d))\n",
    "\n",
    "\n",
    "def get_clumping_kmers(seq, k, clump_length, thres):\n",
    "    \"\"\"\n",
    "    ClumpFinding\n",
    "    \n",
    "    Find clumping kmers (kmers that appears more than <thres> times within a subsequence of length <clump_length>) in <seq>.\n",
    "    \"\"\"\n",
    "    kmers = [0 for i in range(4 ** k)]#np.zeros(4**k)\n",
    "\n",
    "    # Slide window in which to evaluate clumps\n",
    "    for i in range(len(seq) - clump_length + 1):\n",
    "        # 1st window\n",
    "        if i == 0:\n",
    "            # Make the 1st frequency array\n",
    "            freq_array = make_kmer_freq_array(seq[i:clump_length], k)\n",
    "            # Record kmers that clump in this window\n",
    "            for j, freq in enumerate(freq_array):\n",
    "                if freq >= thres:\n",
    "                    kmers[j] = 1\n",
    "        else:\n",
    "            # Decrement for the kmer just passed (1st kmer of the last window)\n",
    "            freq_array[convert_nucleotide_to_number(seq[i - 1:i - 1 + k])] -= 1\n",
    "            # Increment for the kmer just encountered (last kmer of this window)\n",
    "            last_kmer = seq[i + clump_length - k:i + clump_length]\n",
    "            last_kmer_freq_array_idx = convert_nucleotide_to_number(last_kmer)            \n",
    "            freq_array[last_kmer_freq_array_idx] += 1\n",
    "            \n",
    "            # Check if the kmer just encountered (last kmer of this window) passes <thres>\n",
    "            if freq_array[last_kmer_freq_array_idx] >= thres:\n",
    "                kmers[last_kmer_freq_array_idx] += 1\n",
    "    \n",
    "    return set([convert_number_to_nucleotide(i, k) for i, clump_count in enumerate(kmers) if clump_count > 0])\n",
    "\n",
    "\n",
    "def make_cumulative_freq_difference_array(seq, kmer1, kmer2):\n",
    "    \"\"\"\n",
    "    Skew\n",
    "    \n",
    "    Return an array of length |<seq>|, whose i-th element is the\n",
    "    cumulative frequency difference of <kmer1> and <kmer2> up to i-th index.\n",
    "    \"\"\"\n",
    "    assert len(kmer1) == len(kmer2)\n",
    "    k = len(kmer1)\n",
    "    length = len(seq)\n",
    "    \n",
    "    cumulative_freq_difference_array = [0 for i in range(length - k + 1)] #np.empty(length - k + 1)\n",
    "    num_kmer1 = num_kmer2 = 0\n",
    "    # Slide window\n",
    "    for i in range(length - k + 1):\n",
    "        if seq[i:i + k] == kmer1:\n",
    "            num_kmer1 += 1\n",
    "        elif seq[i:i + k] == kmer2:\n",
    "            num_kmer2 += 1\n",
    "        cumulative_freq_difference_array[i] = (num_kmer1 - num_kmer2)\n",
    "    return cumulative_freq_difference_array\n",
    "\n",
    "\n",
    "def get_cumulative_kmer_freq_difference_array_min(seq, kmer1, kmer2):\n",
    "    \"\"\"\n",
    "    Get the index with the minimum of cumulative kmer frequency difference array, whose ith element is the\n",
    "    cumulative frequency difference of <kmer1> and <kmer2> up to i.\n",
    "    \"\"\"\n",
    "    cumulative_freq_difference_array = make_cumulative_freq_difference_array(seq, kmer1, kmer2)\n",
    "    #return np.where(cumulative_freq_difference_array==cumulative_freq_difference_array.min())\n",
    "    min_ = 0\n",
    "    min_indices = [0]\n",
    "    for i, diff in enumerate(cumulative_freq_difference_array):\n",
    "        if diff < min_:\n",
    "            min_indices = [i + 1]\n",
    "            min_ = diff\n",
    "        elif diff == min_:\n",
    "            min_indices.append(i + 1)\n",
    "    return min_indices\n",
    "\n",
    "\n",
    "def get_sequences_with_atmost_d_mismatch(sequence, d, nucleotide_type=DNA, include_self=True):\n",
    "    \"\"\"\n",
    "    Neighbors\n",
    "    \n",
    "    Ruturn all sequences with <d> mismatches from <sequence>.\n",
    "    \"\"\"\n",
    "    # No mismatch\n",
    "    if d == 0:\n",
    "        return sequence\n",
    "    \n",
    "    # Base case with 1 nucleotide\n",
    "    if len(sequence) == 1:\n",
    "        return set(nucleotide_type)\n",
    "\n",
    "    atmost_d_mismatch_seqs = set()\n",
    "    \n",
    "    '''\n",
    "    # Get sequences with at most <d> mismatches from suffix\n",
    "    first_nucleotide = sequence[0]\n",
    "    suffix = sequence[1:]\n",
    "    suffix_atmost_d_mismatch_seqs = get_sequences_with_atmost_d_mismatch(suffix, d)\n",
    "    for seq in suffix_atmost_d_mismatch_seqs:\n",
    "        if get_hamming_distance_between_kmers(suffix, seq) < d:\n",
    "            # Can add 1 or more mismatches\n",
    "            for s in [BASE + seq for BASE in nucleotide_type]:\n",
    "                atmost_d_mismatch_seqs.add(s)\n",
    "                \n",
    "        else:\n",
    "            atmost_d_mismatch_seqs.add(first_nucleotide + seq)\n",
    "    return atmost_d_mismatch_seqs\n",
    "    '''\n",
    "    \n",
    "    # Get <d> combinations of indecises at which sequence can differ\n",
    "    for differing_i in itertools.combinations(range(len(sequence)), d):\n",
    "        #print('differing_i:', differing_i)\n",
    "             \n",
    "        # Break apart <sequence> (to use itertools.product later)\n",
    "        broken_apart_seq = [[letter] for letter in sequence]\n",
    "        #print('broken_apart_seq:', broken_apart_seq)\n",
    "    \n",
    "        # Substitute [A, C, G, T] at these <differing_i>\n",
    "        for idx in differing_i:\n",
    "            broken_apart_seq[idx] = nucleotide_type\n",
    "        #print('broken_apart_seq: after substitution:', broken_apart_seq)\n",
    "        \n",
    "        # Cross multiply and add resulting kmers with atmost d mismatches to <atmost_d_mismatch_seqs>\n",
    "        for seq in [''.join(i) for i in [c for c in itertools.product(*broken_apart_seq)]]:\n",
    "            atmost_d_mismatch_seqs.add(seq)\n",
    "\n",
    "    if include_self:\n",
    "        atmost_d_mismatch_seqs.add(sequence)\n",
    "        \n",
    "    return atmost_d_mismatch_seqs\n",
    "\n",
    "\n",
    "def get_keys_with_max_value(dictionary):\n",
    "    \"\"\"\n",
    "    Get <dictionary>'s keys holding the max value.\n",
    "    \"\"\"\n",
    "    #sorted(kmer_to_freq.items(), key=lambda kv: kv[1])\n",
    "    keys = set()\n",
    "    max_value = max(dictionary.values())\n",
    "    for k, v in dictionary.items():\n",
    "        if v == max_value:\n",
    "            keys.add(k)\n",
    "    return keys\n",
    "\n",
    "\n",
    "def get_most_frequent_kmer_and_reverse_complement_with_d_mismatch(seq, k, d, choices=['A', 'C', 'G', 'T'], search_reverse_complement=True):\n",
    "    \"\"\"\n",
    "    FrequentWordsWithMismatchesAndReverseComplements\n",
    "    \n",
    "    Get the most frequent kmer whose <d>-mismatch sequences appear most frequently in <seq>.\n",
    "    \"\"\"\n",
    "    # Dictionary with kmer key and d-mismatch occurance value\n",
    "    kmer_to_freq = {}\n",
    "    \n",
    "    # Look at each kmer, sliding the window\n",
    "    for i in range(len(seq) - k + 1):\n",
    "        # For each similar kmer with at most <d> mismatches\n",
    "        for s in get_sequences_with_d_mismatch(seq[i:i + k], d):\n",
    "            if s in kmer_to_freq:\n",
    "                kmer_to_freq[s] += 1\n",
    "            else:\n",
    "                kmer_to_freq[s] = 1\n",
    "        if search_reverse_complement:\n",
    "            for s in get_sequences_with_d_mismatch(reverse_complement(seq[i:i + k]), d):\n",
    "                if s in kmer_to_freq:\n",
    "                    kmer_to_freq[s] += 1\n",
    "                else:\n",
    "                    kmer_to_freq[s] = 1\n",
    "    #print(kmer_to_freq)\n",
    "    return get_keys_with_max_value(kmer_to_freq)\n",
    "\n",
    "\n",
    "def find_oric_and_dnaa_box(genome, k, d):\n",
    "    \"\"\"\n",
    "    Find OriC and DnaA box in a genome.\n",
    "    \"\"\"\n",
    "    oric_loci = get_cumulative_kmer_freq_difference_array_min(g, 'G', 'C')\n",
    "    ave_min_ = sum(oric_loci) / len(oric_loci)\n",
    "    replication_start_window = g[ave_min_ - 500:ave_min_ + 500]\n",
    "    kmers = get_most_frequent_kmer_and_reverse_complement_with_d_mismatch(replication_start_window, k, d)\n",
    "    return oric_loci, kmers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_mtrx_from_lines(lines):\n",
    "    mtrx = [[] for i in range(len(lines))]\n",
    "    for i, line in enumerate(lines):\n",
    "        mtrx[i] = [float(j) for j in line.split()]\n",
    "    #print('mtrx:', mtrx)\n",
    "    return mtrx\n",
    "\n",
    "\n",
    "def get_kmers_from_sequence(sequence, k, return_set=False):\n",
    "    \"\"\"\n",
    "    Get all kmers in a <sequence>.\n",
    "    \"\"\"\n",
    "    assert k <= len(sequence), 'k must be less than or equal to sequence length'\n",
    "    kmers = [sequence[i:i + k] for i in range(len(sequence) - k + 1)]\n",
    "    \n",
    "    if return_set:\n",
    "        return set(kmers)\n",
    "    else:\n",
    "        return kmers\n",
    "\n",
    "\n",
    "def get_kmers_from_sequences(sequences, k, return_set=False):\n",
    "    \"\"\"\n",
    "    Get all kmers in all <sequences>.\n",
    "    \"\"\"\n",
    "    kmers = []\n",
    "    for sequence in sequences:\n",
    "        kmers.extend(get_kmers_from_sequence(sequence, k, return_set=return_set))\n",
    "\n",
    "    if return_set:\n",
    "        return set(kmers)\n",
    "    else:\n",
    "        return kmers\n",
    "\n",
    "\n",
    "def find_motifs(sequences, k, d, algorithm='brute'):\n",
    "    \"\"\"\n",
    "    MOTIFENUMERATION\n",
    "    \n",
    "    Find <k>mer motifs whose <d>m-ismatch kmers appear in all <sequences>.\n",
    "    \"\"\"\n",
    "    motifs = []\n",
    "    \n",
    "    # For all kmers in <sequences>\n",
    "    for kmer in get_kmers_from_sequences(sequences, k):\n",
    "        \n",
    "        # For each neighbor kmer (kmer with atmost d-mismatch)\n",
    "        for kmer_with_atmost_d_mismatch in get_sequences_with_d_mismatch(kmer, d, include_self=True):\n",
    "\n",
    "            # Flag indicating whether a kmer is in each sequence\n",
    "            found = [0 for i in range(len(sequences))]#np.zeros(len(sequences))\n",
    "            # Check if this neighboring kmer is in all <sequences>\n",
    "            for j, sequence in enumerate(sequences):\n",
    "                for i in range(len(sequence) - k + 1):\n",
    "                    if get_hamming_distance_between_kmers(sequence[i:i + k], kmer_with_atmost_d_mismatch) <= d:\n",
    "                        # Mark as present\n",
    "                        found[j] = 1\n",
    "                        # Check the next sequence\n",
    "                        break\n",
    "            # Add this neghbor kmer to motifs only if it is present in all <sequences>\n",
    "            if all(found):\n",
    "                motifs.append(kmer_with_atmost_d_mismatch)\n",
    "                \n",
    "    return set(motifs)\n",
    "\n",
    "\n",
    "def make_kmers(k, nucleotide_type='DNA'):\n",
    "    \"\"\"\n",
    "    Make all possible nucleotide <k>mers.\n",
    "    \"\"\"\n",
    "    if nucleotide_type == 'DNA':\n",
    "        return [''.join(product) for product in itertools.product(DNA, repeat=k)]\n",
    "    elif nucleotide_type == 'RNA':\n",
    "        return [''.join(product) for product in itertools.product(RNA, repeat=k)]\n",
    "    \n",
    "    \n",
    "def get_distance_between_kmer_and_sequence(kmer, sequence):\n",
    "    \"\"\"\n",
    "    Get the minimum distance between <kmer> and a kmer in <sequence>.\n",
    "    \"\"\"\n",
    "    # Initialize the minimum distance to be as long as possible (length of the kmer)\n",
    "    min_distance = len(kmer)\n",
    "    # For each kmer in this sequence\n",
    "    for i in range(len(sequence) - len(kmer) + 1):\n",
    "        # Computer the distance between <kmer> and this kmer being scanned\n",
    "        distance = get_hamming_distance_between_kmers(kmer, sequence[i:i + len(kmer)])\n",
    "        # If the computed distance is closer than the current minimum distance,\n",
    "        if distance < min_distance:\n",
    "            # update the minumun distance to be the current distance\n",
    "            min_distance = distance\n",
    "    return min_distance\n",
    "\n",
    "\n",
    "def get_distance_between_kmer_and_sequences(kmer, sequences):\n",
    "    \"\"\"\n",
    "    Get the sum of the minimum distances between <kmer> and a kmer in each sequence in <sequence>.\n",
    "    \"\"\"\n",
    "    sum_distance = 0\n",
    "    # For each sequence\n",
    "    for sequence in sequences:\n",
    "        # Sum the distance between <kmer> and this sequence\n",
    "        sum_distance += get_distance_between_kmer_and_sequence(kmer, sequence)\n",
    "    return sum_distance\n",
    "\n",
    "\n",
    "def get_kmer_closest_to_sequences(sequences, k):\n",
    "    \"\"\"\n",
    "    MEDIANSTRING\n",
    "    \n",
    "    Return a <k>mer whose sum of the distance to each sequence in <sequences> is the minimum.\n",
    "    \"\"\"\n",
    "    # Make all possible kmers\n",
    "    kmers = make_kmers(k)\n",
    "    # Find the mediam string by minimizing the sum of the distances between a kmer and each sequence\n",
    "    min_ = k * len(sequences)\n",
    "    closest_kmers = []\n",
    "    for kmer in kmers:\n",
    "        distance_between_kmer_and_sequences = get_distance_between_kmer_and_sequences(kmer, sequences)\n",
    "        if distance_between_kmer_and_sequences < min_:\n",
    "            min_ = distance_between_kmer_and_sequences\n",
    "            closest_kmers.append(kmer)\n",
    "    return closest_kmers, min_\n",
    "\n",
    "\n",
    "def is_uniform_list_of_lists(list_of_lists):\n",
    "    \"\"\"\n",
    "    Return True if all list in <list_of_lists> have the same length.\n",
    "    \"\"\"\n",
    "    list_length = len(list_of_lists[0])\n",
    "    for a_list in list_of_lists:\n",
    "        if len(a_list) != list_length:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def make_mtrx_acgt_x_idx(sequence_motif_matrix):\n",
    "    \"\"\"\n",
    "    Make nucleotide x kmer index matrix.\n",
    "    \"\"\"\n",
    "    assert is_uniform_list_of_lists(sequence_motif_matrix)\n",
    "    seq_length = len(sequence_motif_matrix[0])\n",
    "    \n",
    "    mtrx_acgt_x_idx = [[0 for j in range(seq_length)] for i in DNA]\n",
    "    #print('mtrx_acgt_x_idx:', mtrx_acgt_x_idx)\n",
    "    \n",
    "    for seq in sequence_motif_matrix:\n",
    "        for j, n in enumerate(seq):\n",
    "            mtrx_acgt_x_idx[MAP_seq2NUMBER.get(n)][j] += 1\n",
    "    #print('mtrx_acgt_x_idx:', mtrx_acgt_x_idx)\n",
    "    return mtrx_acgt_x_idx\n",
    "\n",
    "\n",
    "def make_probability_mtrx_acgt_x_idx(sequence_motif_matrix):\n",
    "    \"\"\"\n",
    "    PROFILE\n",
    "    \n",
    "    Create a DNA x index probability matrix from list of <sequence_motif_matrix>.\n",
    "    \"\"\"\n",
    "    assert is_uniform_list_of_lists(sequence_motif_matrix)\n",
    "    seq_length = len(sequence_motif_matrix[0])\n",
    "    \n",
    "    mtrx_acgt_x_idx = make_mtrx_acgt_x_idx(sequence_motif_matrix)\n",
    "    mtrx_prob_acgt_x_idx = [[0 for j in range(seq_length)] for i in DNA]\n",
    "\n",
    "    for j in range(seq_length):\n",
    "        for i in range(len(DNA)):\n",
    "            mtrx_prob_acgt_x_idx[i][j] = (mtrx_acgt_x_idx[i][j] + 1) / (sum([mtrx_acgt_x_idx[ii][j] for ii in range(len(DNA))]) + 4)\n",
    "    #print('mtrx_prob_acgt_x_idx:', mtrx_prob_acgt_x_idx)\n",
    "    assert is_probability_mtrx(mtrx_prob_acgt_x_idx)\n",
    "    \n",
    "    return mtrx_prob_acgt_x_idx\n",
    "\n",
    "\n",
    "def is_probability_mtrx(probability_mtrx):\n",
    "    \"\"\"\n",
    "    Check if a probability matrix is a list of list and each column sums up to 1.\n",
    "    \"\"\"\n",
    "    assert is_uniform_list_of_lists(probability_mtrx)\n",
    "    row_lenth = len(probability_mtrx)\n",
    "    col_lenth = len(probability_mtrx[0])\n",
    "    for j in range(col_lenth):\n",
    "        #print('probability column: ', [probability_mtrx[i][j] for i in range(row_lenth)])\n",
    "        assert 0.95 < sum([probability_mtrx[i][j] for i in range(row_lenth)]) and sum([probability_mtrx[i][j] for i in range(row_lenth)]) < 1.05, 'error at col %s, each probability column must sum up to 1' % j\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_entropy(probability_list):\n",
    "    \"\"\"\n",
    "    Calculate entropy of a list of probabilities.\n",
    "    \"\"\"\n",
    "    return -1 * sum([p * math.log2(p) for p in probability_list if p > 0])\n",
    "\n",
    "\n",
    "def get_probability_mtrx_entropy(probability_mtrx):\n",
    "    \"\"\"\n",
    "    Calculate column entropy of probability matrix.\n",
    "    \"\"\"\n",
    "    assert is_probability_mtrx(probability_mtrx)\n",
    "    col_lenth = len(probability_mtrx)\n",
    "    row_length = len(probability_mtrx[0])\n",
    "    \n",
    "    col_entropy = [None for j in range(row_length)]\n",
    "    for j in range(row_length):\n",
    "        col = [probability_mtrx[i][j] for i in range(col_lenth)]\n",
    "        col_entropy[j] = get_entropy(col)\n",
    "    return col_entropy\n",
    "\n",
    "\n",
    "def get_sequence_motif_mtrx_entropy(sequence_motif_matrix):\n",
    "    \"\"\"\n",
    "    Calculate column entropy of a <sequence_motif_matrix>.\n",
    "    \"\"\"\n",
    "    assert is_uniform_list_of_lists(sequence_motif_matrix)\n",
    "    \n",
    "    prob_mtrx = make_probability_mtrx_acgt_x_idx(sequence_motif_matrix)\n",
    "    return sum(get_probability_mtrx_entropy(prob_mtrx))\n",
    "\n",
    "\n",
    "def get_mtrx_max_by_row(mtrx):\n",
    "    \"\"\"\n",
    "    Get the max values and their row indices of <mtrx> columns.\n",
    "    \"\"\"\n",
    "    assert is_uniform_list_of_lists(mtrx)\n",
    "    row_lenth = len(mtrx)\n",
    "    col_lenth = len(mtrx[0])\n",
    "    \n",
    "    mtrx_max_by_row = [() for i in range(col_lenth)]\n",
    "    for j in range(col_lenth):\n",
    "        col = [mtrx[i][j] for i in range(row_lenth)]\n",
    "        max_ = max(col)\n",
    "        max_idx = col.index(max_)\n",
    "        mtrx_max_by_row[j] = (max_idx, max_)\n",
    "    return mtrx_max_by_row\n",
    "\n",
    "\n",
    "def make_kmer_most_probable_from_probability_mtrx(probability_mtrx_acgt_x_idx):\n",
    "    \"\"\"\n",
    "    Make the most probable kmer from <probability_mtrx_acgt_x_idx>.\n",
    "    \"\"\"\n",
    "    assert is_probability_mtrx(probability_mtrx_acgt_x_idx)\n",
    "    col_lenth = len(probability_mtrx_acgt_x_idx[0])\n",
    "\n",
    "    most_probable_kmer = ''\n",
    "    mtrx_max_by_row = get_mtrx_max_by_row(probability_mtrx_acgt_x_idx)\n",
    "    for i, v in mtrx_max_by_row:\n",
    "        most_probable_kmer += MAP_NUMBER2DNA[i]\n",
    "    return most_probable_kmer\n",
    "\n",
    "\n",
    "def make_kmer_most_probable_from_sequence_motif_mtrx(sequence_motif_mtrx):\n",
    "    \"\"\"\n",
    "    Make the most probable kmer from <sequence_motif_mtrx>.\n",
    "    \"\"\"\n",
    "    probability_mtrx_acgt_x_idx = make_probability_mtrx_acgt_x_idx(sequence_motif_mtrx)\n",
    "    return make_kmer_most_probable_from_probability_mtrx(probability_mtrx_acgt_x_idx)\n",
    "\n",
    "\n",
    "def product(list_of_numbers):\n",
    "    prod = list_of_numbers[0]\n",
    "    for n in list_of_numbers[1:]:\n",
    "        prod = prod * n\n",
    "    return prod\n",
    "\n",
    "\n",
    "def get_kmer_probability_based_on_probability_mtrx(kmer, probability_mtrx_acgt_x_idx):\n",
    "    \"\"\"\n",
    "    Get the probabiliry of kmer based on <probability_mtrx_acgt_x_idx>.\n",
    "    \"\"\"\n",
    "    #print('probability_mtrx_acgt_x_idx:', probability_mtrx_acgt_x_idx)\n",
    "    assert is_probability_mtrx(probability_mtrx_acgt_x_idx)\n",
    "    #print('kmer:', kmer)\n",
    "    assert len(kmer) == len(probability_mtrx_acgt_x_idx[0])\n",
    "    \n",
    "    nuc_probs = [None for i in range(len(kmer))]\n",
    "    \n",
    "    for j, nuc in enumerate(kmer):\n",
    "        nuc_probs[j] = probability_mtrx_acgt_x_idx[MAP_seq2NUMBER[nuc]][j]\n",
    "    \n",
    "    return product(nuc_probs)\n",
    "\n",
    "\n",
    "def get_kmers_most_probable_in_sequence_based_on_probability_mtrx(sequence, probability_mtrx_acgt_x_idx):\n",
    "    \"\"\"\n",
    "    Get the most probable kmer in <sequence> based on <probability_mtrx_acgt_x_idx>.\n",
    "    \"\"\"\n",
    "    max_prob = 0\n",
    "    most_probable_kmers = []\n",
    "    k = len(probability_mtrx_acgt_x_idx[0])\n",
    "    # Slide window of length k\n",
    "    for i in range(len(sequence) - k + 1):\n",
    "        kmer = sequence[i:i + k]\n",
    "        #print('kmer:', kmer)\n",
    "        prob = get_kmer_probability_based_on_probability_mtrx(kmer, probability_mtrx_acgt_x_idx)\n",
    "        #print('prob:', prob)\n",
    "        if max_prob < prob:\n",
    "            max_prob = prob\n",
    "            most_probable_kmers = [kmer]\n",
    "        elif max_prob == prob:\n",
    "            most_probable_kmers.append(kmer)\n",
    "\n",
    "    return most_probable_kmers, max_prob\n",
    "\n",
    "\n",
    "def get_kmers_most_probable_in_sequences_based_on_probability_mtrx(sequences, probability_mtrx_acgt_x_idx):\n",
    "    \"\"\"\n",
    "    Get the most probable kmers from each sequence in <sequences> based on <probability_mtrx_acgt_x_idx>.\n",
    "    \"\"\"\n",
    "    kmers = []\n",
    "    for seq in sequences:\n",
    "        kmers.append(get_kmers_most_probable_in_sequence_based_on_probability_mtrx(seq, probability_mtrx_acgt_x_idx))\n",
    "    return kmers\n",
    "\n",
    "\n",
    "def score_motifs(motifs):\n",
    "    \"\"\"\n",
    "    Score <motifs> by 1) making the most probable kmer based on <motifs>'s probability matrix and \n",
    "    2) summing the distances between this most probable kmer and each kmer in <motifs>.\n",
    "    \"\"\"\n",
    "    most_probable_motif = make_kmer_most_probable_from_sequence_motif_mtrx(motifs)\n",
    "    return get_distance_between_kmer_and_sequences(most_probable_motif, motifs)\n",
    "\n",
    "\n",
    "def search_motifs_greedly(sequences, k):\n",
    "    # First best motifs are formed by first k-mers in <sequences>\n",
    "    best_motifs = [seq[:k] for seq in sequences]\n",
    "    \n",
    "    # Slide window of size k on 1st sequence\n",
    "    for i in range(len(sequences[0]) - k + 1):\n",
    "        # First motif is only the 1st kmer in sequeces[0]\n",
    "        cur_motifs = [sequences[0][i: i + k]]\n",
    "        # For subsequent <sequences>\n",
    "        for i in range(1, len(sequences)):\n",
    "            # Make probabiliry matrix of the cur_motifs\n",
    "            cur_prob_mtrx = make_probability_mtrx_acgt_x_idx(cur_motifs)\n",
    "            # Get the best motif in this sequence based on cur_prob_mtrx\n",
    "            #print('cur_prob_mtrx:', cur_prob_mtrx)\n",
    "            selected_motif = get_kmers_most_probable_in_sequence_based_on_probability_mtrx(sequences[i], cur_prob_mtrx)[0][0]\n",
    "            cur_motifs.append(selected_motif)\n",
    "            \n",
    "        # Update the best motif matrix based on scoring\n",
    "        if score_motifs(cur_motifs) < score_motifs(best_motifs):\n",
    "            best_motifs = cur_motifs\n",
    "        \n",
    "    return best_motifs\n",
    "\n",
    "\n",
    "def sample_random_kmers(sequences, k):\n",
    "    \"\"\"\n",
    "    Sample random <k>mers from <sequences>.\n",
    "    \"\"\"\n",
    "    # All sequence must have the same length\n",
    "    assert is_uniform_list_of_lists(sequences)\n",
    "    \n",
    "    random_kmers = []\n",
    "    for sequence in sequences:\n",
    "        i = random.randint(0, len(sequence) - k)\n",
    "        random_kmers.append(sequence[i:i + k])\n",
    "    return random_kmers\n",
    "\n",
    "\n",
    "def search_motifs_randomly(sequences, k):\n",
    "    cur_motifs = sample_random_kmers(sequences, k)\n",
    "    #print('cur_motifs: randomly chosen', cur_motifs)\n",
    "    best_motifs = cur_motifs\n",
    "    while True:\n",
    "        cur_prob_mtrx = make_probability_mtrx_acgt_x_idx(cur_motifs)\n",
    "        cur_motifs = [t[0][0] for t in get_kmers_most_probable_in_sequences_based_on_probability_mtrx(sequences, cur_prob_mtrx)]\n",
    "        #print('cur_motifs:', cur_motifs)\n",
    "        # Update the best motif matrix based on scoring\n",
    "        if score_motifs(cur_motifs) < score_motifs(best_motifs):\n",
    "            print('score_motifs(cur_motifs)', score_motifs(cur_motifs))\n",
    "            best_motifs = cur_motifs\n",
    "        else:\n",
    "            return best_motifs\n",
    "\n",
    "        \n",
    "def search_motifs_with_gibbs_sampling(sequences, k):\n",
    "    \"\"\"\n",
    "    GIBBSSAMPLER(Dna, k, t, N)\n",
    "    randomly select k-mers Motifs = (Motif1, …, Motift) in each string\n",
    "        from Dna\n",
    "    BestMotifs ← Motifs\n",
    "    for j ← 1 to N\n",
    "        i ← Random(t)\n",
    "        Profile ← profile matrix constructed from all strings in Motifs\n",
    "                   except for Motifi\n",
    "        Motifi ← Profile-randomly generated k-mer in the i-th sequence\n",
    "        if Score(Motifs) < Score(BestMotifs)\n",
    "            BestMotifs ← Motifs\n",
    "    return BestMotifs\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_sequence_overlapping_network(sequences, nonoverlap=1, edge_score=1):\n",
    "    assert is_uniform_list_sof_lists(sequences)\n",
    "    assert nonoverlap > 0, 'There must be overlap'\n",
    "    \n",
    "    network = Network()\n",
    "    for sequence in sequences:\n",
    "        network.make_node({'name':sequence, 'prefix':sequence[:-nonoverlap], 'suffix':sequence[nonoverlap:]})\n",
    "    \n",
    "    for node_from in network.nodes:\n",
    "        for node_to in remove_node_from_nodes(network.nodes, node_from):\n",
    "            if node_from['suffix'] == node_to['prefix']:\n",
    "                network.add_directed_edge([node_from, node_to, 1], allow_duplicate=False)\n",
    "                print('make_sequence_overlapping_network: added an edge %s =(%s)=> %s' % (node_from, edge_score, node_to))\n",
    "    return network\n",
    "\n",
    "\n",
    "def make_debruijn_network_from_sequence(sequence, k, edge_score=1):\n",
    "    kmers = get_kmers([sequence], k)\n",
    "    network = Network()\n",
    "    for kmer in kmers:\n",
    "        node_from = kmer[:-1]\n",
    "        node_to = kmer[1:]\n",
    "        network.add_directed_edge([node_from, node_to, 1])\n",
    "        #print('make_debruijn_network_from_sequence: added an edge %s =(%s)=> %s' % (node_from, edge_score, node_to))\n",
    "    return network\n",
    "\n",
    "\n",
    "def make_debruijn_network_from_kmers(kmers, edge_score=1, allow_duplicate=True):\n",
    "    network = Network()\n",
    "    for kmer in kmers:\n",
    "        node_from = kmer[:-1]\n",
    "        node_to = kmer[1:]\n",
    "        network.add_directed_edge([node_from, node_to, 1], allow_duplicate=allow_duplicate)\n",
    "        #print('make_debruijn_network_from_kmers: added an edge %s =(%s)=> %s' % (node_from, edge_score, node_to))\n",
    "    return network\n",
    "\n",
    "\n",
    "def print_debruijn_network(debruijn_network):\n",
    "    debruijn_dict = {}\n",
    "    \n",
    "    for node in debruijn_network.nodes:\n",
    "        debruijn_dict[node.get_name()] = []\n",
    "    \n",
    "    for node in debruijn_network.nodes:\n",
    "        if node.nodes_to:\n",
    "            #print(node, node.nodes_to)\n",
    "            #print(node, node.nodes_to)\n",
    "            #print('print_debruijn_network:', node.nodes_from, node, node.nodes_to)\n",
    "            current_values = debruijn_dict.get(node.get_name())\n",
    "            #print(values)\n",
    "            debruijn_dict[node.get_name()] = current_values + [n.get_name() for n in node.nodes_to]\n",
    "\n",
    "    for k, v in debruijn_dict.items():\n",
    "        if v:\n",
    "            print('%s -> %s' % (k, ','.join(v)))\n",
    "\n",
    "            \n",
    "def make_network_from_edges(edges):\n",
    "    \"\"\"\n",
    "    Make a network from <edges>.\n",
    "    \"\"\"\n",
    "    network = Network()\n",
    "    for e in edges:\n",
    "        if len(e) == 2:\n",
    "            e.extend([1])\n",
    "        print(e)\n",
    "        network.add_directed_edge(e, allow_duplicate=False)\n",
    "    return network\n",
    "\n",
    "\n",
    "def traverse_eulerian_cycle(eulerian_network_dict):\n",
    "    # Randomly choose a start_n\n",
    "    start_n = random.choice(list(eulerian_network_dict.keys()))\n",
    "    # Generate a cyclic path starting from start_n\n",
    "    path = traverse_cycle(eulerian_network_dict, start_n)\n",
    "    # While there is any unvisited edge\n",
    "    while len(eulerian_network_dict) != 0:\n",
    "        # Pick a start_n that has a remaining outgoing edge from cyclic path\n",
    "        start_n = random.choice([n for n in path if n in eulerian_network_dict])\n",
    "        # Get the index of the chosen start_n (used later for patching a full path)\n",
    "        i = path.index(start_n)\n",
    "        # Generate another cyclic path starting from start_n\n",
    "        a_path = traverse_cycle(eulerian_network_dict, start_n)        \n",
    "        path = path[i:] + path[1:i+1] + a_path[1:]\n",
    "    return path\n",
    "\n",
    "        \n",
    "def traverse_cycle(network, start_n):\n",
    "    # Cyclic path to return\n",
    "    path = [start_n]\n",
    "    while start_n in network:\n",
    "        # Randomly choose a start_n's outgoing edge\n",
    "        end_n = random.choice(network[start_n])\n",
    "        # Remove the chosen node from start_n's outgoing edges\n",
    "        network[start_n].remove(end_n)\n",
    "        # Remove start_n from the network if it has no more outgoing edges\n",
    "        if len(network[start_n]) == 0:\n",
    "            network.pop(start_n)\n",
    "        # Add end_n to path and end_n becomes the new start_n\n",
    "        path.append(end_n)\n",
    "        start_n = end_n\n",
    "    return path\n",
    "\n",
    "\n",
    "def find_eulerian_start_node(network):\n",
    "    # Get all keys\n",
    "    choices = network.keys()\n",
    "    for c in choices:\n",
    "        out_degree = len(network[c])\n",
    "        in_degree = sum([1 for v in network.values() if c in v])\n",
    "        if out_degree > in_degree:\n",
    "            # start_n must have more out edges than in edges\n",
    "            return c\n",
    "\n",
    "\n",
    "def traverse_eulerian_noncycle(network):\n",
    "    # Find the start node, which has more out going edge than incoming edges\n",
    "    start_n = find_eulerian_start_node(network)\n",
    "    \n",
    "    nodes = [start_n]\n",
    "    \n",
    "    path = []\n",
    "    while len(nodes) != 0:\n",
    "        current_n = nodes[-1]\n",
    "        \n",
    "        if current_n not in network:\n",
    "            # Last node without any outgoing edge\n",
    "            path.append(nodes.pop())\n",
    "            continue\n",
    "        \n",
    "        nodes_to = network[current_n]\n",
    "        if len(nodes_to) <= 0:\n",
    "            path.append(nodes.pop())\n",
    "        else:\n",
    "            node_to = random.choice(nodes_to)\n",
    "            network[current_n].remove(node_to)\n",
    "            nodes.append(node_to)\n",
    "    return path[::-1]\n",
    "\n",
    "\n",
    "def make_sequence_overlapping_network_dict(sequences, nonoverlap=1, edge_score=1):\n",
    "    assert is_uniform_list_of_lists(sequences)\n",
    "    assert nonoverlap > 0, 'There must be overlap'\n",
    "    network_dict = {}\n",
    "    for sequence in sequences:\n",
    "        network_dict[sequence[:-1]] = [sequence[1:]]\n",
    "    return network_dict\n",
    "\n",
    "\n",
    "def reconstruct_string(sequences):\n",
    "    network_dict = make_sequence_overlapping_network_dict(sequences)\n",
    "    path = traverse_eulerian_noncycle(network_dict)\n",
    "    sequence = path[0]\n",
    "    for n in path[1:]:\n",
    "        sequence += n[-1]\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def make_universal_circular_string_network_dict(k):\n",
    "    choices = [0, 1]\n",
    "    product = [p for p in itertools.product(choices, repeat=k-1)]\n",
    "    kmers = [''.join(str(x) for x in p) for p in product]\n",
    "    \n",
    "    kmer_dict = {}\n",
    "    for kmer in kmers:\n",
    "        overlap = kmer[1:]\n",
    "        kmer_dict[kmer] = kmer_dict.get(kmer, []) + [overlap + '1', overlap + '0']\n",
    "    return kmer_dict\n",
    "\n",
    "\n",
    "def make_universal_circular_string(k):\n",
    "    graph = make_universal_circular_string_network_dict(k)\n",
    "    path = traverse_eulerian_cycle(graph)\n",
    "    strand = ''\n",
    "    while len(path) >= 2:\n",
    "        edge = path[0] + path[1][-1]\n",
    "        strand += edge[0]\n",
    "        path = path[1:]\n",
    "    return strand\n",
    "\n",
    "\n",
    "def make_debruijn_network_from_paired_kmers(kmer_pairs):\n",
    "    debruijn_graph = {}\n",
    "    for kp1 in kmer_pairs:\n",
    "        kp1_suffix = (kp1[0][1:], kp1[1][1:])\n",
    "        for kp2 in kmer_pairs:\n",
    "            kp2_prefix = (kp2[0][:-1], kp2[1][:-1])\n",
    "            if kp1_suffix == kp2_prefix and kp1 != kp2:\n",
    "                debruijn_graph[kp1] = debruijn_graph.get(kp1, []) + [kp2]\n",
    "    return debruijn_graph\n",
    "\n",
    "\n",
    "def reconstruct_sequence_from_paired_kmers(kmer_pairs, distance):\n",
    "    debruijn_graph = make_debruijn_network_from_paired_kmers(kmer_pairs)\n",
    "    print(debruijn_graph)\n",
    "    k = len(kmer_pairs[0][0])\n",
    "    path = traverse_eulerian_noncycle(debruijn_graph)\n",
    "    print(path)\n",
    "    sequence = path[0][0]\n",
    "    for n in path[1:]:\n",
    "        sequence += n[0][-1]\n",
    "    for n in path[len(path) - k - d:]:\n",
    "        sequence += n[1][-1]\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def get_max_nonbranching_paths(graph):\n",
    "    paths = []\n",
    "    \n",
    "    # Get in- and out-degrees for each node in De Bruijn graph\n",
    "    degrees = get_node_degrees(graph)\n",
    "    print('degrees:', degrees)\n",
    "    \n",
    "    # Contigs can be built starting from nodes with not-1 indegree or more than 1 out-degree\n",
    "    starts = [n for n in graph if degrees[n][0] != 1 or degrees[n][1] > 1]\n",
    "    print('starts:', starts)\n",
    "    \n",
    "    for n in starts:\n",
    "        print('n:', n)\n",
    "        \n",
    "        while n in graph:\n",
    "            print('while n:', n)\n",
    "            \n",
    "            path = n[0]\n",
    "            print('path:', path)\n",
    "            \n",
    "            stop = False\n",
    "            while not stop:\n",
    "                \n",
    "                # Pick a next node and get its in- and out- degrees\n",
    "                next_n = random.choice(debruijn_graph[n])\n",
    "                degs = degrees[next_n]\n",
    "                print('next_n:', next_n, degs)\n",
    "                # Then remove this picked node from current node's next nodes\n",
    "                debruijn_graph[n].remove(next_n)\n",
    "                # If the current node doesn't have any more out-nodes\n",
    "                if len(debruijn_graph[n]) == 0:\n",
    "                    # Remove from the graph\n",
    "                    debruijn_graph.pop(n)\n",
    "                # If the next_n is in graph, implying that it has outgoing nodes\n",
    "                if next_n in debruijn_graph:\n",
    "                    # If contig intermedia node\n",
    "                    if degs == (1,1):\n",
    "                        # Extend contig by 1\n",
    "                        ctg += next_n[0]\n",
    "                        print('ctg:', ctg)\n",
    "                        # and update the current node\n",
    "                        n = next_n\n",
    "                        print('new n:', n)\n",
    "                    else:\n",
    "                        # If contig is the last node, fully extend contig\n",
    "                        ctg += next_n\n",
    "                        # This contig is done\n",
    "                        stop = True\n",
    "                else:\n",
    "                    # If the contig is not in the graph, implying that the node doens't have outgoing ndoes\n",
    "                    ctg += next_n\n",
    "                    # This contig is done\n",
    "                    stop = True\n",
    "                print('ctg:', ctg)\n",
    "                \n",
    "            # Add the node to the contigs\n",
    "            contigs.append(ctg)\n",
    "    return sorted(contigs)\n",
    "\n",
    "\n",
    "def extend_nonbranching_path(graph, start, ignore):\n",
    "    print('ignore:', ignore)\n",
    "    path = [start]\n",
    "    \n",
    "    # Base case: start node has no outgoing edge or has multiple outgoing edges\n",
    "    if start not in graph or len(graph[start]) != 1:\n",
    "        return path\n",
    "    \n",
    "    # Recursive case when the out-degree is 1\n",
    "    \n",
    "    # Ignore\n",
    "    unvisited_nodes = list(set(graph[start]) - set(ignore))\n",
    "    \n",
    "    # Pick the next node\n",
    "    next_ = unvisited_nodes[0]\n",
    "    print('extend_nonbranching_path: next_:', next_)\n",
    "    ignore.append(next_)\n",
    "          \n",
    "    return path + extend_nonbranching_path(graph, next_, ignore)\n",
    "\n",
    "\n",
    "def get_nonbranching_path(graph, start, ignore=[]):\n",
    "    assert start in graph, '%s is either not a key in the graph (not a node in the graph or has 0 outgoing edge)'\n",
    "    \n",
    "    # Ignore\n",
    "    unvisited_nodes = list(set(graph[start]) - set(ignore))\n",
    "\n",
    "    if len(unvisited_nodes) > 1:\n",
    "        # Start has multiple outgoing edges, so pick the first branch to extend\n",
    "        path = [start]\n",
    "        next_ =  unvisited_nodes[0]\n",
    "        return path + extend_nonbranching_path(graph, next_, ignore=ignore)\n",
    "    else:\n",
    "        return extend_nonbranching_path(graph, start, ignore=ignore)\n",
    "\n",
    "    \n",
    "def get_nonbranching_paths(graph):\n",
    "    degrees = get_node_degrees(graph)\n",
    "    \n",
    "\n",
    "def change_money(money, coins):\n",
    "    min_coin = [9999999] * (money + 1)\n",
    "    min_coin[0] = 0\n",
    "    #print(min_coin, len(min_coin))\n",
    "    for m in range(len(min_coin))[1:]:\n",
    "        #print('m:', m)\n",
    "        for c in coins:\n",
    "            if c <= m:\n",
    "                #print('c:', c)\n",
    "                if min_coin[m - c] + 1 < min_coin[m]:\n",
    "                    min_coin[m] = min_coin[m - c] + 1\n",
    "                    #print(min_coin)\n",
    "    return min_coin[money]\n",
    "\n",
    "\n",
    "def MANHATTANTOURIST(D, R):\n",
    "    n = len(R)\n",
    "    m = len(D[0])\n",
    "    print('n, m:', n, m)\n",
    "\n",
    "    # Make an empty n x m matrix\n",
    "    M = [[0] * m for i in range(n)]\n",
    "    print('M:\\n', np.matrix(M))\n",
    "    \n",
    "    # Update the 1st column\n",
    "    for i, r in enumerate(M):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        r[0] = M[i - 1][0] + D[i - 1][0]\n",
    "    print('M:\\n', np.matrix(M))\n",
    "    \n",
    "    # Update the 1st row\n",
    "    for i, v in enumerate(M[0]):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        M[0][i] = M[0][i-1] + R[0][i-1]\n",
    "    print('M:\\n', np.matrix(M))\n",
    "    \n",
    "    for i in range(n)[1:]:\n",
    "        for j in range(m)[1:]:\n",
    "            down = M[i - 1][j] + D[i - 1][j]\n",
    "            right = M[i][j - 1] + R[i][j - 1]\n",
    "            #print('i, j:', i, j)\n",
    "            #print('down, right:', down, right)\n",
    "            #print('down, right:', down, right)\n",
    "            M[i][j] = max(down, right)\n",
    "            #print('Updated M[%s][%s]:' % (i, j), M[i][j])\n",
    "\n",
    "    print('M:\\n', np.matrix(M))\n",
    "\n",
    "    \n",
    "def get_longest_common_subsequence(seq1, seq2):\n",
    "    print('seq1', seq1)\n",
    "    print('seq2', seq2)\n",
    "    n = len(seq1)\n",
    "    m = len(seq2)\n",
    "    print('n, m:', n, m)\n",
    "    \n",
    "    # Make a similarity matrix\n",
    "    S = [[0] * m for i in range(n)]\n",
    "    for i, b1 in enumerate(seq1):\n",
    "        for j, b2 in enumerate(seq2):\n",
    "            if b1 == b2:\n",
    "                S[i][j] = 1\n",
    "    print('S:\\n', np.matrix(S))\n",
    "    \n",
    "    # Make an empty n x m matrix\n",
    "    M = [[0] * (m + 1) for i in range(n + 1)]\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            M[i + 1][j + 1] = max(M[i][j] + S[i][j], M[i][j + 1], M[i + 1][j])\n",
    "    print('M:\\n', np.matrix(M))\n",
    "    \n",
    "    longest_commond_seq = []\n",
    "    \n",
    "    Mi, Mj = n, m\n",
    "    while Mi > 0 and Mj > 0:\n",
    "        print('current:', Mi, Mj, M[Mi][Mj], seq1[Mi - 1])\n",
    "\n",
    "        if M[Mi][Mj - 1] == M[Mi][Mj]:\n",
    "            Mj = Mj - 1\n",
    "        elif M[Mi - 1][Mj] == M[Mi][Mj]:\n",
    "            Mi = Mi - 1\n",
    "        else:\n",
    "            Mi, Mj = Mi - 1, Mj - 1\n",
    "            print('match:', Mi, Mj, M[Mi][Mj], seq1[Mi])\n",
    "            longest_commond_seq.append(seq1[Mi])\n",
    "\n",
    "    return ''.join(reversed(longest_commond_seq))\n",
    "\n",
    "\n",
    "def sort_topologically(graph):\n",
    "    \"\"\"\n",
    "    Find nodes without any incoming edges and remove them from the graph.\n",
    "    The topological order is this order of discovery.\n",
    "    \"\"\"\n",
    "    # Copy graph\n",
    "    graph = set(graph)\n",
    "    \n",
    "    # Get nodes without any incoming edge\n",
    "    no_inedge = list({edge[0] for edge in graph} - {edge[1] for edge in graph})\n",
    "    \n",
    "    # Recursive find\n",
    "    order = []\n",
    "    while len(no_inedge) != 0:\n",
    "        current = no_inedge.pop(0)\n",
    "        order.append(current)\n",
    "        \n",
    "        # For all edges starting form <current>\n",
    "        nodes_to = []\n",
    "        for edge in [edge for edge in graph if edge[0] == current]:\n",
    "\n",
    "            # Add the <node_to> to <nodes_to>\n",
    "            node_to = edge[1]\n",
    "            \n",
    "            # Remove this outgoing <edge> from the <graph>\n",
    "            graph.remove(edge)\n",
    "        \n",
    "            # If <node_to> doesn't have any incoming edges, add to <no_inedge> and order\n",
    "            if node_to not in {edge[1] for edge in graph}:\n",
    "                no_inedge.append(node_to)\n",
    "        \n",
    "    return order\n",
    "\n",
    "\n",
    "def get_longest_path_dag(edge_scores, edges, source, sink):\n",
    "\n",
    "    # Sort DAG graph topologically\n",
    "    order = sort_topologically(edge_scores.keys())\n",
    "    # Extract sequence from source to sink\n",
    "    order = order[order.index(source) + 1:order.index(sink) + 1]\n",
    "    #print('order:', order)\n",
    "\n",
    "    # Itinialize backtrack; all nodes' prevs are None\n",
    "    backtrack = {n: None for n in order}\n",
    "    \n",
    "    # Initialize scores; all nodes' scores are big negative\n",
    "    scores = {n: -999 for n in {e[0] for e in edge_scores.keys()} | {e[1] for e in edge_scores.keys()}}\n",
    "    \n",
    "    # Set source's score to be 0\n",
    "    scores[source] = 0\n",
    "\n",
    "    # Update the score in topological order\n",
    "    for n in order:\n",
    "        try:\n",
    "            edges_in = filter(lambda e: e[1] == n, edge_scores.keys())\n",
    "            get_node_from = lambda score_nodein: score_nodein[0]\n",
    "            scores[n], backtrack[n] = max(map(lambda e: [scores[e[0]] + edge_scores[e], e[0]], edges_in), key=get_node_from)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    # Backtracks\n",
    "    path = [sink]\n",
    "    while path[0] != source:\n",
    "        path = [backtrack[path[0]]] + path\n",
    "\n",
    "    return scores[sink], path\n",
    "\n",
    "\n",
    "def get_node_degrees(graph):\n",
    "    nodes_to = list(itertools.chain.from_iterable(graph.values()))\n",
    "    degrees = {}\n",
    "    for n in graph:\n",
    "        degrees[n] = [nodes_to.count(n), len(graph[n])]\n",
    "    # Nodes without any outgoing edge\n",
    "    for n in set(n for n in nodes_to if n not in graph):\n",
    "        degrees[n] = [nodes_to.count(n), 0]\n",
    "    return degrees\n",
    "\n",
    "\n",
    "def remove_self_edge(graph):\n",
    "    for n, to_nodes in graph.items():\n",
    "        graph[n] = [to for to in to_nodes if to != n]\n",
    "    return graph\n",
    "\n",
    "\n",
    "def backtrack(state, node, source):\n",
    "    track = [node]\n",
    "    \n",
    "    # Base case\n",
    "    if node == source:\n",
    "        return track\n",
    "    else:\n",
    "        return backtrack(state, state[node][1], source) + track\n",
    "    \n",
    "\n",
    "def get_incoming_nodes(graph):\n",
    "\n",
    "    ns = set()\n",
    "    for from_n, to_ns in graph.items():\n",
    "        ns.add(from_n)\n",
    "        for to in to_ns:\n",
    "            ns.add(to)\n",
    "            \n",
    "    #print('sorted(ns)', sorted(ns))\n",
    "    \n",
    "    n_ins = {}\n",
    "    # For all nodes\n",
    "    for n in ns:\n",
    "        n_ins[n] = []\n",
    "        \n",
    "        for from_n, to_ns in graph.items():\n",
    "            # If from_n visits n, then add from_n to n_ins[n]\n",
    "            if n in to_ns:\n",
    "\n",
    "                if from_n not in n_ins[n]:\n",
    "                    n_ins[n].append(from_n)\n",
    "    return n_ins\n",
    "\n",
    "\n",
    "def is_uniform_list_of_lists(list_of_lists):\n",
    "    \"\"\"\n",
    "    Return True if all list in <list_of_lists> have the same length.\n",
    "    \"\"\"\n",
    "    list_length = len(list_of_lists[0])\n",
    "    for a_list in list_of_lists:\n",
    "        if len(a_list) != list_length:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def init_global_alignment_direction_matrices(seq1, seq2, indel_penalty):\n",
    "    n = len(seq1)\n",
    "    m = len(seq2)\n",
    "    print('init_global_alignment_direction_matrices: n, m:', n, m)\n",
    "    \n",
    "    # Initialize the alignment and direction matrices, taking into consideration initial InDels\n",
    "    alignment_matrix = [[0] * (m + 1) for i in range(n + 1)]\n",
    "    direction_matrix = [[0] * (m + 1) for i in range(n + 1)]\n",
    "\n",
    "    # Update column 1\n",
    "    for i in range(n + 1):\n",
    "        alignment_matrix[i][0] = indel_penalty * i\n",
    "        if i != 0:\n",
    "            direction_matrix[i][0] = (i - 1, 0)\n",
    "    # Update row 1\n",
    "    for j in range(m + 1):\n",
    "        alignment_matrix[0][j] = indel_penalty * j\n",
    "        if j != 0:\n",
    "            direction_matrix[0][j] = (0, j - 1)\n",
    "        \n",
    "    print('init_global_alignment_direction_matrices: alignment_matrix:\\n', pd.DataFrame(alignment_matrix))\n",
    "    print('init_global_alignment_direction_matrices: direction_matrix:\\n', pd.DataFrame(direction_matrix))\n",
    "    return alignment_matrix, direction_matrix\n",
    "\n",
    "\n",
    "def init_local_alignment_direction_matrices(seq1, seq2):\n",
    "    n = len(seq1)\n",
    "    m = len(seq2)\n",
    "    print('init_local_alignment_direction_matrices: n, m:', n, m)\n",
    "    \n",
    "    # Initialize the alignment and direction matrices, taking into consideration initial InDels\n",
    "    alignment_matrix = [[0] * (m + 1) for i in range(n + 1)]\n",
    "    direction_matrix = [[0] * (m + 1) for i in range(n + 1)]\n",
    "    \n",
    "    # Update column 1\n",
    "    for i in range(n + 1)[1:]:\n",
    "        direction_matrix[i][0] = (0, 0)\n",
    "    # Update row 1\n",
    "    for j in range(m + 1)[1:]:\n",
    "        direction_matrix[0][j] = (0, 0)\n",
    "        \n",
    "    print('init_local_alignment_direction_matrices: alignment_matrix:\\n', pd.DataFrame(alignment_matrix))\n",
    "    print('init_local_alignment_direction_matrices: direction_matrix:\\n', pd.DataFrame(direction_matrix))\n",
    "    return alignment_matrix, direction_matrix\n",
    "\n",
    "\n",
    "def backtrack_alignment(seq1, seq2, direction_matrix, init_ij=None, and_or='or'):\n",
    "    # Backtrack\n",
    "    alignment = []\n",
    "    if init_ij:\n",
    "        print('backtrack_alignment: initialization coordinate:', init_ij)\n",
    "        i, j = init_ij\n",
    "    else:\n",
    "        print('backtrack_alignment: no initialization coordinate:')\n",
    "        i = len(seq1)\n",
    "        j = len(seq2)\n",
    "           \n",
    "    if and_or == 'or':\n",
    "        while i > 0 or j > 0:\n",
    "            toi, toj = direction_matrix[i][j]\n",
    "            #print('align_globally: i, j, toi, toj:', i, j, toi, toj)\n",
    "\n",
    "            # For local alignment termination\n",
    "            if toi == 0 and toj == 0:\n",
    "                break    \n",
    "\n",
    "            if toi == i - 1 and toj == j - 1:         \n",
    "                #print('align_globally: match or mismatch', seq1[toi], seq2[toj])\n",
    "                alignment.append((seq1[toi], seq2[toj]))\n",
    "            elif toi == i - 1 and toj == j:         \n",
    "                #print('align_globally: deletion', seq1[toi], '-')\n",
    "                alignment.append((seq1[toi], '-'))\n",
    "            elif toi == i and toj == j - 1:         \n",
    "                #print('align_globally: insertion', '-', seq2[toj])\n",
    "                alignment.append(('-', seq2[toj]))\n",
    "            else:\n",
    "                raise ValueError('direction error')\n",
    "\n",
    "            i, j = toi, toj\n",
    "    else:\n",
    "        while i > 0 and j > 0:\n",
    "            toi, toj = direction_matrix[i][j]\n",
    "            #print('align_globally: i, j, toi, toj:', i, j, toi, toj)\n",
    "\n",
    "            # For local alignment termination\n",
    "            if toi == 0 and toj == 0:\n",
    "                break    \n",
    "\n",
    "            if toi == i - 1 and toj == j - 1:         \n",
    "                #print('align_globally: match or mismatch', seq1[toi], seq2[toj])\n",
    "                alignment.append((seq1[toi], seq2[toj]))\n",
    "            elif toi == i - 1 and toj == j:         \n",
    "                #print('align_globally: deletion', seq1[toi], '-')\n",
    "                alignment.append((seq1[toi], '-'))\n",
    "            elif toi == i and toj == j - 1:         \n",
    "                #print('align_globally: insertion', '-', seq2[toj])\n",
    "                alignment.append(('-', seq2[toj]))\n",
    "            else:\n",
    "                raise ValueError('direction error')\n",
    "\n",
    "            i, j = toi, toj\n",
    "        \n",
    "    return alignment\n",
    "\n",
    "\n",
    "def align_globally(seq1, seq2, scoring_matrix, labels, indel_penalty):\n",
    "    alignment_matrix, direction_matrix = init_global_alignment_direction_matrices(seq1, seq2, indel_penalty)\n",
    "    \n",
    "    # Dynamically update alignment_matrix\n",
    "    for ridx, row in enumerate(alignment_matrix[1:]): \n",
    "        # Row element\n",
    "        relem = seq1[ridx]\n",
    "        rsidx = labels.index(relem)\n",
    "        assert relem == labels[rsidx]\n",
    "        #print('align_globally: ridx, row, relem, rsidx:', ridx, row, relem, rsidx)\n",
    "        \n",
    "        for cidx, col in enumerate(row[1:]):\n",
    "            # Column element\n",
    "            celem = seq2[cidx]\n",
    "            csidx = labels.index(celem)\n",
    "            assert celem == labels[csidx]\n",
    "            #print('align_globally: cidx, col, celem, csidx:', cidx, col, celem, csidx)\n",
    "            \n",
    "            # Score\n",
    "            smatch = alignment_matrix[ridx][cidx] + scoring_matrix[rsidx][csidx], (ridx, cidx)\n",
    "            sin = alignment_matrix[ridx][cidx + 1] - indel_penalty, (ridx, cidx + 1)\n",
    "            sdel = alignment_matrix[ridx + 1][cidx] - indel_penalty, (ridx + 1, cidx)\n",
    "            # Dynamically update alignment and direction matrices\n",
    "            max_ = max([smatch, sin, sdel], key=lambda t: t[0])\n",
    "            alignment_matrix[ridx + 1][cidx + 1] = max_[0]\n",
    "            direction_matrix[ridx + 1][cidx + 1] = max_[1]\n",
    "    \n",
    "    #print('align_globally: alignment_matrix\\n', pd.DataFrame(alignment_matrix, index=['0'] + [s for s in seq1], columns=['0'] + [s for s in seq2]))\n",
    "    #print('align_globally: direction_matrix\\n', pd.DataFrame(direction_matrix, index=['0'] + [s for s in seq1], columns=['0'] + [s for s in seq2]))\n",
    "\n",
    "    alignment = backtrack_alignment(seq1, seq2, direction_matrix)\n",
    "    #print('align_globally: final alignment:', alignment_matrix[len(seq1)][len(seq2)], alignment)\n",
    "    return alignment_matrix[len(seq1)][len(seq2)], alignment\n",
    "\n",
    "\n",
    "def align_locally(seq1, seq2, scoring_matrix, labels, indel_penalty):\n",
    "    alignment_matrix, direction_matrix = init_local_alignment_direction_matrices(seq1, seq2, indel_penalty)\n",
    "    \n",
    "\n",
    "    # Dynamically update the alignment_matrix\n",
    "    source = 0, (0, 0)\n",
    "    # Keep track of the coordinate with the maximum score\n",
    "    global_max = (source)\n",
    "    for ridx, row in enumerate(alignment_matrix[1:]): \n",
    "        # Row element\n",
    "        relem = seq1[ridx]\n",
    "        rsidx = labels.index(relem)\n",
    "        assert relem == labels[rsidx]\n",
    "        #print('align_locally: ridx, row, relem, rsidx:', ridx, row, relem, rsidx)\n",
    "\n",
    "        for cidx, col in enumerate(row[1:]):\n",
    "            # Column element\n",
    "            celem = seq2[cidx]\n",
    "            csidx = labels.index(celem)\n",
    "            assert celem == labels[csidx]\n",
    "            #print('align_locally: cidx, col, celem, csidx:', cidx, col, celem, csidx)\n",
    "\n",
    "            # Score\n",
    "            smatch = alignment_matrix[ridx][cidx] + scoring_matrix[rsidx][csidx], (ridx, cidx)\n",
    "            sin = alignment_matrix[ridx][cidx + 1] - indel_penalty, (ridx, cidx + 1)\n",
    "            sdel = alignment_matrix[ridx + 1][cidx] - indel_penalty, (ridx + 1, cidx)\n",
    "            # Dynamically update alignment and direction matrices\n",
    "            max_ = max([source, smatch, sin, sdel], key=lambda t: t[0])\n",
    "            alignment_matrix[ridx + 1][cidx + 1] = max_[0]\n",
    "            direction_matrix[ridx + 1][cidx + 1] = max_[1]            \n",
    "            \n",
    "            # Keep track of the coordinate with the maximum score\n",
    "            if global_max[0] < max_[0]:\n",
    "                global_max = (max_[0], (ridx + 1, cidx + 1))\n",
    "    \n",
    "    print('align_locally:\\n', pd.DataFrame(alignment_matrix, index=['0'] + [s for s in seq1], columns=['0'] + [s for s in seq2]))\n",
    "    print('align_locally:\\n', pd.DataFrame(direction_matrix, index=['0'] + [s for s in seq1], columns=['0'] + [s for s in seq2]))\n",
    "    print('align_locally: global_max', global_max)\n",
    "    \n",
    "    # Backtrack\n",
    "    alignment = backtrack_alignment(seq1, seq2, direction_matrix, init_ij=global_max[1])\n",
    "    print('align_locally: final alignment:', global_max[0], alignment)\n",
    "    return global_max[0], alignment\n",
    "\n",
    "\n",
    "def print_alignment(alignment_tuple):    \n",
    "    #print('print_alignment: alignment_tuple length:', len(alignment_tuple))\n",
    "    \n",
    "    seq1 = ''\n",
    "    seq2 = ''\n",
    "    for i in alignment_tuple:\n",
    "        if i[0] != '-':\n",
    "            seq1 += i[0]\n",
    "        else:\n",
    "            seq1 += '-'\n",
    "        if i[1] != '-':\n",
    "            seq2 += i[1]\n",
    "        else:\n",
    "            seq2 += '-'\n",
    "    assert len(alignment_tuple) == len(seq1) == len(seq2)\n",
    "    #print('print_alignment: alignment_tuple:', alignment_tuple)\n",
    "    #print('print_alignment: seq1:', seq1[::-1])\n",
    "    #print('print_alignment: seq2:', seq2[::-1])\n",
    "\n",
    "    return seq1[::-1], seq2[::-1]\n",
    "\n",
    "\n",
    "def score_alignment(seq1, seq2, scoring_matrix, labels, indel_penalty):\n",
    "    \n",
    "    assert len(seq1) == len(seq2), 'seq1 and seq2 must have the same length'\n",
    "    #print('score_alignment: alignment length:', len(seq1))\n",
    "\n",
    "    score = 0\n",
    "    for i in range(len(seq1)):\n",
    "        if seq1[i] == '-' or seq2[i] == '-':\n",
    "            score -= indel_penalty\n",
    "        else:\n",
    "            score += scoring_matrix[labels.index(seq1[i])][labels.index(seq2[i])]\n",
    "    return(score)\n",
    "\n",
    "\n",
    "def print_dict(dictionary, title=''):\n",
    "    \"\"\"\n",
    "    Print a dictionary.\n",
    "    \"\"\"\n",
    "    print(title)\n",
    "    print('Number of entries:', len(dictionary))\n",
    "    for k, v in dictionary.items():\n",
    "        print('%s ==> %s' % (k, v))\n",
    "    \n",
    "\n",
    "def align(seq1, seq2, scoring_matrix, labels, indel_penalty=5):\n",
    "    scr, aln = align_locally(seq1, seq2, scoring_matrix, labels, indel_penalty)\n",
    "    s1, s2 = print_alignment(aln)\n",
    "    assert score_alignment(s1, s2, scoring_matrix, labels, indel_penalty) == scr\n",
    "    print('%s\\n%s\\n%s' % (scr, s1, s2))\n",
    "\n",
    "    \n",
    "def get_edit_distance(seq1, seq2):\n",
    "    \"\"\"\n",
    "    Compute edit distance using dynamic programming.\n",
    "    \"\"\"\n",
    "    n, m = len(seq1), len(seq2)\n",
    "    print('get_edit_distance: n, m:', n, m)\n",
    "    \n",
    "    # Initialize the alignment and direction matrices, taking into consideration initial InDels\n",
    "    alignment_matrix = [[0] * (m + 1) for i in range(n + 1)]\n",
    "\n",
    "    # Update column 1\n",
    "    for i in range(n + 1):\n",
    "        alignment_matrix[i][0] = i\n",
    "    # Update row 1\n",
    "    for j in range(m + 1):\n",
    "        alignment_matrix[0][j] = j\n",
    "    print('get_edit_distance: alignment_matrix:\\n', pd.DataFrame(alignment_matrix))\n",
    "\n",
    "    # Dynamcally update the alignment matrix\n",
    "    for ridx in range(1, n + 1):\n",
    "        for cidx in range(1, m + 1):\n",
    "            #print('ridx, cidx:', ridx, cidx)\n",
    "\n",
    "            # Score\n",
    "            if seq1[ridx - 1] == seq2[cidx - 1]:\n",
    "                mismatch_penalty = 0\n",
    "            else:\n",
    "                mismatch_penalty = 1\n",
    "            \n",
    "            smatch = alignment_matrix[ridx - 1][cidx - 1] + mismatch_penalty, (ridx - 1, cidx - 1)\n",
    "            sin = alignment_matrix[ridx][cidx - 1] + 1, (ridx, cidx - 1)\n",
    "            sdel = alignment_matrix[ridx - 1][cidx] + 1, (ridx - 1, cidx)\n",
    "            # Dynamically update alignment and direction matrices\n",
    "            max_ = min([smatch, sin, sdel], key=lambda t: t[0])\n",
    "            alignment_matrix[ridx][cidx] = max_[0]\n",
    "\n",
    "    print('get_edit_distance: alignment_matrix final:\\n', pd.DataFrame(alignment_matrix))\n",
    "    \n",
    "    return alignment_matrix[n][m]\n",
    "\n",
    "\n",
    "def align_with_fit(seq1, seq2, indel_penalty=-1):\n",
    "\n",
    "    n, m = len(seq1), len(seq2)\n",
    "    print('get_edit_distance: n, m:', n, m)\n",
    "\n",
    "    alignment_matrix = [[0 for j in range(m + 1)] for i in range(n + 1)]\n",
    "    print('alignment_matrix: fresh\\n', pd.DataFrame(alignment_matrix))\n",
    "\n",
    "    direction_matrix = [[0 for j in range(m + 1)] for i in range(n + 1)]\n",
    "    print('direction_matrix: fresh\\n', pd.DataFrame(alignment_matrix))\n",
    "    \n",
    "    for ridx in range(1, n + 1):\n",
    "        for cidx in range(1, m + 1):\n",
    "            scores = [alignment_matrix[ridx - 1][cidx] - 1, alignment_matrix[ridx][cidx - 1] - 1, alignment_matrix[ridx - 1][cidx - 1] + [-1, 1][seq1[ridx - 1] == seq2[cidx - 1]]]\n",
    "            alignment_matrix[ridx][cidx] = max(scores)\n",
    "            direction_matrix[ridx][cidx] = scores.index(alignment_matrix[ridx][cidx])\n",
    "    print('alignment_matrix:\\n', pd.DataFrame(alignment_matrix))\n",
    "    \n",
    "    j = m\n",
    "    i = max(enumerate([alignment_matrix[r][j] for r in range(len(seq2), len(seq1))]), key=lambda x: x[1])[0] + len(seq2)\n",
    "    print('i, j:', i, j)\n",
    "    \n",
    "    max_score = alignment_matrix[i][j]\n",
    "    seq1_aligned, seq2_aligned = seq1[:i], seq2[:j]\n",
    "    add_indel = lambda word, i: word[:i] + '-' + word[i:]\n",
    "    while 0 < i and 0 < j:\n",
    "        if direction_matrix[i][j] == 0:\n",
    "            i -= 1\n",
    "            seq2_aligned = add_indel(seq2_aligned, j)\n",
    "        elif direction_matrix[i][j] == 1:\n",
    "            j -= 1\n",
    "            seq1_aligned = add_indel(seq1_aligned, i)\n",
    "        elif direction_matrix[i][j] == 2:\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "    seq1_aligned = seq1_aligned[i:]\n",
    "    return max_score, seq1_aligned, seq2_aligned\n",
    "\n",
    "\n",
    "def align_oseq1erlap(seq1, seq2):\n",
    "    n, m = len(seq1), len(seq2)\n",
    "    #print('get_edit_distance: n, m:', n, m)\n",
    "    alignment_matrix = [[0 for j in range(m + 1)] for i in range(n + 1)]\n",
    "    #print('alignment_matrix: fresh\\n', pd.DataFrame(alignment_matrix))\n",
    "    direction_matrix = [[0 for j in range(m + 1)] for i in range(n + 1)]\n",
    "    #print('direction_matrix: fresh\\n', pd.DataFrame(alignment_matrix))\n",
    "\n",
    "    max_score = -999*(n + m)\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            score = [alignment_matrix[i-1][j-1] + [-2, 1][seq1[i-1] == seq2[j-1]], alignment_matrix[i-1][j] - 2, alignment_matrix[i][j-1] - 2]\n",
    "            alignment_matrix[i][j] = max(score)\n",
    "            direction_matrix[i][j] = score.index(alignment_matrix[i][j])\n",
    "\n",
    "            if i == n or j == m:\n",
    "                if alignment_matrix[i][j] > max_score:\n",
    "                    max_score = alignment_matrix[i][j]\n",
    "                    max_index = (i, j)\n",
    "    print('alignment_matrix: final\\n', pd.DataFrame(alignment_matrix))\n",
    "    print('direction_matrix: final\\n', pd.DataFrame(direction_matrix))\n",
    "    i, j = max_index\n",
    "    print('max_index: i, j:', i, j)\n",
    "    \n",
    "    seq1_aligned, seq2_aligned = seq1[:i], seq2[:j]\n",
    "    add_indel = lambda seq2ord, i: seq2ord[:i] + '-' + seq2ord[i:]\n",
    "    while i*j != 0:\n",
    "        if direction_matrix[i][j] == 1:\n",
    "            i -= 1\n",
    "            seq2_aligned = add_indel(seq2_aligned, j)\n",
    "        elif direction_matrix[i][j] == 2:\n",
    "            j -= 1\n",
    "            seq1_aligned = add_indel(seq1_aligned, i)\n",
    "        else:\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "    seq1_aligned, seq2_aligned = seq1_aligned[i:], seq2_aligned[j:]\n",
    "    \n",
    "    return max_score, seq1_aligned, seq2_aligned\n",
    "\n",
    "\n",
    "def align_globally_with_affinity_gap_penalty(seq1, seq2, score_matrix, labels, gap_penalty, extension_penalty):\n",
    "    n, m = len(seq1), len(seq2)\n",
    "    print('get_edit_distance: n, m:', n, m)\n",
    "    \n",
    "    alignment_matrices = [[[0 for j in range(m + 1)]for i in range(n + 1)] for num_m in range(3)]\n",
    "    direction_matrices = [[[0 for j in range(m + 1)]for i in range(n + 1)] for num_m in range(3)]    \n",
    "    \n",
    "    # 0: , 1: , and 2: \n",
    "    for i in range(1, n + 1):\n",
    "        alignment_matrices[0][i][0] = - gap_penalty - (i - 1) * extension_penalty\n",
    "        alignment_matrices[1][i][0] = - gap_penalty - (i - 1) * extension_penalty\n",
    "        alignment_matrices[2][i][0] = -10 * gap_penalty\n",
    "    for j in range(1, m + 1):\n",
    "        alignment_matrices[2][0][j] = - gap_penalty - (j - 1) * extension_penalty\n",
    "        alignment_matrices[1][0][j] = - gap_penalty - (j - 1) * extension_penalty\n",
    "        alignment_matrices[0][0][j] = -10 * gap_penalty\n",
    "    print('alignment_matrices: fresh\\n', pd.DataFrame(alignment_matrices))\n",
    "    print('direction_matrices: fresh\\n', pd.DataFrame(direction_matrices))\n",
    "    \n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            vs = [alignment_matrices[0][i - 1][j] - extension_penalty, alignment_matrices[1][i - 1][j] - gap_penalty]\n",
    "            alignment_matrices[0][i][j] = max(vs)\n",
    "            direction_matrices[0][i][j] = vs.index(alignment_matrices[0][i][j])\n",
    "            \n",
    "            hs = [alignment_matrices[2][i][j - 1] - extension_penalty, alignment_matrices[1][i][j - 1] - gap_penalty]\n",
    "            alignment_matrices[2][i][j] = max(hs)\n",
    "            direction_matrices[2][i][j] = hs.index(alignment_matrices[2][i][j])\n",
    "                               \n",
    "            ms = [alignment_matrices[0][i][j], alignment_matrices[1][i - 1][j - 1] + score_matrix[labels.index(seq1[i-1])][labels.index(seq2[j-1])], alignment_matrices[2][i][j]]\n",
    "            alignment_matrices[1][i][j] = max(ms)\n",
    "            direction_matrices[1][i][j] = ms.index(alignment_matrices[1][i][j])\n",
    "            \n",
    "    i, j = n, m\n",
    "    seq1_aligned, se2_aligned = seq1, seq2\n",
    "    #print('alignment_matrices: final\\n', pd.DataFrame(alignment_matrices))\n",
    "    #print('direction_matrices: final\\n', pd.DataFrame(direction_matrices))\n",
    "\n",
    "    s = [alignment_matrices[x][i][j] for x in range(3)]\n",
    "    max_score = max(s)\n",
    "    back = s.index(max_score)\n",
    "    \n",
    "    add_indel = lambda seq, i: seq[:i] + '-' + seq[i:]\n",
    "\n",
    "    while i > 0 and j > 0:\n",
    "        if back == 0:\n",
    "            if direction_matrices[0][i][j] == 1:\n",
    "                back = 1\n",
    "            i -= 1\n",
    "            seq2_aligned = add_indel(seq2, j)\n",
    "            \n",
    "        elif back == 1:\n",
    "            if direction_matrices[1][i][j] == 0:\n",
    "                back = 0\n",
    "            elif direction_matrices[1][i][j] == 2:\n",
    "                back = 2\n",
    "            else:\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "        else:\n",
    "            if direction_matrices[2][i][j] == 1:\n",
    "                back = 1\n",
    "            j -= 1\n",
    "            seq1_aligned = add_indel(seq1, i)    \n",
    "            \n",
    "    for x in range(i):\n",
    "        seq2_aligned = add_indel(seq2_aligned, 0)\n",
    "    for x in range(j):\n",
    "        seq1_aligned = add_indel(seq1_aligned, 0)\n",
    "    \n",
    "    return max_score, seq1_aligned, seq2_aligned\n",
    "\n",
    "\n",
    "def align_multiple_seq(seq1, seq2, seq3):\n",
    "\n",
    "    n, m, k = len(seq1), len(seq2), len(seq3)\n",
    "    alignment_matrix = [[[0 for k in range(k+1)] for j in range(m+1)] for i in range(n+1)]\n",
    "    direction_matrix = [[[0 for k in range(k+1)] for j in range(m+1)] for i in range(n+1)]\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            for k in range(1, k+1):\n",
    "                s = [alignment_matrix[i-1][j-1][k-1] + int(seq1[i-1] == seq2[j-1] == seq3[k-1]), alignment_matrix[i-1][j][k], alignment_matrix[i][j-1][k], alignment_matrix[i][j][k-1], alignment_matrix[i-1][j][k-1], alignment_matrix[i][j-1][k-1]]\n",
    "                direction_matrix[i][j][k], alignment_matrix[i][j][k] = max(enumerate(s), key=lambda p: p[1])\n",
    "\n",
    "    inalignment_matrixert_indel = lambda seq2ord, i: seq2ord[:i] + '-' + seq2ord[i:]\n",
    "    seq1_aligned, seq2_aligned, seq3_aligned = seq1, seq2, seq3\n",
    "\n",
    "    i, j, k = len(seq1), len(seq2), len(seq3)\n",
    "    max_score = alignment_matrix[i][j][k]\n",
    "\n",
    "    while i*j*k != 0:\n",
    "        if direction_matrix[i][j][k] == 1:\n",
    "            i -= 1\n",
    "            seq2_aligned = inalignment_matrixert_indel(seq2_aligned, j)\n",
    "            seq3_aligned = inalignment_matrixert_indel(seq3_aligned, k)\n",
    "        elif direction_matrix[i][j][k] == 2:\n",
    "            j -= 1\n",
    "            seq1_aligned = inalignment_matrixert_indel(seq1_aligned, i)\n",
    "            seq3_aligned = inalignment_matrixert_indel(seq3_aligned, k)\n",
    "        elif direction_matrix[i][j][k] == 3:\n",
    "            k -= 1\n",
    "            seq1_aligned = inalignment_matrixert_indel(seq1_aligned, i)\n",
    "            seq2_aligned = inalignment_matrixert_indel(seq2_aligned, j)\n",
    "        elif direction_matrix[i][j][k] == 4:\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "            seq3_aligned = inalignment_matrixert_indel(seq3_aligned, k)\n",
    "        elif direction_matrix[i][j][k] == 5:\n",
    "            i -= 1\n",
    "            k -= 1\n",
    "            seq2_aligned = inalignment_matrixert_indel(seq2_aligned, j)\n",
    "        elif direction_matrix[i][j][k] == 6:\n",
    "            j -= 1\n",
    "            k -= 1\n",
    "            seq1_aligned = inalignment_matrixert_indel(seq1_aligned, i)\n",
    "        else:\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "            k -= 1\n",
    "\n",
    "    while len(seq1_aligned) != max(len(seq1_aligned),len(seq2_aligned),len(seq3_aligned)):\n",
    "        seq1_aligned = inalignment_matrixert_indel(seq1_aligned, 0)\n",
    "    while len(seq2_aligned) != max(len(seq1_aligned),len(seq2_aligned),len(seq3_aligned)):\n",
    "        seq2_aligned = inalignment_matrixert_indel(seq2_aligned, 0)\n",
    "    while len(seq3_aligned) != max(len(seq1_aligned),len(seq2_aligned),len(seq3_aligned)):\n",
    "        seq3_aligned = inalignment_matrixert_indel(seq3_aligned, 0)\n",
    "\n",
    "    return max_score, seq1_aligned, seq2_aligned, seq3_aligned\n",
    "\n",
    "\n",
    "def read_mtrx(matrix_filename):\n",
    "    with open(matrix_filename) as f:\n",
    "        # Read the entire file content\n",
    "        content = f.read()\n",
    "        # Split the file's content by <delimiter>\n",
    "        lines2 = content.split('\\n')\n",
    "        # Be careful about lines containing only ''\n",
    "        lines2 = [i for i in lines2 if i != '']\n",
    "        assert is_uniform_list_of_lists(lines2)\n",
    "\n",
    "    labels = lines2[0].split()\n",
    "    rows = []\n",
    "    for line in lines2[1:]:\n",
    "        trimmed = line.split()[1:]\n",
    "        rows.append([int(i) for i in trimmed])\n",
    "\n",
    "    assert is_uniform_list_of_lists(rows)\n",
    "    print(pd.DataFrame(rows, index=labels, columns=labels))\n",
    "\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def format_input(ccs):\n",
    "    return [list(map(int, cc.split())) for cc in (ccs[1:-1].split(')('))]\n",
    "\n",
    "\n",
    "def format_output(list_of_lines):\n",
    "    for line in list_of_lines:\n",
    "        print('(' + ' '.join([['', '+'][n > 0] + str(n) for n in line]) + ')')\n",
    "\n",
    "\n",
    "def reverse_negate_interval(seq, i, j):\n",
    "    assert i <= j, 'i = %s & j = %s' % (i, j)\n",
    "    \n",
    "    before_i = seq[:i] # Not including i\n",
    "    after_j = seq[j + 1:] # Not including j\n",
    "    i_to_j = seq[i:j + 1] # i to j incluisve\n",
    "    i_to_j_reversed_negated = [-1 * n for n in reversed(i_to_j)]\n",
    "    return before_i + i_to_j_reversed_negated + after_j\n",
    "\n",
    "\n",
    "def reverse_sort_greedily(permutation):\n",
    "    sorted_permutations = []\n",
    "    \n",
    "    index_ = lambda list_, n: list(map(abs, list_)).index(n)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(permutation):\n",
    "        if permutation[i] == i + 1:\n",
    "            i += 1\n",
    "        else:\n",
    "            permutation = reverse_negate_interval(permutation, i, index_(permutation, i + 1))\n",
    "            sorted_permutations.append(permutation)\n",
    "    return sorted_permutations\n",
    "\n",
    "\n",
    "def count_breaking_points(permutation):\n",
    "    c = 0\n",
    "    prev = 0\n",
    "    for n in permutation:\n",
    "        if prev + 1 != n:\n",
    "            c += 1\n",
    "        prev = n\n",
    "    return c\n",
    "\n",
    "\n",
    "def get_2break_distance(ccs1, ccs2):\n",
    "    from collections import defaultdict\n",
    "\n",
    "    graph = defaultdict(list)\n",
    "    for cycle in ccs1 + ccs2:\n",
    "        L = len(cycle)\n",
    "        for i in range(len(cycle)):\n",
    "            graph[cycle[i]].append(-1*cycle[(i+1) % L])\n",
    "            graph[-1*cycle[(i+1) % L]].append(cycle[i])\n",
    "\n",
    "    nc = 0\n",
    "    remaining = set(graph.keys())\n",
    "    while len(remaining) > 0:\n",
    "        nc += 1\n",
    "        queue = [remaining.pop()]\n",
    "        while queue:\n",
    "            current = queue.pop(0)\n",
    "            queue += filter(lambda node: node in remaining, graph.get(current, []))\n",
    "            remaining -= set(queue)\n",
    "\n",
    "    return sum(map(len,P)) - nc\n",
    "\n",
    "\n",
    "def get_shared_kmer(seq1, seq2, k):\n",
    "    from collections import defaultdict\n",
    "    seq1_dict = defaultdict(list)\n",
    "    for i in range(len(seq1)-k+1):\n",
    "        seq1_dict[seq1[i:i+k]].append(i)\n",
    "    return {(i,j) for j in range(len(seq2)-k+1) for i in seq1_dict[seq2[j:j+k]] + seq1_dict[reverse_complement(seq2[j:j+k])]}\n",
    "\n",
    "\n",
    "def convert_synteny_blocks_to_cycle(synteny_blocks):\n",
    "    nodes = [0 for i in range(2 * len(synteny_blocks))]\n",
    "    for i, n in enumerate(synteny_blocks):\n",
    "        if 0 < n:\n",
    "            nodes[2 * i] = 2 * n - 1\n",
    "            nodes[2 * i + 1] = 2 * n\n",
    "        else:\n",
    "            nodes[2 * i] = -2 * n\n",
    "            nodes[2 * i + 1] = -2 * n - 1\n",
    "    return nodes\n",
    "\n",
    "\n",
    "def convert_cycle_to_synteny_blocks(nodes):\n",
    "    synteny_blocks = [0 for i in range(int(1 / 2 * len(nodes)))]\n",
    "    for i, n in enumerate(nodes[::2]):\n",
    "        if (n / 2).is_integer():\n",
    "            synteny_blocks[i] = - int(n / 2)\n",
    "        else:\n",
    "            synteny_blocks[i] = int((n + 1) / 2)\n",
    "    return synteny_blocks\n",
    "\n",
    "\n",
    "def make_synteny_block_graph(list_of_synteny_blocks):\n",
    "    edges = []\n",
    "    for synteny_blocks in list_of_synteny_blocks:\n",
    "        nodes = convert_synteny_blocks_to_cycle(synteny_blocks)\n",
    "        nodes.append(nodes[0])\n",
    "        #print('nodes:', nodes)\n",
    "        for i, n in enumerate(nodes):\n",
    "            if i % 2 == 1:\n",
    "                #print(i, n)\n",
    "                edges.append((n, nodes[i + 1]))\n",
    "    return edges\n",
    "\n",
    "\n",
    "def break_synteny_block_graph(synteny_block_graph_edges):\n",
    "    synteny_block_edges = dict()\n",
    "    for from_, to_ in synteny_block_graph_edges:\n",
    "        from_sign = [- 1, + 1][from_ % 2 == 0]\n",
    "        to_sign = [+ 1, - 1][to_ % 2 == 0]\n",
    "        from_v = int((from_ - 1) / 2) + 1\n",
    "        to_v = int((to_ - 1) / 2) + 1\n",
    "        #print(from_sign * from_v, to_sign * to_v)\n",
    "        synteny_block_edges[from_sign * from_v] = to_sign * to_v\n",
    "        \n",
    "    cycles = []\n",
    "    visited = []\n",
    "    current_from = list(synteny_block_edges.keys())[0]\n",
    "    visited.append(current_from)\n",
    "    while len(synteny_block_edges) > 0:\n",
    "        #print('current_from:', current_from)\n",
    "        current_to = synteny_block_edges.pop(current_from)\n",
    "        #print('current_to:', current_to)\n",
    "        if current_to in visited:\n",
    "            cycles.append(visited)\n",
    "            #print('visited:', visited)\n",
    "            visited = []\n",
    "            keys = list(synteny_block_edges.keys())\n",
    "            if len(keys) == 0:\n",
    "                break\n",
    "            current_from = keys[0]\n",
    "            visited.append(current_from)\n",
    "        else:\n",
    "            visited.append(current_to)\n",
    "            current_from = current_to\n",
    "\n",
    "    return [sorted(c, key=abs) for c in cycles]\n",
    "\n",
    "\n",
    "def fff(synteny_block_graph_edges, a1, a2, b1, b2):\n",
    "    to_return = []\n",
    "    f = set([a1, a2, b1, b2])\n",
    "    #print(f)\n",
    "    for e in synteny_block_graph_edges:\n",
    "        #print(set(v for v in e))\n",
    "        if len(f & set(v for v in e)) == 0:\n",
    "            to_return.append(e)\n",
    "            #print('!')\n",
    "    to_return.append((a1, b1))\n",
    "    to_return.append((a2, b2))\n",
    "    return to_return\n",
    "\n",
    "\n",
    "def ggg(genome, a1, a2, b1, b2):\n",
    "    v = convert_synteny_blocks_to_cycle(genome)\n",
    "    print(v)\n",
    "    vv = make_synteny_block_graph([v])\n",
    "    print(vv)\n",
    "    vvv = fff(vv, a1, a2, b1, b2)\n",
    "    return break_synteny_block_graph(vvv)\n",
    "'''\n",
    "raw = lines[0]\n",
    "split = raw.split(')')\n",
    "input_ = [(int(i[0]), int(i[1])) for i in [s.split(',') for s in [s.split('(')[1] for s in split if s != ''] if s != '']]\n",
    "\n",
    "b = fff(input_, 74, 75, 87, 89)\n",
    "', '.join(str(s) for s in b)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_trie(trie):\n",
    "    for k, v in trie.items():\n",
    "        if len(v) == 0:\n",
    "            continue\n",
    "        for vv in v:\n",
    "            print('%s->%s:%s' % (k, *vv))\n",
    "            \n",
    "            \n",
    "def make_trie(sequences):\n",
    "    \"\"\"\n",
    "    TRIECONSTRUCTION\n",
    "    \n",
    "    \"\"\"\n",
    "    trie = dict()\n",
    "    \n",
    "    # Root\n",
    "    c = 0\n",
    "    trie[c] = []\n",
    "    \n",
    "    for seq in sequences:\n",
    "        seq = seq + '$'\n",
    "        #print('seq:', seq)\n",
    "        # Each sequence starts form root\n",
    "        cur_n = 0\n",
    "        for nuc in seq:\n",
    "            #print('cur_n, nuc:', cur_n, nuc)\n",
    "            next_n = [n for n, e in trie[cur_n] if e == nuc]\n",
    "            assert len(next_n) < 2\n",
    "            #print('next_n:', next_n)\n",
    "            if len(next_n) == 0: # There isn't any edge with ID cur_n\n",
    "                # Create new node\n",
    "                c += 1\n",
    "                trie[c] = []\n",
    "                # Add this new node as successor of the current node\n",
    "                trie[cur_n].append((c, nuc))\n",
    "                # Update the current node to be the new node\n",
    "                if nuc != '$':\n",
    "                    cur_n = c\n",
    "            elif nuc != '$': # There is an edge with ID cur_n\n",
    "                # Go to the successor\n",
    "                cur_n = next_n[0]\n",
    "    return trie\n",
    "\n",
    "\n",
    "'''\n",
    "def get_trie_match(sequence, trie):\n",
    "    i = 0\n",
    "    nuc = sequence[i]\n",
    "    cur_n = 0\n",
    "    while True:\n",
    "        if len(trie[cur_n]) == 0:\n",
    "            return 'LEAF'\n",
    "        else:\n",
    "            next_n = [n for n, e in trie[cur_n] if e == nuc]\n",
    "            if len(next_n) > 0:\n",
    "                nuc = sequence[i]\n",
    "                cur_n == next_n[0]\n",
    "            else:\n",
    "                print('no match')\n",
    "                return False\n",
    "'''\n",
    "\n",
    "\n",
    "def get_trie_match(sequence, trie):\n",
    "    return_ = explore_trie(0, sequence, trie)\n",
    "    #print('get_trie_match: return_:', return_)\n",
    "    if return_:\n",
    "        return return_[:-1]\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def explore_trie(from_n, sequence, trie):\n",
    "    #print('from_n:', from_n)\n",
    "    #print('sequence:', sequence)\n",
    "    \n",
    "    # Get out nodes of from_n\n",
    "    to_ns = trie[from_n]\n",
    "    #print('to_ns:', to_ns)\n",
    "    if '$' in [e for n, e in to_ns]: # Leaf\n",
    "        #print('$ in to_ns')\n",
    "        return '$'\n",
    "    \n",
    "    if not sequence:\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        nuc = sequence[0]\n",
    "        if nuc in [e for n, e in to_ns]: # Nucleotide edge found\n",
    "            cur_n = [n for n, e in to_ns if e == nuc][0]\n",
    "            #print('Updated cur_n:', cur_n)\n",
    "            #print('\\n')\n",
    "            recr = explore_trie(cur_n, sequence[1:], trie)\n",
    "            if recr:\n",
    "                return nuc + recr\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        \n",
    "def make_suffix_trie(sequences):\n",
    "    trie = make_trie(sequences)\n",
    "    print_trie(trie)\n",
    "    \n",
    "    stack = []\n",
    "    cur_n = 0\n",
    "    stack.append(cur_n)\n",
    "    while len(stack) > 0:\n",
    "        for path_n in trie[stack.pop()]:\n",
    "            print('popped:', path_n)\n",
    "            path_s = ''\n",
    "            path_s += path_n[1]\n",
    "            cur_n = path_n[0]\n",
    "            for next_path_n in trie[cur_n]:\n",
    "                print('next_path_n:', next_path_n)\n",
    "                stack.append(next_path_n[0])\n",
    "                \n",
    "            \n",
    "def make_suffix_trie_2(sequence):\n",
    "    trie = {}\n",
    "    next_n = 0\n",
    "    trie[next_n] = []\n",
    "    next_n += 1\n",
    "    for i in range(len(sequence)):\n",
    "        cur_n = 0\n",
    "        for j in range(i, len(sequence)):\n",
    "            cur_s = sequence[j]\n",
    "            print('cur_s:', cur_s)\n",
    "            if cur_s == '$':\n",
    "                \n",
    "                continue\n",
    "            if cur_s in [e for n, e, s in trie[cur_n]]:\n",
    "                cur_n = [n for n, e, s in trie[cur_n]][0]\n",
    "            else:\n",
    "                print('%s --(%s, %s)--> %s' % (cur_n, cur_s, j, next_n))\n",
    "                trie[next_n] = []\n",
    "                trie[cur_n].append((next_n, cur_s, j))\n",
    "                print('trie[cur_n]: after append:', trie[cur_n])\n",
    "                cur_n = next_n\n",
    "                next_n += 1\n",
    "        print('%s --(%s, %s, %s)--> %s' % (cur_n, '$', j, i, next_n))\n",
    "        trie[cur_n].append((next_n, '$', j, i))\n",
    "        next_n += 1\n",
    "    return trie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_suffix_array(sequence):\n",
    "    \"\"\"\n",
    "    Make a suffix array.\n",
    "    \"\"\"\n",
    "    if sequence[-1] != '$':\n",
    "        sequence += '$'\n",
    "    a = []\n",
    "    for i in range(len(sequence)):\n",
    "        a.append((i, sequence[i:]))\n",
    "    a = sorted(a, key=lambda x: x[1])\n",
    "    return a\n",
    "\n",
    "\n",
    "def match_suffix_array(kmer, sequence):\n",
    "    \"\"\"\n",
    "    Make a suffix array and return its indices at which a suffix starts with <kmer>.\n",
    "    \"\"\"\n",
    "    a = make_suffix_array(sequence)\n",
    "    return [i for i, s in a if s.startswith(kmer)]\n",
    "\n",
    "\n",
    "def trim_suffix_array(k, suffix_array):\n",
    "    \"\"\"\n",
    "    Trim a suffix_array by keeping indices that are multiple of <k>.\n",
    "    \"\"\"\n",
    "    return [(i, t[0]) for i, t in enumerate(suffix_array) if t[0] % k == 0]\n",
    "\n",
    "\n",
    "def cyclic_rotate_sequence(seq):\n",
    "    \"\"\"\n",
    "    Return sequences that result from cyclically rotating <seq>.\n",
    "    \"\"\"\n",
    "    return [seq[len(seq) - i:] + seq[0:len(seq) - i] for i in range(len(seq))]\n",
    "\n",
    "\n",
    "def get_bwa(seq):\n",
    "    \"\"\"\n",
    "    Return the BWA of <seq>.\n",
    "    \"\"\"\n",
    "    return [s[-1] for s in sorted(cyclic_rotate_sequence(seq))]\n",
    "\n",
    "\n",
    "def get_number_of_occurences_up_to_index(index, sequence):\n",
    "    \"\"\"\n",
    "    Get the number of occurences <sequecne>[<index>] appears up to and inlcuding <index>.\n",
    "    \"\"\"\n",
    "    # Get the value at index\n",
    "    value = sequence[index]\n",
    "    \n",
    "    count = 0\n",
    "    for v in sequence[:index + 1]:\n",
    "        if v == value:\n",
    "            count += 1\n",
    "    return count\n",
    "            \n",
    "    \n",
    "def get_ith_occuring_index(value, i, sequence):\n",
    "    \"\"\"\n",
    "    Get the index at which <value> appears for the <i>th time.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for j, v in enumerate(sequence):\n",
    "        if v == value:\n",
    "            count += 1\n",
    "        if count == i:\n",
    "            return j\n",
    "    raise ValueError(\"'{}' does not occure {} times in {}\".format(value, i, sequence))\n",
    "\n",
    "\n",
    "def get_ith_occuring_sequence2_index_of_ith_occuring_sequence1_val(i, sequence1, sequence2):\n",
    "    \"\"\"\n",
    "    Get the <i>th occuring <sequence2> index for the <i>th occuring value in <sequence1>.\n",
    "    \"\"\"\n",
    "    # Get value at <i>\n",
    "    val = sequence1[i]\n",
    "    # Get how many times <val> appears up to and including index <i> in <sequence1>\n",
    "    num_occurences_up_to_i = get_number_of_occurences_up_to_index(i, sequence1)\n",
    "    # Get <num_occurences_up_to_i>th occurence of <val> in <sequence2>\n",
    "    return get_ith_occuring_index(val, num_occurences_up_to_i, sequence2)\n",
    "\n",
    "\n",
    "def make_sequence_from_bwt(bwt):\n",
    "    \"\"\"\n",
    "    Reconstruct a sequene from its <bwt>.\n",
    "    \"\"\"\n",
    "    # Get column 1 by sorting <bwt>\n",
    "    col1 = sorted(bwt)\n",
    "\n",
    "    sequence = ''\n",
    "    # Start from $, the end\n",
    "    bwt_idx = bwt.index('$')\n",
    "    start_idx = bwt_idx\n",
    "    while True:\n",
    "        # Get the <btw_idx>th value in <col1>\n",
    "        col1_nuc = col1[bwt_idx]\n",
    "        sequence += col1_nuc\n",
    "        \n",
    "        # Get the number of occurences of <col1_nuc> up to and inclduing <btw_idx>th index\n",
    "        num_occurences_up_to_bwt_idx = get_number_of_occurences_up_to_index(bwt_idx, col1)\n",
    "        \n",
    "        # Get <num_occurences_up_to_bwt_idx>th occurence of <col1_nuc> in <bwt>\n",
    "        bwt_idx = get_ith_occurence_index(col1_nuc, num_occurences_up_to_bwt_idx, bwt)\n",
    "        \n",
    "        # Return sequence if back to $\n",
    "        if bwt_idx == start_idx:\n",
    "            return sequence\n",
    "        \n",
    "        \n",
    "def get_first_col1_occurences_of_bwt(bwt):\n",
    "    col1 = sorted(bwt)\n",
    "    first_col1_occurences_of_bwt = {}\n",
    "    cur_v = None\n",
    "    for i, v in enumerate(col1):\n",
    "        if v != cur_v:\n",
    "            print(i)\n",
    "            cur_v = v\n",
    "\n",
    "\n",
    "def track_element_occurenes_in_bwt(bwt):\n",
    "    elem_occurence = {}\n",
    "    for e in set(bwt):\n",
    "        c = 0\n",
    "        elem_occurence[e] = [c for i in range(len(bwt))]\n",
    "        for i, ee in enumerate(bwt):\n",
    "            if ee == e:\n",
    "                c += 1\n",
    "            elem_occurence[e][i] = c\n",
    "    return elem_occurence\n",
    "\n",
    "\n",
    "def match_kmer(sequence, kmers, sequence_is_btw=False):\n",
    "    #print('sequence:', sequence)\n",
    "    #print('kmers:', kmers)\n",
    "\n",
    "    # Get BWT O(n)\n",
    "    if sequence_is_btw:\n",
    "        bwt = [n for n in sequence]\n",
    "    else:\n",
    "        bwt = [n for n in get_bwa(sequence)]\n",
    "    #print('\\nbwt:', bwt)\n",
    "\n",
    "    # Get the 1st column O(nlogn)\n",
    "    col1 = sorted(bwt)\n",
    "    #print('col1:', col1)\n",
    "\n",
    "    # Make a map of indices of matching <bwt> index and <col1> index\n",
    "    map_bwt_to_col1 = {}\n",
    "    for i in range(len(bwt)):\n",
    "        map_bwt_to_col1[i] = get_ith_occuring_sequence2_index_of_ith_occuring_sequence1_val(i, bwt, col1)\n",
    "    #print('\\nmap_bwt_to_col1:', map_bwt_to_col1)\n",
    "\n",
    "    num_occurences = []\n",
    "    occuring_indices = set()\n",
    "    \n",
    "    # For each kmer\n",
    "    for kmer in kmers:\n",
    "        found = True\n",
    "        \n",
    "        # Define search scope\n",
    "        col1_idx_first = 0\n",
    "        col1_idx_last = len(bwt) - 1\n",
    "        #print('col1_idx_first, col1_idx_last:', col1_idx_first, col1_idx_last)\n",
    "\n",
    "        #while col1_idx_first <= col1_idx_last:\n",
    "        while kmer:\n",
    "            popped = kmer.pop()\n",
    "            #print('\\nkmer, popped:', kmer, popped)\n",
    "            # Get all occurences of <popped> in <bwt>\n",
    "            popped_indices_in_bwt = [col1_idx_first + i for i, n in enumerate(bwt[col1_idx_first:col1_idx_last + 1]) if n == popped]\n",
    "            #print('\\npopped_indices_in_bwt:', popped_indices_in_bwt)\n",
    "            if popped_indices_in_bwt:\n",
    "\n",
    "                bwt_idx_first = popped_indices_in_bwt[0]\n",
    "                bwt_idx_last = popped_indices_in_bwt[-1]\n",
    "                #print('bwt_idx_first, bwt_idx_last:', bwt_idx_first, bwt_idx_last)\n",
    "\n",
    "                col1_idx_first = map_bwt_to_col1[bwt_idx_first]\n",
    "                col1_idx_last = map_bwt_to_col1[bwt_idx_last]\n",
    "                #print('col1_idx_first, col1_idx_last:', col1_idx_first, col1_idx_last)\n",
    "            else:\n",
    "                num_occurences.append(0)\n",
    "                found = False\n",
    "                break\n",
    "\n",
    "        if found:\n",
    "            num_occurences.append(col1_idx_last + 1 - col1_idx_first)\n",
    "            for i in range(col1_idx_first, col1_idx_last + 1):\n",
    "                occuring_indices.add(i)\n",
    "\n",
    "    sfx_array = make_suffix_array(sequence)\n",
    "        \n",
    "    return num_occurences, [sfx_array[i][0] for i in occuring_indices]\n",
    "\n",
    "\n",
    "sequence = lines[0]#'panamabananas$'\n",
    "sequence += '$'\n",
    "B = ' '.join(lines[1:]) #\n",
    "kmers = [list(kmer) for kmer in (B.split(' '))]\n",
    "matches = match_kmer(sequence, kmers, sequence_is_btw=False)\n",
    "print(' '.join(sorted((str(i) for i in matches[1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Chapter 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_data_points(points_line, dictionarize=False):\n",
    "    points = []\n",
    "    for p in points_line:\n",
    "        points.append(tuple(float(i) for i in p.split(' ') if i))\n",
    "    if dictionarize:\n",
    "        points = dict(zip(range(0, len(points)), points))\n",
    "    return points\n",
    "\n",
    "\n",
    "def get_euclidean_distance(p1, p2):\n",
    "    assert len(p1) == len(p2), '{} and {} must have the same dimension'.format(p1, p2)\n",
    "    sqrd_diff_per_dim = []\n",
    "    for dim, val1 in enumerate(p1):\n",
    "        sqrd_diff_per_dim.append(math.pow(val1 - p2[dim], 2))\n",
    "    return math.sqrt(sum(sqrd_diff_per_dim))\n",
    "    \n",
    "\n",
    "# TODO: remove center added\n",
    "def cluster_furthest(num_centers, points):\n",
    "    points = make_data_points(points)\n",
    "    print('points:', points)\n",
    "    \n",
    "    centers = []\n",
    "    centers.append(random.choice(range(0, points)))\n",
    "    print('initial centers:', centers)\n",
    "    \n",
    "    min_dist_to_a_center = [None for i in range(len(points))]\n",
    "    while len(centers) < num_centers:\n",
    "        for i, p in enumerate(points):\n",
    "            min_dist_to_a_center[i] = min((get_euclidean_distance(c, p) for c in centers))\n",
    "        print('min_dist_to_a_center:', min_dist_to_a_center)\n",
    "        \n",
    "        centers.append(points[min_dist_to_a_center.index(max(min_dist_to_a_center))])\n",
    "        print('updated centers:', centers)\n",
    "        print()\n",
    "\n",
    "    return centers\n",
    "\n",
    "\n",
    "def print_points(points):\n",
    "    for p in points:\n",
    "        print(' '.join(('{0:.3f}'.format(i) for i in p)))\n",
    "\n",
    "\n",
    "def calculate_cluster_distortion(points, centers):\n",
    "    points = make_data_points(points, dictionarize=False)\n",
    "    #print('points:', points)\n",
    "    \n",
    "    num_points = len(points)\n",
    "    #print('num_points:', num_points)\n",
    "    \n",
    "    centers = make_data_points(centers, dictionarize=False)\n",
    "    #print('centers:', centers)\n",
    "    \n",
    "    min_distances = []\n",
    "    for coord in points:\n",
    "        #print('coord:', coord)\n",
    "        distances = []\n",
    "        for c in centers:\n",
    "            distances.append(get_euclidean_distance(coord, c))\n",
    "        min_distances.append(min(distances))\n",
    "        #print('min_distances:', min_distances)\n",
    "    \n",
    "    return sum((math.pow(v, 2) for v in min_distances)) / num_points\n",
    "\n",
    "\n",
    "def assign_clusters(points, centers):\n",
    "    # Assign each data point to the cluster corresponding to its nearest center\n",
    "    cluster_assignments = [None for i in range(len(points))]  # List of integers, <points> indices\n",
    "    for i, p in enumerate(points):\n",
    "        min_distance = get_euclidean_distance(p, centers[0])\n",
    "        min_center_idx = 0\n",
    "        for ii, c in enumerate(centers[1:]):\n",
    "            dist = get_euclidean_distance(p, c)\n",
    "            if dist < min_distance:\n",
    "                min_distance = dist\n",
    "                min_center_idx = ii + 1\n",
    "        cluster_assignments[i] = min_center_idx\n",
    "    return cluster_assignments\n",
    "\n",
    "\n",
    "def update_centers(points, cluster_assignments, k):\n",
    "    num_points = len(points)\n",
    "    \n",
    "    # Separate clustering points\n",
    "    clusters = {}\n",
    "    for i, c in enumerate(cluster_assignments):\n",
    "        if c not in clusters:\n",
    "            clusters[c] = [points[i]]\n",
    "        else:\n",
    "            clusters[c].append(points[i])\n",
    "    print('clusters:', clusters)\n",
    "    \n",
    "    # Compute new centers\n",
    "    centers = [[None for ii in range(len(points[0]))] for i in range(k)]\n",
    "    print('empty centers:', centers)\n",
    "    \n",
    "    # For each cluster, compute a new center\n",
    "    for c, clustering_points in clusters.items():\n",
    "        print('c, clustering_points:', c, clustering_points)\n",
    "        # Sum dimension coordinates\n",
    "        dimension_sum = {}  # key = dimension; value = dimension sum\n",
    "        for p in clustering_points:\n",
    "            for dim, coord in enumerate(p):\n",
    "                if dim not in dimension_sum:\n",
    "                    dimension_sum[dim] = coord\n",
    "                else:\n",
    "                    dimension_sum[dim] += coord\n",
    "        \n",
    "        print('dimension_sum:', dimension_sum)\n",
    "        \n",
    "        for dim, sum_ in dimension_sum.items():\n",
    "            print('centers:', centers)\n",
    "            centers[c][dim] = sum_ / num_points\n",
    "    \n",
    "    return centers\n",
    "        \n",
    "        \n",
    "def cluster_lloyd(k, points):\n",
    "    points = make_data_points(points)  # List of point coordinates\n",
    "\n",
    "    cur_centers = random.sample(points, k)  # List of point coordinates\n",
    "    print('cur_centers:', cur_centers)\n",
    "    \n",
    "    while True:\n",
    "        cluster_assignments = assign_clusters(points, cur_centers)\n",
    "        #print('cluster_assignments:', cluster_assignments)\n",
    "\n",
    "        new_centers = update_centers(points, cluster_assignments, k)\n",
    "        print('new_centers:', new_centers)\n",
    "        \n",
    "        \n",
    "        # If the centers stop changing, exit\n",
    "        if cur_centers == new_centers:\n",
    "            return cur_centers\n",
    "        else:\n",
    "            cur_centers = new_centers\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_input_edges(edge_list):\n",
    "    \"\"\"\n",
    "    Read lines like: from->to:weight as dictionary {from:[(to, weight)]}.\n",
    "    \"\"\"\n",
    "    edges = {}\n",
    "    for line in edge_list:\n",
    "        from_, to_and_weight = line.split('->')\n",
    "        to_, weight = to_and_weight.split(':')\n",
    "        from_ = int(from_)\n",
    "        to_ = int(to_)\n",
    "        weight = int(weight)\n",
    "        \n",
    "        if from_ not in edges:\n",
    "            edges[from_] = [(to_, weight)]\n",
    "        else:\n",
    "            edges[from_].append((to_, weight))\n",
    "    return edges\n",
    "\n",
    "\n",
    "def get_leaves(edges):\n",
    "    \"\"\"\n",
    "    Get leaves, which has 1 neighbor.\n",
    "    \"\"\"\n",
    "    leaves = []\n",
    "    for from_, to_weight in edges.items():\n",
    "        if len(to_weight) == 1:\n",
    "            leaves.append(from_)\n",
    "    return leaves\n",
    "\n",
    "\n",
    "def get_distance_between_leaves(from_node, to_node, edges):\n",
    "    \"\"\"\n",
    "    Get distance between 2 nodes.\n",
    "    \"\"\"\n",
    "    #print('Getting the distance from {} to {}'.format(from_node, to_node))\n",
    "    \n",
    "    visited = []\n",
    "    stack = [(from_node, 0)]\n",
    "\n",
    "    while len(stack) != 0:\n",
    "        cur_n, cur_d = stack.pop()\n",
    "        #print('cur_n, cur_d:', cur_n, cur_d)\n",
    "        \n",
    "        if cur_n == to_node:\n",
    "            return cur_d\n",
    "        elif cur_n in visited:\n",
    "            continue\n",
    "        else:\n",
    "            visited.append(cur_n)\n",
    "\n",
    "        for to_n, to_d in edges[cur_n]:\n",
    "            #print('to:', to_n, to_d)\n",
    "            stack.append((to_n, to_d + cur_d))\n",
    "            \n",
    "            \n",
    "def make_leaf_distance_matrix(lines):\n",
    "    \"\"\"\n",
    "    Distances Between Leaves Problem\n",
    "    \n",
    "    Make lead distance matrix from edge lines like from->to:weight.\n",
    "    \"\"\"\n",
    "    #print('lines:', lines)\n",
    "    edges = read_input_edges(lines)\n",
    "    #print('edges:', edges)\n",
    "    leaves = get_leaves(edges)\n",
    "    #print('leaves:', leaves)\n",
    "\n",
    "    for from_leaf in leaves:\n",
    "        #print('from_leaf', from_leaf)\n",
    "        row = []\n",
    "        for to_leaf in leaves:\n",
    "            #print('to_leaf:', to_leaf)\n",
    "            if to_leaf == from_leaf:\n",
    "                row.append(0)\n",
    "            else:\n",
    "                row.append(get_distance(from_leaf, to_leaf, edges))\n",
    "        print(' '.join([str(i) for i in row]))\n",
    "\n",
    "        \n",
    "def get_limb_length(mtrx, leaf_n):\n",
    "    \"\"\"\n",
    "    Limb Length\n",
    "    \n",
    "    Get the length of a leaf node to its parent node.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read matrix\n",
    "    #print('mtrx: {}'.format(mtrx))\n",
    "    \n",
    "    # Index leaves and remove\n",
    "    leaves = list(range(0, len(mtrx)))\n",
    "    leaves.remove(leaf_n)\n",
    "    #print('leaves:', leaves)\n",
    "    \n",
    "    min_ = 999999999\n",
    "    # For each pair of leaves excluding <leaf_n>\n",
    "    for l1, l2 in [i for i in itertools.combinations(leaves, 2)]:\n",
    "        # Compute the limb length\n",
    "        val = (int(mtrx[l1][leaf_n]) + int(mtrx[leaf_n][l2]) - int(mtrx[l1][l2])) / 2\n",
    "        # Look for the min limb length because of limb length theorem\n",
    "        if val < min_:\n",
    "            min_ = val\n",
    "    return int(min_)\n",
    "\n",
    "\n",
    "def make_phylogeny_tree_using_additive_method(distance_mtrx, n, idx):\n",
    "    print('distance_mtrx: {}\\nn: {}'.format(distance_mtrx, n))\n",
    "    \n",
    "    # Base case\n",
    "    if n == 1:\n",
    "        print('n is 1; 2 x 2 matrix: {}'.format(distance_mtrx))\n",
    "        assert distance_mtrx[0][1] == distance_mtrx[1][0]\n",
    "        print('RETURNING:', {0: [(1, distance_mtrx[0][1])], 1: [(0, distance_mtrx[1][0])]})\n",
    "        return {0: [(1, distance_mtrx[0][1])], 1: [(0, distance_mtrx[1][0])]}, idx\n",
    "    \n",
    "    # Get limb length of leaf n\n",
    "    limb_length = get_limb_length(distance_mtrx, n)\n",
    "    print('limb_length: {}'.format(limb_length))\n",
    "    \n",
    "    # Alimb_length non-n leaves\n",
    "    non_n_indices = list(range(0, len(distance_mtrx)))\n",
    "    non_n_indices.remove(n)\n",
    "    print('non_n_indices: {}'.format(non_n_indices))\n",
    "    \n",
    "    # Remove the impact of leaf n\n",
    "    for i in non_n_indices:\n",
    "        distance_mtrx[i][n] -= limb_length\n",
    "        distance_mtrx[n][i] = distance_mtrx[i][n]\n",
    "    print('distance_mtrx after updating distances: {}'.format(distance_mtrx))\n",
    "    \n",
    "    # Find l1 and l2 such that D(l1,l2) = D(l1,n) + D(n,l2)\n",
    "    for l1, l2 in [i for i in itertools.combinations(non_n_indices, 2)]:\n",
    "        if distance_mtrx[l1][l2] == distance_mtrx[l1][n] + distance_mtrx[n][l2]:\n",
    "            leaf1, leaf2 = l1, l2\n",
    "            break\n",
    "    print('l1 and l2: {} {}'.format(l1, l2))\n",
    "    \n",
    "    # Get the distance between l1 and n; this distance is used to attach leaf n later\n",
    "    attaching_point = distance_mtrx[l1][n]\n",
    "    print('attaching_point: {}'.format(attaching_point))\n",
    "    \n",
    "    '''\n",
    "    # Remove nth column\n",
    "    distance_mtrx = distance_mtrx[:n] + distance_mtrx[n + 1:]\n",
    "    # Remove nth row\n",
    "    for row in distance_mtrx:\n",
    "        row.pop(n)\n",
    "    print('distance_mtrx after removing n: {}'.format(distance_mtrx))\n",
    "    '''\n",
    "    \n",
    "    tree, idx = make_phylogeny_tree_using_additive_method([r[:-1] for r in distance_mtrx[:-1]], len(distance_mtrx) - 2, idx)\n",
    "    \n",
    "    # (current node, distacne to current node, previous node, distacne to previous node)\n",
    "    stack = [(l1, 0, None, None)]\n",
    "    visited = []\n",
    "    while True:\n",
    "        cur_n, cur_d, prev_n, prev_d = stack.pop()\n",
    "        print('popped:', cur_n, cur_d, prev_n, prev_d)\n",
    "        \n",
    "        if cur_n in visited:\n",
    "            continue\n",
    "        visited.append(cur_n)\n",
    "        if not can_reach(tree, cur_n, l2, visited):\n",
    "            print('{} cannot reach {}'.format(cur_n, l2))\n",
    "            continue\n",
    "            \n",
    "        if cur_d == attaching_point:\n",
    "            print('AT THE ATTACHING POINT')\n",
    "            tree[cur_n].append((n, limb_length))\n",
    "            print('{} --({})--> {}'.format(cur_n, limb_length, n))\n",
    "            assert n not in tree\n",
    "            tree[n] = [(cur_n, limb_length)]\n",
    "            print('{} --({})--> {}'.format(n, limb_length, cur_n))\n",
    "            return tree, idx\n",
    "        \n",
    "        elif cur_d > attaching_point:\n",
    "            print('PASSED THE ATTACHING POINT')\n",
    "            # Make a new node\n",
    "            new_n = idx\n",
    "            idx += 1\n",
    "            print('new_n: {}'.format(new_n))\n",
    "            #\n",
    "            tree[prev_n].append((new_n, attaching_point - prev_d))\n",
    "            print('{} --({})--> {}'.format(prev_n, attaching_point - prev_d, new_n))\n",
    "            assert new_n not in tree\n",
    "            tree[new_n] = [(prev_n, attaching_point - prev_d)]\n",
    "            print('{} --({})--> {}'.format(new_n, attaching_point - prev_d, prev_n))\n",
    "            #\n",
    "            tree[cur_n].append((new_n, cur_d - attaching_point))\n",
    "            print('{} --({})--> {}'.format(cur_n, cur_d - attaching_point, new_n))\n",
    "            tree[new_n].append((cur_n, cur_d - attaching_point))\n",
    "            print('{} --({})--> {}'.format(new_n, cur_d - attaching_point, cur_n))\n",
    "            #\n",
    "            tree[new_n].append((n, limb_length))\n",
    "            print('{} --({})--> {}'.format(new_n, limb_length, n))\n",
    "            assert n not in tree\n",
    "            tree[n] = [(new_n, limb_length)]\n",
    "            print('{} --({})--> {}'.format(n, limb_length, new_n))\n",
    "            \n",
    "            # Remove edges\n",
    "            tree[prev_n] = [(nn, dd) for nn, dd in tree[prev_n] if nn != cur_n]\n",
    "            tree[cur_n] = [(nn, dd) for nn, dd in tree[cur_n] if nn != prev_n]\n",
    "            \n",
    "            return tree, idx\n",
    "        \n",
    "        else:\n",
    "            for to_n, to_d in tree[cur_n]:\n",
    "                stack.append((to_n, cur_d + to_d, cur_n, cur_d))\n",
    "\n",
    "\n",
    "def can_reach(tree, from_n, to_n, visited):\n",
    "    print('TREE:', tree)\n",
    "    local_visited= [n for n in visited if n != from_n]\n",
    "    stack = [from_n]\n",
    "    while stack:\n",
    "        print('stack:\\t{}'.format(stack))\n",
    "        cur_n = stack.pop()\n",
    "        print('cur_n:\\t{}'.format(cur_n))\n",
    "        if cur_n == to_n:\n",
    "            return True\n",
    "        elif cur_n in local_visited:\n",
    "            print('{} is in {}'.format(cur_n, local_visited))\n",
    "            continue\n",
    "        else:\n",
    "            local_visited.append(cur_n)\n",
    "            for n, d in tree[cur_n]:\n",
    "                stack.append(n)\n",
    "    return False\n",
    "\n",
    "\n",
    "def AddiditePhylogeny():\n",
    "    idx = 1\n",
    "    mtrx = [list(map(int, ln)) for ln in [ln.split(' ') for ln in lines[1:]]]\n",
    "    result, idx = make_phylogeny_tree_using_additive_method(mtrx, len(mtrx) - 1, len(mtrx))\n",
    "    for k, v in result.items():\n",
    "        for vv, dd in v:\n",
    "            print('{}->{}:{0:.3g}'.format(k, vv, dd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "clusters: [(0,), (1,), (2,), (3,), (4,), (5,), (6,), (7,), (8,), (9,), (10,), (11,), (12,), (13,), (14,), (15,), (16,), (17,), (18,), (19,)]\n",
      "labels: [(0,), (1,), (2,), (3,), (4,), (5,), (6,), (7,), (8,), (9,), (10,), (11,), (12,), (13,), (14,), (15,), (16,), (17,), (18,), (19,)]\n",
      "ages: {(15,): (0, 15), (0,): (0, 0), (1,): (0, 1), (2,): (0, 2), (8,): (0, 8), (3,): (0, 3), (9,): (0, 9), (4,): (0, 4), (10,): (0, 10), (5,): (0, 5), (16,): (0, 16), (11,): (0, 11), (6,): (0, 6), (17,): (0, 17), (12,): (0, 12), (7,): (0, 7), (18,): (0, 18), (13,): (0, 13), (19,): (0, 19), (14,): (0, 14)}\n",
      "tree: {(15,): [[None, 0]], (0,): [[None, 0]], (1,): [[None, 0]], (2,): [[None, 0]], (8,): [[None, 0]], (3,): [[None, 0]], (9,): [[None, 0]], (4,): [[None, 0]], (10,): [[None, 0]], (5,): [[None, 0]], (16,): [[None, 0]], (11,): [[None, 0]], (6,): [[None, 0]], (17,): [[None, 0]], (12,): [[None, 0]], (7,): [[None, 0]], (18,): [[None, 0]], (13,): [[None, 0]], (19,): [[None, 0]], (14,): [[None, 0]]}\n",
      "Updated clustering pair: (0,)--<765.0>--(1,)\n",
      "Updated clustering pair: (0,)--<486.0>--(2,)\n",
      "Updated clustering pair: (0,)--<420.0>--(4,)\n",
      "Updated clustering pair: (5,)--<415.0>--(7,)\n",
      "Updated clustering pair: (5,)--<414.0>--(18,)\n",
      "Updated clustering pair: (6,)--<401.0>--(13,)\n",
      "i1: 6; i2: 13\n",
      "new_row: [610.0, 678.0, 676.0, 569.5, 491.0, 722.0, 652.5, 697.0, 688.0, 592.0, 643.0, 573.5, 643.5, 508.5, 633.5, 598.0, 531.0, 449.0, 0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "\n",
      "\n",
      "clusters: [(0,), (1,), (2,), (3,), (4,), (5,), (7,), (8,), (9,), (10,), (11,), (12,), (14,), (15,), (16,), (17,), (18,), (19,), (6, 13)]\n",
      "labels: [(0,), (1,), (2,), (3,), (4,), (5,), (7,), (8,), (9,), (10,), (11,), (12,), (14,), (15,), (16,), (17,), (18,), (19,), (6, 13)]\n",
      "ages: {(15,): (0, 15), (0,): (0, 0), (6, 13): (200.5, 20), (1,): (0, 1), (2,): (0, 2), (8,): (0, 8), (3,): (0, 3), (9,): (0, 9), (4,): (0, 4), (10,): (0, 10), (5,): (0, 5), (16,): (0, 16), (11,): (0, 11), (6,): (0, 6), (17,): (0, 17), (12,): (0, 12), (7,): (0, 7), (18,): (0, 18), (13,): (0, 13), (19,): (0, 19), (14,): (0, 14)}\n",
      "tree: {(15,): [[None, 0]], (0,): [[None, 0]], (6, 13): [[(6,), 0], [(13,), 0]], (1,): [[None, 0]], (2,): [[None, 0]], (8,): [[None, 0]], (3,): [[None, 0]], (9,): [[None, 0]], (4,): [[None, 0]], (10,): [[None, 0]], (5,): [[None, 0]], (16,): [[None, 0]], (11,): [[None, 0]], (6,): [[None, 0], [(6, 13), 0]], (17,): [[None, 0]], (12,): [[None, 0]], (7,): [[None, 0]], (18,): [[None, 0]], (13,): [[None, 0], [(6, 13), 0]], (19,): [[None, 0]], (14,): [[None, 0]]}\n",
      "Updated clustering pair: (0,)--<765.0>--(1,)\n",
      "Updated clustering pair: (0,)--<486.0>--(2,)\n",
      "Updated clustering pair: (0,)--<420.0>--(4,)\n",
      "Updated clustering pair: (5,)--<415.0>--(7,)\n",
      "Updated clustering pair: (5,)--<414.0>--(18,)\n",
      "Updated clustering pair: (7,)--<406.0>--(14,)\n",
      "Updated clustering pair: (8,)--<402.0>--(10,)\n",
      "i1: 7; i2: 9\n",
      "new_row: [596.5, 592.0, 596.0, 644.0, 616.5, 629.0, 648.0, 586.5, 555.0, 666.5, 579.0, 554.5, 458.0, 581.0, 465.0, 732.5, 644.5, 0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "\n",
      "\n",
      "clusters: [(0,), (1,), (2,), (3,), (4,), (5,), (7,), (9,), (11,), (12,), (14,), (15,), (16,), (17,), (18,), (19,), (6, 13), (8, 10)]\n",
      "labels: [(0,), (1,), (2,), (3,), (4,), (5,), (7,), (9,), (11,), (12,), (14,), (15,), (16,), (17,), (18,), (19,), (6, 13), (8, 10)]\n",
      "ages: {(17,): (0, 17), (8,): (0, 8), (9,): (0, 9), (10,): (0, 10), (11,): (0, 11), (12,): (0, 12), (13,): (0, 13), (14,): (0, 14), (15,): (0, 15), (0,): (0, 0), (1,): (0, 1), (2,): (0, 2), (3,): (0, 3), (8, 10): (201.0, 21), (4,): (0, 4), (5,): (0, 5), (16,): (0, 16), (6,): (0, 6), (6, 13): (200.5, 20), (7,): (0, 7), (18,): (0, 18), (19,): (0, 19)}\n",
      "tree: {(17,): [[None, 0]], (8,): [[None, 0], [(8, 10), 0]], (9,): [[None, 0]], (10,): [[None, 0], [(8, 10), 0]], (11,): [[None, 0]], (12,): [[None, 0]], (13,): [[None, 0], [(6, 13), 0]], (14,): [[None, 0]], (15,): [[None, 0]], (0,): [[None, 0]], (1,): [[None, 0]], (2,): [[None, 0]], (3,): [[None, 0]], (8, 10): [[(8,), 0], [(10,), 0]], (4,): [[None, 0]], (5,): [[None, 0]], (16,): [[None, 0]], (6,): [[None, 0], [(6, 13), 0]], (6, 13): [[(6,), 0], [(13,), 0]], (7,): [[None, 0]], (18,): [[None, 0]], (19,): [[None, 0]]}\n",
      "Updated clustering pair: (0,)--<765.0>--(1,)\n",
      "Updated clustering pair: (0,)--<486.0>--(2,)\n",
      "Updated clustering pair: (0,)--<420.0>--(4,)\n",
      "Updated clustering pair: (5,)--<415.0>--(7,)\n",
      "Updated clustering pair: (5,)--<414.0>--(18,)\n",
      "Updated clustering pair: (7,)--<406.0>--(14,)\n",
      "Updated clustering pair: (18,)--<405.0>--(19,)\n",
      "i1: 14; i2: 15\n",
      "new_row: [603.5, 675.5, 541.0, 517.5, 709.5, 431.5, 648.0, 602.5, 637.5, 699.0, 683.0, 672.0, 603.0, 708.5, 490.0, 598.75, 0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "\n",
      "\n",
      "clusters: [(0,), (1,), (2,), (3,), (4,), (5,), (7,), (9,), (11,), (12,), (14,), (15,), (16,), (17,), (6, 13), (8, 10), (18, 19)]\n",
      "labels: [(0,), (1,), (2,), (3,), (4,), (5,), (7,), (9,), (11,), (12,), (14,), (15,), (16,), (17,), (6, 13), (8, 10), (18, 19)]\n",
      "ages: {(17,): (0, 17), (8,): (0, 8), (9,): (0, 9), (10,): (0, 10), (11,): (0, 11), (12,): (0, 12), (13,): (0, 13), (14,): (0, 14), (18, 19): (202.5, 22), (15,): (0, 15), (0,): (0, 0), (1,): (0, 1), (2,): (0, 2), (3,): (0, 3), (8, 10): (201.0, 21), (4,): (0, 4), (5,): (0, 5), (16,): (0, 16), (6,): (0, 6), (6, 13): (200.5, 20), (7,): (0, 7), (18,): (0, 18), (19,): (0, 19)}\n",
      "tree: {(17,): [[None, 0]], (8,): [[None, 0], [(8, 10), 0]], (9,): [[None, 0]], (10,): [[None, 0], [(8, 10), 0]], (11,): [[None, 0]], (12,): [[None, 0]], (13,): [[None, 0], [(6, 13), 0]], (14,): [[None, 0]], (18, 19): [[(18,), 0], [(19,), 0]], (15,): [[None, 0]], (0,): [[None, 0]], (1,): [[None, 0]], (2,): [[None, 0]], (3,): [[None, 0]], (8, 10): [[(8,), 0], [(10,), 0]], (4,): [[None, 0]], (5,): [[None, 0]], (16,): [[None, 0]], (6,): [[None, 0], [(6, 13), 0]], (6, 13): [[(6,), 0], [(13,), 0]], (7,): [[None, 0]], (18,): [[None, 0], [(18, 19), 0]], (19,): [[None, 0], [(18, 19), 0]]}\n",
      "Updated clustering pair: (0,)--<765.0>--(1,)\n",
      "Updated clustering pair: (0,)--<486.0>--(2,)\n",
      "Updated clustering pair: (0,)--<420.0>--(4,)\n",
      "Updated clustering pair: (5,)--<415.0>--(7,)\n",
      "Updated clustering pair: (7,)--<406.0>--(14,)\n",
      "i1: 6; i2: 10\n",
      "new_row: [579.0, 621.5, 525.5, 640.5, 656.5, 560.5, 515.0, 619.0, 520.5, 770.5, 584.0, 546.0, 648.0, 613.5, 665.5, 0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "\n",
      "\n",
      "clusters: [(0,), (1,), (2,), (3,), (4,), (5,), (9,), (11,), (12,), (15,), (16,), (17,), (6, 13), (8, 10), (18, 19), (7, 14)]\n",
      "labels: [(0,), (1,), (2,), (3,), (4,), (5,), (9,), (11,), (12,), (15,), (16,), (17,), (6, 13), (8, 10), (18, 19), (7, 14)]\n",
      "ages: {(7, 14): (203.0, 23), (17,): (0, 17), (8,): (0, 8), (9,): (0, 9), (10,): (0, 10), (11,): (0, 11), (12,): (0, 12), (13,): (0, 13), (14,): (0, 14), (18, 19): (202.5, 22), (15,): (0, 15), (0,): (0, 0), (1,): (0, 1), (2,): (0, 2), (3,): (0, 3), (8, 10): (201.0, 21), (4,): (0, 4), (5,): (0, 5), (16,): (0, 16), (6,): (0, 6), (6, 13): (200.5, 20), (7,): (0, 7), (18,): (0, 18), (19,): (0, 19)}\n",
      "tree: {(7, 14): [[(7,), 0], [(14,), 0]], (17,): [[None, 0]], (8,): [[None, 0], [(8, 10), 0]], (9,): [[None, 0]], (10,): [[None, 0], [(8, 10), 0]], (11,): [[None, 0]], (12,): [[None, 0]], (13,): [[None, 0], [(6, 13), 0]], (14,): [[None, 0], [(7, 14), 0]], (18, 19): [[(18,), 0], [(19,), 0]], (15,): [[None, 0]], (0,): [[None, 0]], (1,): [[None, 0]], (2,): [[None, 0]], (3,): [[None, 0]], (8, 10): [[(8,), 0], [(10,), 0]], (4,): [[None, 0]], (5,): [[None, 0]], (16,): [[None, 0]], (6,): [[None, 0], [(6, 13), 0]], (6, 13): [[(6,), 0], [(13,), 0]], (7,): [[None, 0], [(7, 14), 0]], (18,): [[None, 0], [(18, 19), 0]], (19,): [[None, 0], [(18, 19), 0]]}\n",
      "Updated clustering pair: (0,)--<765.0>--(1,)\n",
      "Updated clustering pair: (0,)--<486.0>--(2,)\n",
      "Updated clustering pair: (0,)--<420.0>--(4,)\n",
      "Updated clustering pair: (9,)--<413.0>--(16,)\n",
      "i1: 6; i2: 10\n",
      "new_row: [586.0, 652.0, 676.5, 553.5, 606.0, 724.5, 565.0, 605.0, 535.5, 545.5, 660.75, 522.25, 602.75, 549.5, 0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "\n",
      "\n",
      "clusters: [(0,), (1,), (2,), (3,), (4,), (5,), (11,), (12,), (15,), (17,), (6, 13), (8, 10), (18, 19), (7, 14), (9, 16)]\n",
      "labels: [(0,), (1,), (2,), (3,), (4,), (5,), (11,), (12,), (15,), (17,), (6, 13), (8, 10), (18, 19), (7, 14), (9, 16)]\n",
      "ages: {(7, 14): (203.0, 23), (17,): (0, 17), (8,): (0, 8), (9,): (0, 9), (10,): (0, 10), (9, 16): (206.5, 24), (11,): (0, 11), (12,): (0, 12), (13,): (0, 13), (14,): (0, 14), (18, 19): (202.5, 22), (15,): (0, 15), (0,): (0, 0), (1,): (0, 1), (2,): (0, 2), (3,): (0, 3), (8, 10): (201.0, 21), (4,): (0, 4), (5,): (0, 5), (16,): (0, 16), (6,): (0, 6), (6, 13): (200.5, 20), (7,): (0, 7), (18,): (0, 18), (19,): (0, 19)}\n",
      "tree: {(7, 14): [[(7,), 0], [(14,), 0]], (17,): [[None, 0]], (8,): [[None, 0], [(8, 10), 0]], (9,): [[None, 0], [(9, 16), 0]], (10,): [[None, 0], [(8, 10), 0]], (9, 16): [[(9,), 0], [(16,), 0]], (11,): [[None, 0]], (12,): [[None, 0]], (13,): [[None, 0], [(6, 13), 0]], (14,): [[None, 0], [(7, 14), 0]], (18, 19): [[(18,), 0], [(19,), 0]], (15,): [[None, 0]], (0,): [[None, 0]], (1,): [[None, 0]], (2,): [[None, 0]], (3,): [[None, 0]], (8, 10): [[(8,), 0], [(10,), 0]], (4,): [[None, 0]], (5,): [[None, 0]], (16,): [[None, 0], [(9, 16), 0]], (6,): [[None, 0], [(6, 13), 0]], (6, 13): [[(6,), 0], [(13,), 0]], (7,): [[None, 0], [(7, 14), 0]], (18,): [[None, 0], [(18, 19), 0]], (19,): [[None, 0], [(18, 19), 0]]}\n",
      "Updated clustering pair: (0,)--<765.0>--(1,)\n",
      "Updated clustering pair: (0,)--<486.0>--(2,)\n",
      "Updated clustering pair: (0,)--<420.0>--(4,)\n",
      "i1: 0; i2: 4\n",
      "new_row: [771.5, 459.0, 698.5, 738.5, 522.5, 568.0, 519.0, 709.0, 550.5, 606.5, 656.5, 617.75, 596.0, 0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "\n",
      "\n",
      "clusters: [(1,), (2,), (3,), (5,), (11,), (12,), (15,), (17,), (6, 13), (8, 10), (18, 19), (7, 14), (9, 16), (0, 4)]\n",
      "labels: [(1,), (2,), (3,), (5,), (11,), (12,), (15,), (17,), (6, 13), (8, 10), (18, 19), (7, 14), (9, 16), (0, 4)]\n",
      "ages: {(7, 14): (203.0, 23), (17,): (0, 17), (8,): (0, 8), (9,): (0, 9), (10,): (0, 10), (9, 16): (206.5, 24), (11,): (0, 11), (12,): (0, 12), (13,): (0, 13), (14,): (0, 14), (18, 19): (202.5, 22), (15,): (0, 15), (0,): (0, 0), (1,): (0, 1), (2,): (0, 2), (3,): (0, 3), (8, 10): (201.0, 21), (4,): (0, 4), (5,): (0, 5), (16,): (0, 16), (6,): (0, 6), (6, 13): (200.5, 20), (0, 4): (210.0, 25), (7,): (0, 7), (18,): (0, 18), (19,): (0, 19)}\n",
      "tree: {(7, 14): [[(7,), 0], [(14,), 0]], (17,): [[None, 0]], (8,): [[None, 0], [(8, 10), 0]], (9,): [[None, 0], [(9, 16), 0]], (10,): [[None, 0], [(8, 10), 0]], (9, 16): [[(9,), 0], [(16,), 0]], (11,): [[None, 0]], (12,): [[None, 0]], (13,): [[None, 0], [(6, 13), 0]], (14,): [[None, 0], [(7, 14), 0]], (18, 19): [[(18,), 0], [(19,), 0]], (15,): [[None, 0]], (0,): [[None, 0], [(0, 4), 0]], (1,): [[None, 0]], (2,): [[None, 0]], (3,): [[None, 0]], (8, 10): [[(8,), 0], [(10,), 0]], (4,): [[None, 0], [(0, 4), 0]], (5,): [[None, 0]], (16,): [[None, 0], [(9, 16), 0]], (6,): [[None, 0], [(6, 13), 0]], (6, 13): [[(6,), 0], [(13,), 0]], (0, 4): [[(0,), 0], [(4,), 0]], (7,): [[None, 0], [(7, 14), 0]], (18,): [[None, 0], [(18, 19), 0]], (19,): [[None, 0], [(18, 19), 0]]}\n",
      "Updated clustering pair: (1,)--<428.0>--(2,)\n",
      "i1: 0; i2: 1\n",
      "new_row: [629.5, 705.0, 475.5, 703.0, 597.0, 543.0, 677.0, 594.0, 608.25, 573.5, 664.25, 615.25, 0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "\n",
      "\n",
      "clusters: [(3,), (5,), (11,), (12,), (15,), (17,), (6, 13), (8, 10), (18, 19), (7, 14), (9, 16), (0, 4), (1, 2)]\n",
      "labels: [(3,), (5,), (11,), (12,), (15,), (17,), (6, 13), (8, 10), (18, 19), (7, 14), (9, 16), (0, 4), (1, 2)]\n",
      "ages: {(1, 2): (214.0, 26), (7, 14): (203.0, 23), (17,): (0, 17), (8,): (0, 8), (9,): (0, 9), (10,): (0, 10), (9, 16): (206.5, 24), (11,): (0, 11), (12,): (0, 12), (13,): (0, 13), (14,): (0, 14), (18, 19): (202.5, 22), (15,): (0, 15), (0,): (0, 0), (1,): (0, 1), (2,): (0, 2), (3,): (0, 3), (8, 10): (201.0, 21), (4,): (0, 4), (5,): (0, 5), (16,): (0, 16), (6,): (0, 6), (6, 13): (200.5, 20), (0, 4): (210.0, 25), (7,): (0, 7), (18,): (0, 18), (19,): (0, 19)}\n",
      "tree: {(1, 2): [[(1,), 0], [(2,), 0]], (7, 14): [[(7,), 0], [(14,), 0]], (17,): [[None, 0]], (8,): [[None, 0], [(8, 10), 0]], (9,): [[None, 0], [(9, 16), 0]], (10,): [[None, 0], [(8, 10), 0]], (9, 16): [[(9,), 0], [(16,), 0]], (11,): [[None, 0]], (12,): [[None, 0]], (13,): [[None, 0], [(6, 13), 0]], (14,): [[None, 0], [(7, 14), 0]], (18, 19): [[(18,), 0], [(19,), 0]], (15,): [[None, 0]], (0,): [[None, 0], [(0, 4), 0]], (1,): [[None, 0], [(1, 2), 0]], (2,): [[None, 0], [(1, 2), 0]], (3,): [[None, 0]], (8, 10): [[(8,), 0], [(10,), 0]], (4,): [[None, 0], [(0, 4), 0]], (5,): [[None, 0]], (16,): [[None, 0], [(9, 16), 0]], (6,): [[None, 0], [(6, 13), 0]], (6, 13): [[(6,), 0], [(13,), 0]], (0, 4): [[(0,), 0], [(4,), 0]], (7,): [[None, 0], [(7, 14), 0]], (18,): [[None, 0], [(18, 19), 0]], (19,): [[None, 0], [(18, 19), 0]]}\n",
      "Updated clustering pair: (3,)--<576.0>--(5,)\n",
      "Updated clustering pair: (3,)--<546.0>--(12,)\n",
      "Updated clustering pair: (3,)--<524.0>--(17,)\n",
      "Updated clustering pair: (3,)--<517.5>--(18, 19)\n",
      "Updated clustering pair: (5,)--<470.0>--(11,)\n",
      "Updated clustering pair: (5,)--<431.5>--(18, 19)\n",
      "i1: 1; i2: 8\n",
      "new_row: [537.0, 581.6666666666666, 676.3333333333334, 655.0, 729.6666666666666, 567.3333333333334, 608.8333333333334, 630.5, 643.3333333333334, 683.8333333333334, 640.5, 0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "\n",
      "\n",
      "clusters: [(3,), (11,), (12,), (15,), (17,), (6, 13), (8, 10), (7, 14), (9, 16), (0, 4), (1, 2), (5, 18, 19)]\n",
      "labels: [(3,), (11,), (12,), (15,), (17,), (6, 13), (8, 10), (7, 14), (9, 16), (0, 4), (1, 2), (5, 18, 19)]\n",
      "ages: {(1, 2): (214.0, 26), (7, 14): (203.0, 23), (17,): (0, 17), (8,): (0, 8), (9,): (0, 9), (10,): (0, 10), (9, 16): (206.5, 24), (5, 18, 19): (215.75, 27), (11,): (0, 11), (12,): (0, 12), (13,): (0, 13), (14,): (0, 14), (18, 19): (202.5, 22), (15,): (0, 15), (0,): (0, 0), (1,): (0, 1), (2,): (0, 2), (3,): (0, 3), (8, 10): (201.0, 21), (4,): (0, 4), (5,): (0, 5), (16,): (0, 16), (6,): (0, 6), (6, 13): (200.5, 20), (0, 4): (210.0, 25), (7,): (0, 7), (18,): (0, 18), (19,): (0, 19)}\n",
      "tree: {(1, 2): [[(1,), 0], [(2,), 0]], (7, 14): [[(7,), 0], [(14,), 0]], (17,): [[None, 0]], (8,): [[None, 0], [(8, 10), 0]], (9,): [[None, 0], [(9, 16), 0]], (10,): [[None, 0], [(8, 10), 0]], (9, 16): [[(9,), 0], [(16,), 0]], (5, 18, 19): [[(5,), 0], [(18, 19), 0]], (11,): [[None, 0]], (12,): [[None, 0]], (13,): [[None, 0], [(6, 13), 0]], (14,): [[None, 0], [(7, 14), 0]], (18, 19): [[(18,), 0], [(19,), 0], [(5, 18, 19), 0]], (15,): [[None, 0]], (0,): [[None, 0], [(0, 4), 0]], (1,): [[None, 0], [(1, 2), 0]], (2,): [[None, 0], [(1, 2), 0]], (3,): [[None, 0]], (8, 10): [[(8,), 0], [(10,), 0]], (4,): [[None, 0], [(0, 4), 0]], (5,): [[None, 0], [(5, 18, 19), 0]], (16,): [[None, 0], [(9, 16), 0]], (6,): [[None, 0], [(6, 13), 0]], (6, 13): [[(6,), 0], [(13,), 0]], (0, 4): [[(0,), 0], [(4,), 0]], (7,): [[None, 0], [(7, 14), 0]], (18,): [[None, 0], [(18, 19), 0]], (19,): [[None, 0], [(18, 19), 0]]}\n",
      "Updated clustering pair: (3,)--<662.0>--(11,)\n",
      "Updated clustering pair: (3,)--<546.0>--(12,)\n",
      "Updated clustering pair: (3,)--<524.0>--(17,)\n",
      "Updated clustering pair: (11,)--<522.5>--(0, 4)\n",
      "Updated clustering pair: (11,)--<475.5>--(1, 2)\n",
      "i1: 1; i2: 10\n",
      "new_row: [640.3333333333334, 727.0, 630.6666666666666, 541.6666666666666, 665.6666666666666, 581.0, 588.6666666666666, 631.1666666666666, 584.3333333333334, 620.8888888888889, 0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "\n",
      "\n",
      "clusters: [(3,), (12,), (15,), (17,), (6, 13), (8, 10), (7, 14), (9, 16), (0, 4), (5, 18, 19), (11, 1, 2)]\n",
      "labels: [(3,), (12,), (15,), (17,), (6, 13), (8, 10), (7, 14), (9, 16), (0, 4), (5, 18, 19), (11, 1, 2)]\n",
      "ages: {(1, 2): (214.0, 26), (7, 14): (203.0, 23), (17,): (0, 17), (8,): (0, 8), (9,): (0, 9), (10,): (0, 10), (9, 16): (206.5, 24), (5, 18, 19): (215.75, 27), (11,): (0, 11), (11, 1, 2): (237.75, 28), (12,): (0, 12), (13,): (0, 13), (14,): (0, 14), (18, 19): (202.5, 22), (15,): (0, 15), (0,): (0, 0), (1,): (0, 1), (2,): (0, 2), (3,): (0, 3), (8, 10): (201.0, 21), (4,): (0, 4), (5,): (0, 5), (16,): (0, 16), (6,): (0, 6), (6, 13): (200.5, 20), (0, 4): (210.0, 25), (7,): (0, 7), (18,): (0, 18), (19,): (0, 19)}\n",
      "tree: {(1, 2): [[(1,), 0], [(2,), 0], [(11, 1, 2), 0]], (7, 14): [[(7,), 0], [(14,), 0]], (17,): [[None, 0]], (8,): [[None, 0], [(8, 10), 0]], (9,): [[None, 0], [(9, 16), 0]], (10,): [[None, 0], [(8, 10), 0]], (9, 16): [[(9,), 0], [(16,), 0]], (5, 18, 19): [[(5,), 0], [(18, 19), 0]], (11,): [[None, 0], [(11, 1, 2), 0]], (11, 1, 2): [[(11,), 0], [(1, 2), 0]], (12,): [[None, 0]], (13,): [[None, 0], [(6, 13), 0]], (14,): [[None, 0], [(7, 14), 0]], (18, 19): [[(18,), 0], [(19,), 0], [(5, 18, 19), 0]], (15,): [[None, 0]], (0,): [[None, 0], [(0, 4), 0]], (1,): [[None, 0], [(1, 2), 0]], (2,): [[None, 0], [(1, 2), 0]], (3,): [[None, 0]], (8, 10): [[(8,), 0], [(10,), 0]], (4,): [[None, 0], [(0, 4), 0]], (5,): [[None, 0], [(5, 18, 19), 0]], (16,): [[None, 0], [(9, 16), 0]], (6,): [[None, 0], [(6, 13), 0]], (6, 13): [[(6,), 0], [(13,), 0]], (0, 4): [[(0,), 0], [(4,), 0]], (7,): [[None, 0], [(7, 14), 0]], (18,): [[None, 0], [(18, 19), 0]], (19,): [[None, 0], [(18, 19), 0]]}\n",
      "Updated clustering pair: (3,)--<546.0>--(12,)\n",
      "Updated clustering pair: (3,)--<524.0>--(17,)\n",
      "Updated clustering pair: (12,)--<520.5>--(7, 14)\n",
      "Updated clustering pair: (15,)--<508.5>--(6, 13)\n",
      "i1: 2; i2: 4\n",
      "new_row: [602.0, 638.0, 643.0, 614.5, 688.8333333333334, 619.0, 540.0, 596.5555555555555, 654.0, 0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "\n",
      "\n",
      "clusters: [(3,), (12,), (17,), (8, 10), (7, 14), (9, 16), (0, 4), (5, 18, 19), (11, 1, 2), (15, 6, 13)]\n",
      "labels: [(3,), (12,), (17,), (8, 10), (7, 14), (9, 16), (0, 4), (5, 18, 19), (11, 1, 2), (15, 6, 13)]\n",
      "ages: {(1, 2): (214.0, 26), (7, 14): (203.0, 23), (17,): (0, 17), (8,): (0, 8), (9,): (0, 9), (10,): (0, 10), (9, 16): (206.5, 24), (5, 18, 19): (215.75, 27), (11,): (0, 11), (11, 1, 2): (237.75, 28), (12,): (0, 12), (13,): (0, 13), (14,): (0, 14), (18, 19): (202.5, 22), (15,): (0, 15), (0,): (0, 0), (1,): (0, 1), (2,): (0, 2), (15, 6, 13): (254.25, 29), (3,): (0, 3), (8, 10): (201.0, 21), (4,): (0, 4), (5,): (0, 5), (16,): (0, 16), (6,): (0, 6), (6, 13): (200.5, 20), (0, 4): (210.0, 25), (7,): (0, 7), (18,): (0, 18), (19,): (0, 19)}\n",
      "tree: {(1, 2): [[(1,), 0], [(2,), 0], [(11, 1, 2), 0]], (7, 14): [[(7,), 0], [(14,), 0]], (17,): [[None, 0]], (8,): [[None, 0], [(8, 10), 0]], (9,): [[None, 0], [(9, 16), 0]], (10,): [[None, 0], [(8, 10), 0]], (9, 16): [[(9,), 0], [(16,), 0]], (5, 18, 19): [[(5,), 0], [(18, 19), 0]], (11,): [[None, 0], [(11, 1, 2), 0]], (11, 1, 2): [[(11,), 0], [(1, 2), 0]], (12,): [[None, 0]], (13,): [[None, 0], [(6, 13), 0]], (14,): [[None, 0], [(7, 14), 0]], (18, 19): [[(18,), 0], [(19,), 0], [(5, 18, 19), 0]], (15,): [[None, 0], [(15, 6, 13), 0]], (0,): [[None, 0], [(0, 4), 0]], (1,): [[None, 0], [(1, 2), 0]], (2,): [[None, 0], [(1, 2), 0]], (15, 6, 13): [[(15,), 0], [(6, 13), 0]], (3,): [[None, 0]], (8, 10): [[(8,), 0], [(10,), 0]], (4,): [[None, 0], [(0, 4), 0]], (5,): [[None, 0], [(5, 18, 19), 0]], (16,): [[None, 0], [(9, 16), 0]], (6,): [[None, 0], [(6, 13), 0]], (6, 13): [[(6,), 0], [(13,), 0], [(15, 6, 13), 0]], (0, 4): [[(0,), 0], [(4,), 0]], (7,): [[None, 0], [(7, 14), 0]], (18,): [[None, 0], [(18, 19), 0]], (19,): [[None, 0], [(18, 19), 0]]}\n",
      "Updated clustering pair: (3,)--<546.0>--(12,)\n",
      "Updated clustering pair: (3,)--<524.0>--(17,)\n",
      "Updated clustering pair: (12,)--<520.5>--(7, 14)\n",
      "i1: 1; i2: 4\n",
      "new_row: [609.0, 582.6666666666666, 631.1666666666666, 568.0, 601.1666666666666, 645.7777777777778, 634.7777777777778, 671.8888888888889, 0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "\n",
      "\n",
      "clusters: [(3,), (17,), (8, 10), (9, 16), (0, 4), (5, 18, 19), (11, 1, 2), (15, 6, 13), (12, 7, 14)]\n",
      "labels: [(3,), (17,), (8, 10), (9, 16), (0, 4), (5, 18, 19), (11, 1, 2), (15, 6, 13), (12, 7, 14)]\n",
      "ages: {(1, 2): (214.0, 26), (7, 14): (203.0, 23), (17,): (0, 17), (8,): (0, 8), (9,): (0, 9), (10,): (0, 10), (9, 16): (206.5, 24), (5, 18, 19): (215.75, 27), (11,): (0, 11), (11, 1, 2): (237.75, 28), (12,): (0, 12), (13,): (0, 13), (14,): (0, 14), (18, 19): (202.5, 22), (15,): (0, 15), (0,): (0, 0), (1,): (0, 1), (2,): (0, 2), (15, 6, 13): (254.25, 29), (3,): (0, 3), (8, 10): (201.0, 21), (12, 7, 14): (260.25, 30), (4,): (0, 4), (5,): (0, 5), (16,): (0, 16), (6,): (0, 6), (6, 13): (200.5, 20), (0, 4): (210.0, 25), (7,): (0, 7), (18,): (0, 18), (19,): (0, 19)}\n",
      "tree: {(1, 2): [[(1,), 0], [(2,), 0], [(11, 1, 2), 0]], (7, 14): [[(7,), 0], [(14,), 0], [(12, 7, 14), 0]], (17,): [[None, 0]], (8,): [[None, 0], [(8, 10), 0]], (9,): [[None, 0], [(9, 16), 0]], (10,): [[None, 0], [(8, 10), 0]], (9, 16): [[(9,), 0], [(16,), 0]], (5, 18, 19): [[(5,), 0], [(18, 19), 0]], (11,): [[None, 0], [(11, 1, 2), 0]], (11, 1, 2): [[(11,), 0], [(1, 2), 0]], (12,): [[None, 0], [(12, 7, 14), 0]], (13,): [[None, 0], [(6, 13), 0]], (14,): [[None, 0], [(7, 14), 0]], (18, 19): [[(18,), 0], [(19,), 0], [(5, 18, 19), 0]], (15,): [[None, 0], [(15, 6, 13), 0]], (0,): [[None, 0], [(0, 4), 0]], (1,): [[None, 0], [(1, 2), 0]], (2,): [[None, 0], [(1, 2), 0]], (15, 6, 13): [[(15,), 0], [(6, 13), 0]], (3,): [[None, 0]], (8, 10): [[(8,), 0], [(10,), 0]], (12, 7, 14): [[(12,), 0], [(7, 14), 0]], (4,): [[None, 0], [(0, 4), 0]], (5,): [[None, 0], [(5, 18, 19), 0]], (16,): [[None, 0], [(9, 16), 0]], (6,): [[None, 0], [(6, 13), 0]], (6, 13): [[(6,), 0], [(13,), 0], [(15, 6, 13), 0]], (0, 4): [[(0,), 0], [(4,), 0]], (7,): [[None, 0], [(7, 14), 0]], (18,): [[None, 0], [(18, 19), 0]], (19,): [[None, 0], [(18, 19), 0]]}\n",
      "Updated clustering pair: (3,)--<524.0>--(17,)\n",
      "Updated clustering pair: (8, 10)--<522.25>--(9, 16)\n",
      "i1: 2; i2: 3\n",
      "new_row: [598.75, 563.25, 601.25, 626.0833333333334, 606.0833333333334, 616.75, 599.5833333333334, 0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "\n",
      "\n",
      "clusters: [(3,), (17,), (0, 4), (5, 18, 19), (11, 1, 2), (15, 6, 13), (12, 7, 14), (8, 10, 9, 16)]\n",
      "labels: [(3,), (17,), (0, 4), (5, 18, 19), (11, 1, 2), (15, 6, 13), (12, 7, 14), (8, 10, 9, 16)]\n",
      "ages: {(1, 2): (214.0, 26), (7, 14): (203.0, 23), (17,): (0, 17), (8,): (0, 8), (8, 10, 9, 16): (261.125, 31), (9,): (0, 9), (10,): (0, 10), (9, 16): (206.5, 24), (5, 18, 19): (215.75, 27), (11,): (0, 11), (11, 1, 2): (237.75, 28), (12,): (0, 12), (13,): (0, 13), (14,): (0, 14), (18, 19): (202.5, 22), (15,): (0, 15), (0,): (0, 0), (1,): (0, 1), (2,): (0, 2), (15, 6, 13): (254.25, 29), (3,): (0, 3), (8, 10): (201.0, 21), (12, 7, 14): (260.25, 30), (4,): (0, 4), (5,): (0, 5), (16,): (0, 16), (6,): (0, 6), (6, 13): (200.5, 20), (0, 4): (210.0, 25), (7,): (0, 7), (18,): (0, 18), (19,): (0, 19)}\n",
      "tree: {(1, 2): [[(1,), 0], [(2,), 0], [(11, 1, 2), 0]], (7, 14): [[(7,), 0], [(14,), 0], [(12, 7, 14), 0]], (17,): [[None, 0]], (8,): [[None, 0], [(8, 10), 0]], (8, 10, 9, 16): [[(8, 10), 0], [(9, 16), 0]], (9,): [[None, 0], [(9, 16), 0]], (10,): [[None, 0], [(8, 10), 0]], (9, 16): [[(9,), 0], [(16,), 0], [(8, 10, 9, 16), 0]], (5, 18, 19): [[(5,), 0], [(18, 19), 0]], (11,): [[None, 0], [(11, 1, 2), 0]], (11, 1, 2): [[(11,), 0], [(1, 2), 0]], (12,): [[None, 0], [(12, 7, 14), 0]], (13,): [[None, 0], [(6, 13), 0]], (14,): [[None, 0], [(7, 14), 0]], (18, 19): [[(18,), 0], [(19,), 0], [(5, 18, 19), 0]], (15,): [[None, 0], [(15, 6, 13), 0]], (0,): [[None, 0], [(0, 4), 0]], (1,): [[None, 0], [(1, 2), 0]], (2,): [[None, 0], [(1, 2), 0]], (15, 6, 13): [[(15,), 0], [(6, 13), 0]], (3,): [[None, 0]], (8, 10): [[(8,), 0], [(10,), 0], [(8, 10, 9, 16), 0]], (12, 7, 14): [[(12,), 0], [(7, 14), 0]], (4,): [[None, 0], [(0, 4), 0]], (5,): [[None, 0], [(5, 18, 19), 0]], (16,): [[None, 0], [(9, 16), 0]], (6,): [[None, 0], [(6, 13), 0]], (6, 13): [[(6,), 0], [(13,), 0], [(15, 6, 13), 0]], (0, 4): [[(0,), 0], [(4,), 0]], (7,): [[None, 0], [(7, 14), 0]], (18,): [[None, 0], [(18, 19), 0]], (19,): [[None, 0], [(18, 19), 0]]}\n",
      "Updated clustering pair: (3,)--<524.0>--(17,)\n",
      "i1: 0; i2: 1\n",
      "new_row: [703.75, 633.3333333333334, 591.0, 622.5, 595.8333333333334, 581.0, 0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "\n",
      "\n",
      "clusters: [(0, 4), (5, 18, 19), (11, 1, 2), (15, 6, 13), (12, 7, 14), (8, 10, 9, 16), (3, 17)]\n",
      "labels: [(0, 4), (5, 18, 19), (11, 1, 2), (15, 6, 13), (12, 7, 14), (8, 10, 9, 16), (3, 17)]\n",
      "ages: {(1, 2): (214.0, 26), (7, 14): (203.0, 23), (17,): (0, 17), (8,): (0, 8), (8, 10, 9, 16): (261.125, 31), (9,): (0, 9), (10,): (0, 10), (9, 16): (206.5, 24), (5, 18, 19): (215.75, 27), (11,): (0, 11), (11, 1, 2): (237.75, 28), (12,): (0, 12), (13,): (0, 13), (3, 17): (262.0, 32), (14,): (0, 14), (18, 19): (202.5, 22), (15,): (0, 15), (0,): (0, 0), (1,): (0, 1), (2,): (0, 2), (15, 6, 13): (254.25, 29), (3,): (0, 3), (8, 10): (201.0, 21), (12, 7, 14): (260.25, 30), (4,): (0, 4), (5,): (0, 5), (16,): (0, 16), (6,): (0, 6), (6, 13): (200.5, 20), (0, 4): (210.0, 25), (7,): (0, 7), (18,): (0, 18), (19,): (0, 19)}\n",
      "tree: {(1, 2): [[(1,), 0], [(2,), 0], [(11, 1, 2), 0]], (7, 14): [[(7,), 0], [(14,), 0], [(12, 7, 14), 0]], (17,): [[None, 0], [(3, 17), 0]], (8,): [[None, 0], [(8, 10), 0]], (8, 10, 9, 16): [[(8, 10), 0], [(9, 16), 0]], (9,): [[None, 0], [(9, 16), 0]], (10,): [[None, 0], [(8, 10), 0]], (9, 16): [[(9,), 0], [(16,), 0], [(8, 10, 9, 16), 0]], (5, 18, 19): [[(5,), 0], [(18, 19), 0]], (11,): [[None, 0], [(11, 1, 2), 0]], (11, 1, 2): [[(11,), 0], [(1, 2), 0]], (12,): [[None, 0], [(12, 7, 14), 0]], (13,): [[None, 0], [(6, 13), 0]], (3, 17): [[(3,), 0], [(17,), 0]], (14,): [[None, 0], [(7, 14), 0]], (18, 19): [[(18,), 0], [(19,), 0], [(5, 18, 19), 0]], (15,): [[None, 0], [(15, 6, 13), 0]], (0,): [[None, 0], [(0, 4), 0]], (1,): [[None, 0], [(1, 2), 0]], (2,): [[None, 0], [(1, 2), 0]], (15, 6, 13): [[(15,), 0], [(6, 13), 0]], (3,): [[None, 0], [(3, 17), 0]], (8, 10): [[(8,), 0], [(10,), 0], [(8, 10, 9, 16), 0]], (12, 7, 14): [[(12,), 0], [(7, 14), 0]], (4,): [[None, 0], [(0, 4), 0]], (5,): [[None, 0], [(5, 18, 19), 0]], (16,): [[None, 0], [(9, 16), 0]], (6,): [[None, 0], [(6, 13), 0]], (6, 13): [[(6,), 0], [(13,), 0], [(15, 6, 13), 0]], (0, 4): [[(0,), 0], [(4,), 0]], (7,): [[None, 0], [(7, 14), 0]], (18,): [[None, 0], [(18, 19), 0]], (19,): [[None, 0], [(18, 19), 0]]}\n",
      "Updated clustering pair: (0, 4)--<683.8333333333334>--(5, 18, 19)\n",
      "Updated clustering pair: (0, 4)--<584.3333333333334>--(11, 1, 2)\n",
      "Updated clustering pair: (0, 4)--<540.0>--(15, 6, 13)\n",
      "i1: 0; i2: 3\n",
      "new_row: [631.4666666666667, 626.1333333333333, 643.6, 610.55, 655.0, 0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "\n",
      "\n",
      "clusters: [(5, 18, 19), (11, 1, 2), (12, 7, 14), (8, 10, 9, 16), (3, 17), (0, 4, 15, 6, 13)]\n",
      "labels: [(5, 18, 19), (11, 1, 2), (12, 7, 14), (8, 10, 9, 16), (3, 17), (0, 4, 15, 6, 13)]\n",
      "ages: {(1, 2): (214.0, 26), (7, 14): (203.0, 23), (17,): (0, 17), (8,): (0, 8), (8, 10, 9, 16): (261.125, 31), (9,): (0, 9), (10,): (0, 10), (9, 16): (206.5, 24), (5, 18, 19): (215.75, 27), (11,): (0, 11), (11, 1, 2): (237.75, 28), (12,): (0, 12), (13,): (0, 13), (3, 17): (262.0, 32), (14,): (0, 14), (18, 19): (202.5, 22), (15,): (0, 15), (0,): (0, 0), (1,): (0, 1), (0, 4, 15, 6, 13): (270.0, 33), (2,): (0, 2), (15, 6, 13): (254.25, 29), (3,): (0, 3), (8, 10): (201.0, 21), (12, 7, 14): (260.25, 30), (4,): (0, 4), (5,): (0, 5), (16,): (0, 16), (6,): (0, 6), (6, 13): (200.5, 20), (0, 4): (210.0, 25), (7,): (0, 7), (18,): (0, 18), (19,): (0, 19)}\n",
      "tree: {(1, 2): [[(1,), 0], [(2,), 0], [(11, 1, 2), 0]], (7, 14): [[(7,), 0], [(14,), 0], [(12, 7, 14), 0]], (17,): [[None, 0], [(3, 17), 0]], (8,): [[None, 0], [(8, 10), 0]], (8, 10, 9, 16): [[(8, 10), 0], [(9, 16), 0]], (9,): [[None, 0], [(9, 16), 0]], (10,): [[None, 0], [(8, 10), 0]], (9, 16): [[(9,), 0], [(16,), 0], [(8, 10, 9, 16), 0]], (5, 18, 19): [[(5,), 0], [(18, 19), 0]], (11,): [[None, 0], [(11, 1, 2), 0]], (11, 1, 2): [[(11,), 0], [(1, 2), 0]], (12,): [[None, 0], [(12, 7, 14), 0]], (13,): [[None, 0], [(6, 13), 0]], (3, 17): [[(3,), 0], [(17,), 0]], (14,): [[None, 0], [(7, 14), 0]], (18, 19): [[(18,), 0], [(19,), 0], [(5, 18, 19), 0]], (15,): [[None, 0], [(15, 6, 13), 0]], (0,): [[None, 0], [(0, 4), 0]], (1,): [[None, 0], [(1, 2), 0]], (0, 4, 15, 6, 13): [[(0, 4), 0], [(15, 6, 13), 0]], (2,): [[None, 0], [(1, 2), 0]], (15, 6, 13): [[(15,), 0], [(6, 13), 0], [(0, 4, 15, 6, 13), 0]], (3,): [[None, 0], [(3, 17), 0]], (8, 10): [[(8,), 0], [(10,), 0], [(8, 10, 9, 16), 0]], (12, 7, 14): [[(12,), 0], [(7, 14), 0]], (4,): [[None, 0], [(0, 4), 0]], (5,): [[None, 0], [(5, 18, 19), 0]], (16,): [[None, 0], [(9, 16), 0]], (6,): [[None, 0], [(6, 13), 0]], (6, 13): [[(6,), 0], [(13,), 0], [(15, 6, 13), 0]], (0, 4): [[(0,), 0], [(4,), 0], [(0, 4, 15, 6, 13), 0]], (7,): [[None, 0], [(7, 14), 0]], (18,): [[None, 0], [(18, 19), 0]], (19,): [[None, 0], [(18, 19), 0]]}\n",
      "Updated clustering pair: (5, 18, 19)--<620.8888888888889>--(11, 1, 2)\n",
      "Updated clustering pair: (11, 1, 2)--<606.0833333333334>--(8, 10, 9, 16)\n",
      "Updated clustering pair: (11, 1, 2)--<591.0>--(3, 17)\n",
      "Updated clustering pair: (8, 10, 9, 16)--<581.0>--(3, 17)\n",
      "i1: 3; i2: 4\n",
      "new_row: [628.5, 601.0555555555555, 598.3333333333334, 625.3666666666667, 0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "\n",
      "\n",
      "clusters: [(5, 18, 19), (11, 1, 2), (12, 7, 14), (0, 4, 15, 6, 13), (8, 10, 9, 16, 3, 17)]\n",
      "labels: [(5, 18, 19), (11, 1, 2), (12, 7, 14), (0, 4, 15, 6, 13), (8, 10, 9, 16, 3, 17)]\n",
      "ages: {(1, 2): (214.0, 26), (7, 14): (203.0, 23), (17,): (0, 17), (8,): (0, 8), (8, 10, 9, 16): (261.125, 31), (9,): (0, 9), (10,): (0, 10), (9, 16): (206.5, 24), (5, 18, 19): (215.75, 27), (11,): (0, 11), (11, 1, 2): (237.75, 28), (12,): (0, 12), (13,): (0, 13), (3, 17): (262.0, 32), (14,): (0, 14), (18, 19): (202.5, 22), (15,): (0, 15), (0,): (0, 0), (1,): (0, 1), (0, 4, 15, 6, 13): (270.0, 33), (2,): (0, 2), (15, 6, 13): (254.25, 29), (3,): (0, 3), (8, 10): (201.0, 21), (12, 7, 14): (260.25, 30), (4,): (0, 4), (5,): (0, 5), (16,): (0, 16), (6,): (0, 6), (6, 13): (200.5, 20), (0, 4): (210.0, 25), (7,): (0, 7), (18,): (0, 18), (19,): (0, 19), (8, 10, 9, 16, 3, 17): (290.5, 34)}\n",
      "tree: {(1, 2): [[(1,), 0], [(2,), 0], [(11, 1, 2), 0]], (7, 14): [[(7,), 0], [(14,), 0], [(12, 7, 14), 0]], (17,): [[None, 0], [(3, 17), 0]], (8,): [[None, 0], [(8, 10), 0]], (8, 10, 9, 16): [[(8, 10), 0], [(9, 16), 0], [(8, 10, 9, 16, 3, 17), 0]], (9,): [[None, 0], [(9, 16), 0]], (10,): [[None, 0], [(8, 10), 0]], (9, 16): [[(9,), 0], [(16,), 0], [(8, 10, 9, 16), 0]], (5, 18, 19): [[(5,), 0], [(18, 19), 0]], (11,): [[None, 0], [(11, 1, 2), 0]], (11, 1, 2): [[(11,), 0], [(1, 2), 0]], (12,): [[None, 0], [(12, 7, 14), 0]], (13,): [[None, 0], [(6, 13), 0]], (3, 17): [[(3,), 0], [(17,), 0], [(8, 10, 9, 16, 3, 17), 0]], (14,): [[None, 0], [(7, 14), 0]], (18, 19): [[(18,), 0], [(19,), 0], [(5, 18, 19), 0]], (15,): [[None, 0], [(15, 6, 13), 0]], (0,): [[None, 0], [(0, 4), 0]], (1,): [[None, 0], [(1, 2), 0]], (0, 4, 15, 6, 13): [[(0, 4), 0], [(15, 6, 13), 0]], (2,): [[None, 0], [(1, 2), 0]], (15, 6, 13): [[(15,), 0], [(6, 13), 0], [(0, 4, 15, 6, 13), 0]], (3,): [[None, 0], [(3, 17), 0]], (8, 10): [[(8,), 0], [(10,), 0], [(8, 10, 9, 16), 0]], (12, 7, 14): [[(12,), 0], [(7, 14), 0]], (4,): [[None, 0], [(0, 4), 0]], (5,): [[None, 0], [(5, 18, 19), 0]], (16,): [[None, 0], [(9, 16), 0]], (6,): [[None, 0], [(6, 13), 0]], (6, 13): [[(6,), 0], [(13,), 0], [(15, 6, 13), 0]], (0, 4): [[(0,), 0], [(4,), 0], [(0, 4, 15, 6, 13), 0]], (7,): [[None, 0], [(7, 14), 0]], (18,): [[None, 0], [(18, 19), 0]], (19,): [[None, 0], [(18, 19), 0]], (8, 10, 9, 16, 3, 17): [[(8, 10, 9, 16), 0], [(3, 17), 0]]}\n",
      "Updated clustering pair: (5, 18, 19)--<620.8888888888889>--(11, 1, 2)\n",
      "Updated clustering pair: (11, 1, 2)--<601.0555555555555>--(8, 10, 9, 16, 3, 17)\n",
      "Updated clustering pair: (12, 7, 14)--<598.3333333333334>--(8, 10, 9, 16, 3, 17)\n",
      "i1: 2; i2: 4\n",
      "new_row: [634.2592592592592, 612.2962962962963, 631.4444444444445, 0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "\n",
      "\n",
      "clusters: [(5, 18, 19), (11, 1, 2), (0, 4, 15, 6, 13), (12, 7, 14, 8, 10, 9, 16, 3, 17)]\n",
      "labels: [(5, 18, 19), (11, 1, 2), (0, 4, 15, 6, 13), (12, 7, 14, 8, 10, 9, 16, 3, 17)]\n",
      "ages: {(1, 2): (214.0, 26), (7, 14): (203.0, 23), (17,): (0, 17), (8,): (0, 8), (8, 10, 9, 16): (261.125, 31), (12, 7, 14, 8, 10, 9, 16, 3, 17): (299.1666666666667, 35), (9,): (0, 9), (10,): (0, 10), (9, 16): (206.5, 24), (5, 18, 19): (215.75, 27), (11,): (0, 11), (11, 1, 2): (237.75, 28), (12,): (0, 12), (13,): (0, 13), (3, 17): (262.0, 32), (14,): (0, 14), (18, 19): (202.5, 22), (15,): (0, 15), (0,): (0, 0), (1,): (0, 1), (0, 4, 15, 6, 13): (270.0, 33), (2,): (0, 2), (15, 6, 13): (254.25, 29), (3,): (0, 3), (8, 10): (201.0, 21), (12, 7, 14): (260.25, 30), (4,): (0, 4), (5,): (0, 5), (16,): (0, 16), (6,): (0, 6), (6, 13): (200.5, 20), (0, 4): (210.0, 25), (7,): (0, 7), (18,): (0, 18), (19,): (0, 19), (8, 10, 9, 16, 3, 17): (290.5, 34)}\n",
      "tree: {(1, 2): [[(1,), 0], [(2,), 0], [(11, 1, 2), 0]], (7, 14): [[(7,), 0], [(14,), 0], [(12, 7, 14), 0]], (17,): [[None, 0], [(3, 17), 0]], (8,): [[None, 0], [(8, 10), 0]], (8, 10, 9, 16): [[(8, 10), 0], [(9, 16), 0], [(8, 10, 9, 16, 3, 17), 0]], (12, 7, 14, 8, 10, 9, 16, 3, 17): [[(12, 7, 14), 0], [(8, 10, 9, 16, 3, 17), 0]], (9,): [[None, 0], [(9, 16), 0]], (10,): [[None, 0], [(8, 10), 0]], (9, 16): [[(9,), 0], [(16,), 0], [(8, 10, 9, 16), 0]], (5, 18, 19): [[(5,), 0], [(18, 19), 0]], (11,): [[None, 0], [(11, 1, 2), 0]], (11, 1, 2): [[(11,), 0], [(1, 2), 0]], (12,): [[None, 0], [(12, 7, 14), 0]], (13,): [[None, 0], [(6, 13), 0]], (3, 17): [[(3,), 0], [(17,), 0], [(8, 10, 9, 16, 3, 17), 0]], (14,): [[None, 0], [(7, 14), 0]], (18, 19): [[(18,), 0], [(19,), 0], [(5, 18, 19), 0]], (15,): [[None, 0], [(15, 6, 13), 0]], (0,): [[None, 0], [(0, 4), 0]], (1,): [[None, 0], [(1, 2), 0]], (0, 4, 15, 6, 13): [[(0, 4), 0], [(15, 6, 13), 0]], (2,): [[None, 0], [(1, 2), 0]], (15, 6, 13): [[(15,), 0], [(6, 13), 0], [(0, 4, 15, 6, 13), 0]], (3,): [[None, 0], [(3, 17), 0]], (8, 10): [[(8,), 0], [(10,), 0], [(8, 10, 9, 16), 0]], (12, 7, 14): [[(12,), 0], [(7, 14), 0], [(12, 7, 14, 8, 10, 9, 16, 3, 17), 0]], (4,): [[None, 0], [(0, 4), 0]], (5,): [[None, 0], [(5, 18, 19), 0]], (16,): [[None, 0], [(9, 16), 0]], (6,): [[None, 0], [(6, 13), 0]], (6, 13): [[(6,), 0], [(13,), 0], [(15, 6, 13), 0]], (0, 4): [[(0,), 0], [(4,), 0], [(0, 4, 15, 6, 13), 0]], (7,): [[None, 0], [(7, 14), 0]], (18,): [[None, 0], [(18, 19), 0]], (19,): [[None, 0], [(18, 19), 0]], (8, 10, 9, 16, 3, 17): [[(8, 10, 9, 16), 0], [(3, 17), 0], [(12, 7, 14, 8, 10, 9, 16, 3, 17), 0]]}\n",
      "Updated clustering pair: (5, 18, 19)--<620.8888888888889>--(11, 1, 2)\n",
      "Updated clustering pair: (11, 1, 2)--<612.2962962962963>--(12, 7, 14, 8, 10, 9, 16, 3, 17)\n",
      "i1: 1; i2: 3\n",
      "new_row: [630.9166666666666, 630.1166666666667, 0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "\n",
      "\n",
      "clusters: [(5, 18, 19), (0, 4, 15, 6, 13), (11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17)]\n",
      "labels: [(5, 18, 19), (0, 4, 15, 6, 13), (11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17)]\n",
      "ages: {(1, 2): (214.0, 26), (7, 14): (203.0, 23), (17,): (0, 17), (8,): (0, 8), (8, 10, 9, 16): (261.125, 31), (12, 7, 14, 8, 10, 9, 16, 3, 17): (299.1666666666667, 35), (9,): (0, 9), (10,): (0, 10), (9, 16): (206.5, 24), (5, 18, 19): (215.75, 27), (11,): (0, 11), (11, 1, 2): (237.75, 28), (12,): (0, 12), (13,): (0, 13), (3, 17): (262.0, 32), (14,): (0, 14), (18, 19): (202.5, 22), (15,): (0, 15), (0,): (0, 0), (1,): (0, 1), (0, 4, 15, 6, 13): (270.0, 33), (2,): (0, 2), (15, 6, 13): (254.25, 29), (3,): (0, 3), (8, 10): (201.0, 21), (12, 7, 14): (260.25, 30), (4,): (0, 4), (5,): (0, 5), (16,): (0, 16), (6,): (0, 6), (6, 13): (200.5, 20), (0, 4): (210.0, 25), (7,): (0, 7), (18,): (0, 18), (19,): (0, 19), (8, 10, 9, 16, 3, 17): (290.5, 34), (11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17): (306.14814814814815, 36)}\n",
      "tree: {(1, 2): [[(1,), 0], [(2,), 0], [(11, 1, 2), 0]], (7, 14): [[(7,), 0], [(14,), 0], [(12, 7, 14), 0]], (17,): [[None, 0], [(3, 17), 0]], (8,): [[None, 0], [(8, 10), 0]], (8, 10, 9, 16): [[(8, 10), 0], [(9, 16), 0], [(8, 10, 9, 16, 3, 17), 0]], (12, 7, 14, 8, 10, 9, 16, 3, 17): [[(12, 7, 14), 0], [(8, 10, 9, 16, 3, 17), 0], [(11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17), 0]], (9,): [[None, 0], [(9, 16), 0]], (10,): [[None, 0], [(8, 10), 0]], (9, 16): [[(9,), 0], [(16,), 0], [(8, 10, 9, 16), 0]], (5, 18, 19): [[(5,), 0], [(18, 19), 0]], (11,): [[None, 0], [(11, 1, 2), 0]], (11, 1, 2): [[(11,), 0], [(1, 2), 0], [(11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17), 0]], (12,): [[None, 0], [(12, 7, 14), 0]], (13,): [[None, 0], [(6, 13), 0]], (3, 17): [[(3,), 0], [(17,), 0], [(8, 10, 9, 16, 3, 17), 0]], (14,): [[None, 0], [(7, 14), 0]], (18, 19): [[(18,), 0], [(19,), 0], [(5, 18, 19), 0]], (15,): [[None, 0], [(15, 6, 13), 0]], (0,): [[None, 0], [(0, 4), 0]], (1,): [[None, 0], [(1, 2), 0]], (0, 4, 15, 6, 13): [[(0, 4), 0], [(15, 6, 13), 0]], (2,): [[None, 0], [(1, 2), 0]], (15, 6, 13): [[(15,), 0], [(6, 13), 0], [(0, 4, 15, 6, 13), 0]], (3,): [[None, 0], [(3, 17), 0]], (8, 10): [[(8,), 0], [(10,), 0], [(8, 10, 9, 16), 0]], (12, 7, 14): [[(12,), 0], [(7, 14), 0], [(12, 7, 14, 8, 10, 9, 16, 3, 17), 0]], (4,): [[None, 0], [(0, 4), 0]], (5,): [[None, 0], [(5, 18, 19), 0]], (16,): [[None, 0], [(9, 16), 0]], (6,): [[None, 0], [(6, 13), 0]], (6, 13): [[(6,), 0], [(13,), 0], [(15, 6, 13), 0]], (0, 4): [[(0,), 0], [(4,), 0], [(0, 4, 15, 6, 13), 0]], (7,): [[None, 0], [(7, 14), 0]], (18,): [[None, 0], [(18, 19), 0]], (19,): [[None, 0], [(18, 19), 0]], (8, 10, 9, 16, 3, 17): [[(8, 10, 9, 16), 0], [(3, 17), 0], [(12, 7, 14, 8, 10, 9, 16, 3, 17), 0]], (11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17): [[(11, 1, 2), 0], [(12, 7, 14, 8, 10, 9, 16, 3, 17), 0]]}\n",
      "Updated clustering pair: (5, 18, 19)--<631.4666666666667>--(0, 4, 15, 6, 13)\n",
      "Updated clustering pair: (5, 18, 19)--<630.9166666666666>--(11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17)\n",
      "Updated clustering pair: (0, 4, 15, 6, 13)--<630.1166666666667>--(11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17)\n",
      "i1: 1; i2: 2\n",
      "new_row: [631.0784313725491, 0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "\n",
      "\n",
      "clusters: [(5, 18, 19), (0, 4, 15, 6, 13, 11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17)]\n",
      "labels: [(5, 18, 19), (0, 4, 15, 6, 13, 11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17)]\n",
      "ages: {(1, 2): (214.0, 26), (7, 14): (203.0, 23), (17,): (0, 17), (0, 4, 15, 6, 13, 11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17): (315.05833333333334, 37), (8,): (0, 8), (8, 10, 9, 16): (261.125, 31), (12, 7, 14, 8, 10, 9, 16, 3, 17): (299.1666666666667, 35), (9,): (0, 9), (10,): (0, 10), (9, 16): (206.5, 24), (5, 18, 19): (215.75, 27), (11,): (0, 11), (11, 1, 2): (237.75, 28), (12,): (0, 12), (13,): (0, 13), (3, 17): (262.0, 32), (14,): (0, 14), (18, 19): (202.5, 22), (15,): (0, 15), (0,): (0, 0), (1,): (0, 1), (0, 4, 15, 6, 13): (270.0, 33), (2,): (0, 2), (15, 6, 13): (254.25, 29), (3,): (0, 3), (8, 10): (201.0, 21), (12, 7, 14): (260.25, 30), (4,): (0, 4), (5,): (0, 5), (16,): (0, 16), (6,): (0, 6), (6, 13): (200.5, 20), (0, 4): (210.0, 25), (7,): (0, 7), (18,): (0, 18), (19,): (0, 19), (8, 10, 9, 16, 3, 17): (290.5, 34), (11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17): (306.14814814814815, 36)}\n",
      "tree: {(1, 2): [[(1,), 0], [(2,), 0], [(11, 1, 2), 0]], (7, 14): [[(7,), 0], [(14,), 0], [(12, 7, 14), 0]], (17,): [[None, 0], [(3, 17), 0]], (0, 4, 15, 6, 13, 11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17): [[(0, 4, 15, 6, 13), 0], [(11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17), 0]], (8,): [[None, 0], [(8, 10), 0]], (8, 10, 9, 16): [[(8, 10), 0], [(9, 16), 0], [(8, 10, 9, 16, 3, 17), 0]], (12, 7, 14, 8, 10, 9, 16, 3, 17): [[(12, 7, 14), 0], [(8, 10, 9, 16, 3, 17), 0], [(11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17), 0]], (9,): [[None, 0], [(9, 16), 0]], (10,): [[None, 0], [(8, 10), 0]], (9, 16): [[(9,), 0], [(16,), 0], [(8, 10, 9, 16), 0]], (5, 18, 19): [[(5,), 0], [(18, 19), 0]], (11,): [[None, 0], [(11, 1, 2), 0]], (11, 1, 2): [[(11,), 0], [(1, 2), 0], [(11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17), 0]], (12,): [[None, 0], [(12, 7, 14), 0]], (13,): [[None, 0], [(6, 13), 0]], (3, 17): [[(3,), 0], [(17,), 0], [(8, 10, 9, 16, 3, 17), 0]], (14,): [[None, 0], [(7, 14), 0]], (18, 19): [[(18,), 0], [(19,), 0], [(5, 18, 19), 0]], (15,): [[None, 0], [(15, 6, 13), 0]], (0,): [[None, 0], [(0, 4), 0]], (1,): [[None, 0], [(1, 2), 0]], (0, 4, 15, 6, 13): [[(0, 4), 0], [(15, 6, 13), 0], [(0, 4, 15, 6, 13, 11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17), 0]], (2,): [[None, 0], [(1, 2), 0]], (15, 6, 13): [[(15,), 0], [(6, 13), 0], [(0, 4, 15, 6, 13), 0]], (3,): [[None, 0], [(3, 17), 0]], (8, 10): [[(8,), 0], [(10,), 0], [(8, 10, 9, 16), 0]], (12, 7, 14): [[(12,), 0], [(7, 14), 0], [(12, 7, 14, 8, 10, 9, 16, 3, 17), 0]], (4,): [[None, 0], [(0, 4), 0]], (5,): [[None, 0], [(5, 18, 19), 0]], (16,): [[None, 0], [(9, 16), 0]], (6,): [[None, 0], [(6, 13), 0]], (6, 13): [[(6,), 0], [(13,), 0], [(15, 6, 13), 0]], (0, 4): [[(0,), 0], [(4,), 0], [(0, 4, 15, 6, 13), 0]], (7,): [[None, 0], [(7, 14), 0]], (18,): [[None, 0], [(18, 19), 0]], (19,): [[None, 0], [(18, 19), 0]], (8, 10, 9, 16, 3, 17): [[(8, 10, 9, 16), 0], [(3, 17), 0], [(12, 7, 14, 8, 10, 9, 16, 3, 17), 0]], (11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17): [[(11, 1, 2), 0], [(12, 7, 14, 8, 10, 9, 16, 3, 17), 0], [(0, 4, 15, 6, 13, 11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17), 0]]}\n",
      "Updated clustering pair: (5, 18, 19)--<631.0784313725491>--(0, 4, 15, 6, 13, 11, 1, 2, 12, 7, 14, 8, 10, 9, 16, 3, 17)\n",
      "i1: 0; i2: 1\n",
      "new_row: [0]\n",
      "updated mtrx: [[0, 765, 486, 692, 420, 759, 741, 562, 477, 584, 716, 550, 579, 479, 596, 482, 588, 674, 713, 494], [765, 0, 428, 614, 778, 749, 642, 708, 729, 657, 455, 514, 695, 714, 535, 555, 647, 561, 745, 606], [486, 428, 0, 645, 432, 661, 578, 609, 607, 754, 585, 437, 711, 774, 442, 639, 599, 525, 653, 429], [692, 614, 645, 0, 705, 576, 704, 669, 628, 651, 660, 662, 546, 435, 612, 667, 456, 524, 560, 475], [420, 778, 432, 705, 0, 718, 522, 558, 781, 782, 452, 495, 557, 460, 755, 556, 430, 744, 731, 688], [759, 749, 661, 576, 718, 0, 780, 415, 784, 795, 474, 470, 631, 664, 706, 621, 654, 772, 414, 449], [741, 642, 578, 704, 522, 780, 0, 582, 685, 783, 552, 592, 634, 401, 591, 506, 501, 684, 623, 407], [562, 708, 609, 669, 558, 415, 582, 0, 748, 597, 548, 613, 563, 723, 406, 752, 411, 590, 762, 534], [477, 729, 607, 628, 781, 784, 685, 748, 0, 521, 402, 559, 797, 709, 457, 412, 497, 409, 509, 722], [584, 657, 754, 651, 782, 795, 783, 597, 521, 0, 652, 610, 663, 593, 433, 507, 413, 583, 717, 488], [716, 455, 585, 660, 452, 474, 552, 548, 402, 652, 0, 551, 536, 632, 701, 697, 419, 753, 421, 743], [550, 514, 437, 662, 495, 470, 592, 613, 559, 610, 551, 0, 775, 694, 625, 698, 520, 539, 710, 565], [579, 695, 711, 546, 557, 631, 634, 563, 797, 663, 536, 775, 0, 513, 478, 767, 547, 656, 638, 760], [479, 714, 774, 435, 460, 664, 401, 723, 709, 593, 632, 694, 513, 0, 696, 511, 766, 512, 439, 491], [596, 535, 442, 612, 755, 706, 591, 406, 457, 433, 701, 625, 478, 696, 0, 789, 757, 502, 603, 763], [482, 555, 639, 667, 556, 621, 506, 752, 412, 507, 697, 698, 767, 511, 789, 0, 564, 733, 545, 799], [588, 647, 599, 456, 430, 654, 501, 411, 497, 413, 419, 520, 547, 766, 757, 564, 0, 508, 580, 626], [674, 561, 525, 524, 744, 772, 684, 590, 409, 583, 753, 539, 656, 512, 502, 733, 508, 0, 690, 727], [713, 745, 653, 560, 731, 414, 623, 762, 509, 717, 421, 710, 638, 439, 603, 545, 580, 690, 0, 405], [494, 606, 429, 475, 688, 449, 407, 534, 722, 488, 743, 565, 760, 491, 763, 799, 626, 727, 405, 0]]\n",
      "26->1:214.0\n",
      "26->2:214.0\n",
      "26->28:23.75\n",
      "23->7:203.0\n",
      "23->14:203.0\n",
      "23->30:57.25\n",
      "38->27:99.78921568627453\n",
      "38->37:0.48088235294119386\n",
      "17->32:262.0\n",
      "37->33:45.05833333333334\n",
      "37->36:8.910185185185185\n",
      "37->38:0.48088235294119386\n",
      "8->21:201.0\n",
      "31->21:60.125\n",
      "31->24:54.625\n",
      "31->34:29.375\n",
      "35->30:38.916666666666686\n",
      "35->34:8.666666666666686\n",
      "35->36:6.981481481481467\n",
      "9->24:206.5\n",
      "10->21:201.0\n",
      "24->9:206.5\n",
      "24->16:206.5\n",
      "24->31:54.625\n",
      "27->5:215.75\n",
      "27->22:13.25\n",
      "27->38:99.78921568627453\n",
      "11->28:237.75\n",
      "28->11:237.75\n",
      "28->26:23.75\n",
      "28->36:68.39814814814815\n",
      "12->30:260.25\n",
      "13->20:200.5\n",
      "32->3:262.0\n",
      "32->17:262.0\n",
      "32->34:28.5\n",
      "14->23:203.0\n",
      "22->18:202.5\n",
      "22->19:202.5\n",
      "22->27:13.25\n",
      "15->29:254.25\n",
      "0->25:210.0\n",
      "1->26:214.0\n",
      "33->25:60.0\n",
      "33->29:15.75\n",
      "33->37:45.05833333333334\n",
      "2->26:214.0\n",
      "29->15:254.25\n",
      "29->20:53.75\n",
      "29->33:15.75\n",
      "3->32:262.0\n",
      "21->8:201.0\n",
      "21->10:201.0\n",
      "21->31:60.125\n",
      "30->12:260.25\n",
      "30->23:57.25\n",
      "30->35:38.916666666666686\n",
      "4->25:210.0\n",
      "5->27:215.75\n",
      "16->24:206.5\n",
      "6->20:200.5\n",
      "20->6:200.5\n",
      "20->13:200.5\n",
      "20->29:53.75\n",
      "25->0:210.0\n",
      "25->4:210.0\n",
      "25->33:60.0\n",
      "7->23:203.0\n",
      "18->22:202.5\n",
      "19->22:202.5\n",
      "34->31:29.375\n",
      "34->32:28.5\n",
      "34->35:8.666666666666686\n",
      "36->28:68.39814814814815\n",
      "36->35:6.981481481481467\n",
      "36->37:8.910185185185185\n"
     ]
    }
   ],
   "source": [
    "def upgma(lines):\n",
    "    # Read in matrix\n",
    "    mtrx_orig = [list(map(int, ln)) for ln in [ln.strip().split('\\t') for ln in lines]]\n",
    "    mtrx = [list(map(int, ln)) for ln in [ln.strip().split('\\t') for ln in lines]]\n",
    "    \n",
    "    node_name = 0\n",
    "    \n",
    "    # Create individual clusters\n",
    "    clusters = [tuple([i]) for i in range(len(mtrx))]  # [(c1), (c2), ...]\n",
    "    \n",
    "    # Label matrix\n",
    "    labels = [c for c in clusters]  # [(c1), (c2), ...]\n",
    "    \n",
    "    # Make ages and tree\n",
    "    ages = {}  # (c1): age\n",
    "    tree = {}  # (c_from): [((c_to), dist), ...]\n",
    "    for c in clusters:\n",
    "        ages[c] = (0, node_name)\n",
    "        node_name += 1\n",
    "        tree[c] = [[None, 0]]\n",
    "\n",
    "    \n",
    "    # Cluster into 1\n",
    "    while len(clusters) > 1:\n",
    "        print('\\n\\nclusters: {}'.format(clusters))\n",
    "        print('labels: {}'.format(labels))\n",
    "        print('ages: {}'.format(ages))\n",
    "        print('tree: {}'.format(tree))\n",
    "        \n",
    "        # Find the closest 2 clusters\n",
    "        cluster1 = csluter2 = None\n",
    "        min_dist = 999999999\n",
    "        for c1, c2 in itertools.combinations(clusters, 2):\n",
    "            #print('c1: {}; c2: {}'.format(c1, c2))\n",
    "            dist = get_mean_pairwise_distance(mtrx_orig, c1, c2)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                cluster1, cluster2 = c1, c2\n",
    "                print('Updated clustering pair: {}--<{}>--{}'.format(cluster1, min_dist, cluster2))\n",
    "        \n",
    "        # Merge 2 closest clusters and add to clusters list\n",
    "        clusters.remove(cluster1)\n",
    "        clusters.remove(cluster2)\n",
    "        new_cluster = cluster1 + cluster2\n",
    "        clusters.append(new_cluster)\n",
    "        #print('\\nupdated clusters: {}'.format(clusters))\n",
    "        \n",
    "        # Add the ages of the new cluster\n",
    "        ages[new_cluster] = (min_dist / 2, node_name)\n",
    "        node_name += 1\n",
    "        #print('updated ages: {}'.format(ages))\n",
    "        \n",
    "        # Add the new cluster into the tree\n",
    "        tree[new_cluster] = [[cluster1, 0], [cluster2, 0]]\n",
    "        tree[cluster1].append([new_cluster, 0])\n",
    "        tree[cluster2].append([new_cluster, 0])\n",
    "        #print('updated tree: {}'.format(tree))\n",
    "        \n",
    "        # Get indices of cluster 1 and cluster 2\n",
    "        i1, i2 = sorted([labels.index(cluster1), labels.index(cluster2)])\n",
    "        print('i1: {}; i2: {}'.format(i1, i2))\n",
    "\n",
    "        # Remove cluster 1 and cluster 2 and add new cluster to the label\n",
    "        labels.remove(cluster1)\n",
    "        labels.remove(cluster2)\n",
    "        labels.append(new_cluster)\n",
    "        #print('updated labels: {}'.format(labels))\n",
    "        \n",
    "        # Make a row for the new cluster\n",
    "        new_row = []\n",
    "        for lab in labels:\n",
    "            if lab == new_cluster:\n",
    "                new_row.append(0)\n",
    "            else:\n",
    "                new_row.append(get_mean_pairwise_distance(mtrx_orig, new_cluster, lab))\n",
    "        print('new_row: {}'.format(new_row))\n",
    "        #print('mtrx: {}'.format(mtrx))\n",
    "                                                          \n",
    "        if len(mtrx) > 3:\n",
    "            # Remove cluster 1 and cluster 2 and add new cluster to the matrix\n",
    "            #mtrx = [row[:i1] + row[i1 + 1:i2] + row[i2 + 1:] + [new_row[i]] for i, row in enumerate(mtrx) if i != i1 and i != i2]\n",
    "            #mtrx.append(new_row)\n",
    "            print('updated mtrx: {}'.format(mtrx))\n",
    "    \n",
    "    for k, v in tree.items():\n",
    "        for vv, dd in v:\n",
    "            if not vv:\n",
    "                continue\n",
    "            dist = abs(ages[k][0] - ages[vv][0])\n",
    "            print('{}->{}:{}'.format(ages[k][1], ages[vv][1], dist))\n",
    "        \n",
    "        \n",
    "def get_mean_pairwise_distance(mtrx, cluster1, cluster2):\n",
    "    #print('get_mean_pairwise_distances:\\nmtrx: {}\\ncluster1: {}\\ncluster2: {}'.format(mtrx, cluster1, cluster2))\n",
    "    sum_ = 0\n",
    "    assert not set(cluster1) & set(cluster2), 'cluster 1 {} and cluster 2 {} should not have an intersection'.format(cluster1, cluster2)\n",
    "    for c1 in cluster1:\n",
    "        for c2 in cluster2:\n",
    "            sum_ += mtrx[c1][c2]\n",
    "    return sum_ / (len(cluster1) * len(cluster2))\n",
    "upgma(lines[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_nj_mtrx(mtrx):\n",
    "    n = len(mtrx)\n",
    "    \n",
    "    total_dist = [sum(row) for row in mtrx]\n",
    "    #print('total_dist: {}'.format(total_dist))\n",
    "    \n",
    "    nj_mtrx = [[0 for i in range(len(mtrx[0]))] for i in range(len(mtrx))]\n",
    "    #print('nj_mtrx: {}'.format(nj_mtrx))\n",
    "    \n",
    "    for i, row in enumerate(nj_mtrx):\n",
    "        for j, col in enumerate(row):\n",
    "            if i == j:\n",
    "                continue\n",
    "            #print('i: {} j: {}'.format(i, j))\n",
    "            row[j] = (n - 2) * mtrx[i][j] - total_dist[i] - total_dist[j]\n",
    "    return nj_mtrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lli: 6.0; llj: 7.0\n",
      "new_row: [15.0, 6.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "def NJ2(mtrx, n, idx):\n",
    "    #print('mtrx: {}\\nn: {}\\nidx: {}'.format(mtrx, n, idx))\n",
    "    \n",
    "    total_dist = [sum(row) for row in mtrx]\n",
    "    #print('total_dist: {}'.format(total_dist))\n",
    "    \n",
    "    # Base case\n",
    "    if n == 1:\n",
    "        #print('n is 1; 2 x 2 matrix: {}'.format(mtrx))\n",
    "        return {0: [(1, mtrx[0][1])], 1: [(0, mtrx[1][0])]}, idx\n",
    "    \n",
    "    # Make NJ mtrx\n",
    "    nj_mtrx = make_nj_mtrx(mtrx)\n",
    "    #print('nj_mtrx: {}'.format(nj_mtrx))\n",
    "    \n",
    "    # Find i and j such that nj_mtrx[i][j] is the minimum non-diagonal element\n",
    "    min_ = 999999999\n",
    "    for i, j in itertools.combinations(range(len(nj_mtrx)), 2):\n",
    "        if nj_mtrx[i][j] < min_:\n",
    "            min_ = nj_mtrx[i][j]\n",
    "    #print('i: {}; j: {}'.format(i, j))\n",
    "    \n",
    "    delta = (total_dist[i] - total_dist[j]) / (n - 2)\n",
    "    limb_length_i = 0.5 * (mtrx[i][j] + delta)\n",
    "    limb_length_j = 0.5 * (mtrx[i][j] - delta)\n",
    "    print('lli: {}; llj: {}'.format(limb_length_i, limb_length_j))\n",
    "    \n",
    "    new_row = [0.5 * (mtrx[k][i] + mtrx[k][j] - mtrx[i][j]) for k in range(len(mtrx))]\n",
    "    print('new_row:', new_row)\n",
    "    return\n",
    "    \n",
    "    \n",
    "    # Get limb length of leaf n\n",
    "    limb_length = get_limb_length(mtrx, n)\n",
    "    print('limb_length: {}'.format(limb_length))\n",
    "    \n",
    "    # Alimb_length non-n leaves\n",
    "    non_n_indices = list(range(0, len(mtrx)))\n",
    "    non_n_indices.remove(n)\n",
    "    print('non_n_indices: {}'.format(non_n_indices))\n",
    "    \n",
    "    # Remove the impact of leaf n\n",
    "    for i in non_n_indices:\n",
    "        mtrx[i][n] -= limb_length\n",
    "        mtrx[n][i] = mtrx[i][n]\n",
    "    print('mtrx after updating distances: {}'.format(mtrx))\n",
    "    \n",
    "    # Find l1 and l2 such that D(l1,l2) = D(l1,n) + D(n,l2)\n",
    "    for l1, l2 in [i for i in itertools.combinations(non_n_indices, 2)]:\n",
    "        if mtrx[l1][l2] == mtrx[l1][n] + mtrx[n][l2]:\n",
    "            leaf1, leaf2 = l1, l2\n",
    "            break\n",
    "    print('l1 and l2: {} {}'.format(l1, l2))\n",
    "    \n",
    "    # Get the distance between l1 and n; this distance is used to attach leaf n later\n",
    "    attaching_point = mtrx[l1][n]\n",
    "    print('attaching_point: {}'.format(attaching_point))\n",
    "    \n",
    "    '''\n",
    "    # Remove nth column\n",
    "    mtrx = mtrx[:n] + mtrx[n + 1:]\n",
    "    # Remove nth row\n",
    "    for row in mtrx:\n",
    "        row.pop(n)\n",
    "    print('mtrx after removing n: {}'.format(mtrx))\n",
    "    '''\n",
    "    \n",
    "    tree, idx = make_phylogeny_tree_using_additive_method([r[:-1] for r in mtrx[:-1]], len(mtrx) - 2, idx)\n",
    "    \n",
    "    # (current node, distacne to current node, previous node, distacne to previous node)\n",
    "    stack = [(l1, 0, None, None)]\n",
    "    visited = []\n",
    "    while True:\n",
    "        cur_n, cur_d, prev_n, prev_d = stack.pop()\n",
    "        print('popped:', cur_n, cur_d, prev_n, prev_d)\n",
    "        \n",
    "        if cur_n in visited:\n",
    "            continue\n",
    "        visited.append(cur_n)\n",
    "        if not can_reach(tree, cur_n, l2, visited):\n",
    "            print('{} cannot reach {}'.format(cur_n, l2))\n",
    "            continue\n",
    "            \n",
    "        if cur_d == attaching_point:\n",
    "            print('AT THE ATTACHING POINT')\n",
    "            tree[cur_n].append((n, limb_length))\n",
    "            print('{} --({})--> {}'.format(cur_n, limb_length, n))\n",
    "            assert n not in tree\n",
    "            tree[n] = [(cur_n, limb_length)]\n",
    "            print('{} --({})--> {}'.format(n, limb_length, cur_n))\n",
    "            return tree, idx\n",
    "        \n",
    "        elif cur_d > attaching_point:\n",
    "            print('PASSED THE ATTACHING POINT')\n",
    "            # Make a new node\n",
    "            new_n = idx\n",
    "            idx += 1\n",
    "            print('new_n: {}'.format(new_n))\n",
    "            #\n",
    "            tree[prev_n].append((new_n, attaching_point - prev_d))\n",
    "            print('{} --({})--> {}'.format(prev_n, attaching_point - prev_d, new_n))\n",
    "            assert new_n not in tree\n",
    "            tree[new_n] = [(prev_n, attaching_point - prev_d)]\n",
    "            print('{} --({})--> {}'.format(new_n, attaching_point - prev_d, prev_n))\n",
    "            #\n",
    "            tree[cur_n].append((new_n, cur_d - attaching_point))\n",
    "            print('{} --({})--> {}'.format(cur_n, cur_d - attaching_point, new_n))\n",
    "            tree[new_n].append((cur_n, cur_d - attaching_point))\n",
    "            print('{} --({})--> {}'.format(new_n, cur_d - attaching_point, cur_n))\n",
    "            #\n",
    "            tree[new_n].append((n, limb_length))\n",
    "            print('{} --({})--> {}'.format(new_n, limb_length, n))\n",
    "            assert n not in tree\n",
    "            tree[n] = [(new_n, limb_length)]\n",
    "            print('{} --({})--> {}'.format(n, limb_length, new_n))\n",
    "            \n",
    "            # Remove edges\n",
    "            tree[prev_n] = [(nn, dd) for nn, dd in tree[prev_n] if nn != cur_n]\n",
    "            tree[cur_n] = [(nn, dd) for nn, dd in tree[cur_n] if nn != prev_n]\n",
    "            \n",
    "            return tree, idx\n",
    "        \n",
    "        else:\n",
    "            for to_n, to_d in tree[cur_n]:\n",
    "                stack.append((to_n, cur_d + to_d, cur_n, cur_d))\n",
    "\n",
    "def NJ():\n",
    "    idx = 1\n",
    "    mtrx = [list(map(int, ln)) for ln in [ln.split(' ') for ln in lines[1:]]]\n",
    "    result, idx = NJ2(mtrx, len(mtrx) - 1, len(mtrx))\n",
    "    for k, v in result.items():\n",
    "        for vv, dd in v:\n",
    "            print('{}->{}:{0:.3g}'.format(k, vv, dd))\n",
    "mtrx = [[0, 13, 21, 22], [13, 0, 12, 13], [21, 12, 0, 13], [22, 13, 13, 0]]\n",
    "\n",
    "NJ2(mtrx, len(mtrx), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line 0:\t20\n",
      "line 1:\t0\t765\t486\t692\t420\t759\t741\t562\t477\t584\t716\t550\t579\t\n",
      "line 2:\t765\t0\t428\t614\t778\t749\t642\t708\t729\t657\t455\t514\t695\t\n",
      "line 3:\t486\t428\t0\t645\t432\t661\t578\t609\t607\t754\t585\t437\t711\t\n",
      "line 4:\t692\t614\t645\t0\t705\t576\t704\t669\t628\t651\t660\t662\t546\t\n",
      "line 5:\t420\t778\t432\t705\t0\t718\t522\t558\t781\t782\t452\t495\t557\t\n",
      "line 6:\t759\t749\t661\t576\t718\t0\t780\t415\t784\t795\t474\t470\t631\t\n",
      "line 7:\t741\t642\t578\t704\t522\t780\t0\t582\t685\t783\t552\t592\t634\t\n",
      "line 8:\t562\t708\t609\t669\t558\t415\t582\t0\t748\t597\t548\t613\t563\t\n",
      "line 9:\t477\t729\t607\t628\t781\t784\t685\t748\t0\t521\t402\t559\t797\t\n",
      "line 10:\t584\t657\t754\t651\t782\t795\t783\t597\t521\t0\t652\t610\t663\t\n",
      "line 11:\t716\t455\t585\t660\t452\t474\t552\t548\t402\t652\t0\t551\t536\t\n",
      "line 12:\t550\t514\t437\t662\t495\t470\t592\t613\t559\t610\t551\t0\t775\t\n",
      "line 13:\t579\t695\t711\t546\t557\t631\t634\t563\t797\t663\t536\t775\t0\t\n",
      "line 14:\t479\t714\t774\t435\t460\t664\t401\t723\t709\t593\t632\t694\t51\n",
      "line 15:\t596\t535\t442\t612\t755\t706\t591\t406\t457\t433\t701\t625\t47\n",
      "line 16:\t482\t555\t639\t667\t556\t621\t506\t752\t412\t507\t697\t698\t76\n",
      "line 17:\t588\t647\t599\t456\t430\t654\t501\t411\t497\t413\t419\t520\t54\n",
      "line 18:\t674\t561\t525\t524\t744\t772\t684\t590\t409\t583\t753\t539\t65\n",
      "line 19:\t713\t745\t653\t560\t731\t414\t623\t762\t509\t717\t421\t710\t63\n",
      "line 20:\t494\t606\t429\t475\t688\t449\t407\t534\t722\t488\t743\t565\t76\n"
     ]
    }
   ],
   "source": [
    "DOWNLOAD_DIRECTORY_PATH = os.path.join(os.environ['HOME'], 'Downloads')\n",
    "with open('/Users/Kwat/Downloads/rosalind_ba7d.txt', 'r') as f:\n",
    "    content = f.read()\n",
    "    lines = content.split('\\n')\n",
    "    lines = [i for i in lines if i != ''] # Be careful about lines containing only ''\n",
    "for i, line in enumerate(lines):\n",
    "    print('line {}:\\t{}'.format(i, line[:50]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
